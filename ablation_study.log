2024-08-04 11:24:15,662 - INFO - Created results directory: results\20240804_112415
2024-08-04 11:24:15,663 - INFO - Starting Ablation Study
2024-08-04 11:24:15,663 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 11:24:15,747 - INFO - Using device: cuda
2024-08-04 11:24:15,747 - INFO - Using device: cuda
2024-08-04 11:24:47,500 - INFO - Profiling stats saved to results\20240804_112415\kg_completeness_0.25\profile_stats.txt
2024-08-04 11:24:47,500 - INFO - Profiling stats saved to results\20240804_112415\kg_completeness_0.25\profile_stats.txt
2024-08-04 11:24:49,496 - INFO - Training and evaluation completed.
2024-08-04 11:24:49,496 - INFO - Training and evaluation completed.
2024-08-04 11:24:49,498 - INFO - Experiment kg_completeness_0.25 completed
2024-08-04 11:24:49,498 - INFO - Experiment kg_completeness_0.25 completed
2024-08-04 11:24:49,499 - INFO - Running experiment: kg_completeness_0.5
2024-08-04 11:24:49,499 - INFO - Running experiment: kg_completeness_0.5
2024-08-04 11:24:49,500 - INFO - Using device: cuda
2024-08-04 11:24:49,500 - INFO - Using device: cuda
2024-08-04 11:24:49,500 - INFO - Using device: cuda
2024-08-04 11:25:20,417 - INFO - Profiling stats saved to results\20240804_112415\kg_completeness_0.5\profile_stats.txt
2024-08-04 11:25:20,417 - INFO - Profiling stats saved to results\20240804_112415\kg_completeness_0.5\profile_stats.txt
2024-08-04 11:25:20,417 - INFO - Profiling stats saved to results\20240804_112415\kg_completeness_0.5\profile_stats.txt
2024-08-04 11:25:22,534 - INFO - Training and evaluation completed.
2024-08-04 11:25:22,534 - INFO - Training and evaluation completed.
2024-08-04 11:25:22,534 - INFO - Training and evaluation completed.
2024-08-04 11:25:22,535 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 11:25:22,535 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 11:25:22,535 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 11:25:22,536 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 11:25:22,536 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 11:25:22,536 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 11:25:22,536 - INFO - Using device: cuda
2024-08-04 11:25:22,536 - INFO - Using device: cuda
2024-08-04 11:25:22,536 - INFO - Using device: cuda
2024-08-04 11:25:22,536 - INFO - Using device: cuda
2024-08-04 11:25:52,789 - INFO - Profiling stats saved to results\20240804_112415\kg_completeness_0.75\profile_stats.txt
2024-08-04 11:25:52,789 - INFO - Profiling stats saved to results\20240804_112415\kg_completeness_0.75\profile_stats.txt
2024-08-04 11:25:52,789 - INFO - Profiling stats saved to results\20240804_112415\kg_completeness_0.75\profile_stats.txt
2024-08-04 11:25:52,789 - INFO - Profiling stats saved to results\20240804_112415\kg_completeness_0.75\profile_stats.txt
2024-08-04 11:25:54,891 - INFO - Training and evaluation completed.
2024-08-04 11:25:54,891 - INFO - Training and evaluation completed.
2024-08-04 11:25:54,891 - INFO - Training and evaluation completed.
2024-08-04 11:25:54,891 - INFO - Training and evaluation completed.
2024-08-04 11:25:54,893 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 11:25:54,893 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 11:25:54,893 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 11:25:54,893 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 11:25:54,894 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 11:25:54,894 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 11:25:54,894 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 11:25:54,894 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 11:25:54,895 - INFO - Using device: cuda
2024-08-04 11:25:54,895 - INFO - Using device: cuda
2024-08-04 11:25:54,895 - INFO - Using device: cuda
2024-08-04 11:25:54,895 - INFO - Using device: cuda
2024-08-04 11:25:54,895 - INFO - Using device: cuda
2024-08-04 11:25:54,911 - ERROR - An error occurred during the ablation study: Cannot choose from an empty sequence
2024-08-04 11:25:54,911 - ERROR - An error occurred during the ablation study: Cannot choose from an empty sequence
2024-08-04 11:25:54,911 - ERROR - An error occurred during the ablation study: Cannot choose from an empty sequence
2024-08-04 11:25:54,911 - ERROR - An error occurred during the ablation study: Cannot choose from an empty sequence
2024-08-04 11:25:54,911 - ERROR - An error occurred during the ablation study: Cannot choose from an empty sequence
2024-08-04 11:25:54,919 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 260, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 139, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 186, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 39, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 11, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 27, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-04 11:25:54,919 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 260, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 139, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 186, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 39, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 11, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 27, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-04 11:25:54,919 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 260, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 139, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 186, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 39, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 11, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 27, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-04 11:25:54,919 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 260, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 139, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 186, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 39, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 11, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 27, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-04 11:25:54,919 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 260, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 139, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 186, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 39, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 11, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 27, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-04 11:27:08,890 - INFO - Created results directory: results\20240804_112708
2024-08-04 11:27:08,890 - INFO - Starting Ablation Study
2024-08-04 11:27:08,891 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 11:27:08,914 - INFO - Using device: cuda
2024-08-04 11:27:08,914 - INFO - Using device: cuda
2024-08-04 11:27:36,783 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_0.25\profile_stats.txt
2024-08-04 11:27:36,783 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_0.25\profile_stats.txt
2024-08-04 11:27:38,611 - INFO - Training and evaluation completed.
2024-08-04 11:27:38,611 - INFO - Training and evaluation completed.
2024-08-04 11:27:38,612 - INFO - Experiment kg_completeness_0.25 completed
2024-08-04 11:27:38,612 - INFO - Experiment kg_completeness_0.25 completed
2024-08-04 11:27:38,613 - INFO - Running experiment: kg_completeness_0.5
2024-08-04 11:27:38,613 - INFO - Running experiment: kg_completeness_0.5
2024-08-04 11:27:38,614 - INFO - Using device: cuda
2024-08-04 11:27:38,614 - INFO - Using device: cuda
2024-08-04 11:27:38,614 - INFO - Using device: cuda
2024-08-04 11:28:07,275 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_0.5\profile_stats.txt
2024-08-04 11:28:07,275 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_0.5\profile_stats.txt
2024-08-04 11:28:07,275 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_0.5\profile_stats.txt
2024-08-04 11:28:09,288 - INFO - Training and evaluation completed.
2024-08-04 11:28:09,288 - INFO - Training and evaluation completed.
2024-08-04 11:28:09,288 - INFO - Training and evaluation completed.
2024-08-04 11:28:09,288 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 11:28:09,288 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 11:28:09,288 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 11:28:09,289 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 11:28:09,289 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 11:28:09,289 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 11:28:09,290 - INFO - Using device: cuda
2024-08-04 11:28:09,290 - INFO - Using device: cuda
2024-08-04 11:28:09,290 - INFO - Using device: cuda
2024-08-04 11:28:09,290 - INFO - Using device: cuda
2024-08-04 11:28:39,380 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_0.75\profile_stats.txt
2024-08-04 11:28:39,380 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_0.75\profile_stats.txt
2024-08-04 11:28:39,380 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_0.75\profile_stats.txt
2024-08-04 11:28:39,380 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_0.75\profile_stats.txt
2024-08-04 11:28:41,390 - INFO - Training and evaluation completed.
2024-08-04 11:28:41,390 - INFO - Training and evaluation completed.
2024-08-04 11:28:41,390 - INFO - Training and evaluation completed.
2024-08-04 11:28:41,390 - INFO - Training and evaluation completed.
2024-08-04 11:28:41,392 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 11:28:41,392 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 11:28:41,392 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 11:28:41,392 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 11:28:41,392 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 11:28:41,392 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 11:28:41,392 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 11:28:41,392 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 11:28:41,405 - INFO - Using device: cuda
2024-08-04 11:28:41,405 - INFO - Using device: cuda
2024-08-04 11:28:41,405 - INFO - Using device: cuda
2024-08-04 11:28:41,405 - INFO - Using device: cuda
2024-08-04 11:28:41,405 - INFO - Using device: cuda
2024-08-04 11:29:09,257 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_1.0\profile_stats.txt
2024-08-04 11:29:09,257 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_1.0\profile_stats.txt
2024-08-04 11:29:09,257 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_1.0\profile_stats.txt
2024-08-04 11:29:09,257 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_1.0\profile_stats.txt
2024-08-04 11:29:09,257 - INFO - Profiling stats saved to results\20240804_112708\kg_completeness_1.0\profile_stats.txt
2024-08-04 11:29:10,907 - INFO - Training and evaluation completed.
2024-08-04 11:29:10,907 - INFO - Training and evaluation completed.
2024-08-04 11:29:10,907 - INFO - Training and evaluation completed.
2024-08-04 11:29:10,907 - INFO - Training and evaluation completed.
2024-08-04 11:29:10,907 - INFO - Training and evaluation completed.
2024-08-04 11:29:10,909 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 11:29:10,909 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 11:29:10,909 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 11:29:10,909 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 11:29:10,909 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 11:29:10,910 - INFO - Ablation study results saved to results\20240804_112708\ablation_study_results.json
2024-08-04 11:29:10,910 - INFO - Ablation study results saved to results\20240804_112708\ablation_study_results.json
2024-08-04 11:29:10,910 - INFO - Ablation study results saved to results\20240804_112708\ablation_study_results.json
2024-08-04 11:29:10,910 - INFO - Ablation study results saved to results\20240804_112708\ablation_study_results.json
2024-08-04 11:29:10,910 - INFO - Ablation study results saved to results\20240804_112708\ablation_study_results.json
2024-08-04 11:29:10,912 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.25_results.json
2024-08-04 11:29:10,912 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.25_results.json
2024-08-04 11:29:10,912 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.25_results.json
2024-08-04 11:29:10,912 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.25_results.json
2024-08-04 11:29:10,912 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.25_results.json
2024-08-04 11:29:10,914 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.5_results.json
2024-08-04 11:29:10,914 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.5_results.json
2024-08-04 11:29:10,914 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.5_results.json
2024-08-04 11:29:10,914 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.5_results.json
2024-08-04 11:29:10,914 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.5_results.json
2024-08-04 11:29:10,915 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.75_results.json
2024-08-04 11:29:10,915 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.75_results.json
2024-08-04 11:29:10,915 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.75_results.json
2024-08-04 11:29:10,915 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.75_results.json
2024-08-04 11:29:10,915 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_0.75_results.json
2024-08-04 11:29:10,917 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_1.0_results.json
2024-08-04 11:29:10,917 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_1.0_results.json
2024-08-04 11:29:10,917 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_1.0_results.json
2024-08-04 11:29:10,917 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_1.0_results.json
2024-08-04 11:29:10,917 - INFO - Individual experiment results saved to results\20240804_112708\kg_completeness_1.0_results.json
2024-08-04 11:29:10,919 - INFO - Base configuration saved to results\20240804_112708\base_config.json
2024-08-04 11:29:10,919 - INFO - Base configuration saved to results\20240804_112708\base_config.json
2024-08-04 11:29:10,919 - INFO - Base configuration saved to results\20240804_112708\base_config.json
2024-08-04 11:29:10,919 - INFO - Base configuration saved to results\20240804_112708\base_config.json
2024-08-04 11:29:10,919 - INFO - Base configuration saved to results\20240804_112708\base_config.json
2024-08-04 11:29:10,920 - INFO - Ablation Study completed
2024-08-04 11:29:10,920 - INFO - Ablation Study completed
2024-08-04 11:29:10,920 - INFO - Ablation Study completed
2024-08-04 11:29:10,920 - INFO - Ablation Study completed
2024-08-04 11:29:10,920 - INFO - Ablation Study completed
2024-08-04 14:34:39,034 - INFO - Created results directory: results\20240804_143439
2024-08-04 14:34:39,035 - INFO - Starting Ablation Study
2024-08-04 14:34:39,035 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 14:34:39,111 - INFO - Using device: cuda
2024-08-04 14:34:39,111 - INFO - Using device: cuda
2024-08-04 14:34:40,411 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_0.25\profile_stats.txt
2024-08-04 14:34:40,411 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_0.25\profile_stats.txt
2024-08-04 14:34:42,802 - INFO - Training and evaluation completed.
2024-08-04 14:34:42,802 - INFO - Training and evaluation completed.
2024-08-04 14:34:42,803 - INFO - Experiment kg_completeness_0.25 completed
2024-08-04 14:34:42,803 - INFO - Experiment kg_completeness_0.25 completed
2024-08-04 14:34:42,803 - INFO - Running experiment: kg_completeness_0.5
2024-08-04 14:34:42,803 - INFO - Running experiment: kg_completeness_0.5
2024-08-04 14:34:42,804 - INFO - Using device: cuda
2024-08-04 14:34:42,804 - INFO - Using device: cuda
2024-08-04 14:34:42,804 - INFO - Using device: cuda
2024-08-04 14:34:43,679 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_0.5\profile_stats.txt
2024-08-04 14:34:43,679 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_0.5\profile_stats.txt
2024-08-04 14:34:43,679 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_0.5\profile_stats.txt
2024-08-04 14:34:45,097 - INFO - Training and evaluation completed.
2024-08-04 14:34:45,097 - INFO - Training and evaluation completed.
2024-08-04 14:34:45,097 - INFO - Training and evaluation completed.
2024-08-04 14:34:45,098 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 14:34:45,098 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 14:34:45,098 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 14:34:45,098 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 14:34:45,098 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 14:34:45,098 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 14:34:45,099 - INFO - Using device: cuda
2024-08-04 14:34:45,099 - INFO - Using device: cuda
2024-08-04 14:34:45,099 - INFO - Using device: cuda
2024-08-04 14:34:45,099 - INFO - Using device: cuda
2024-08-04 14:34:45,986 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_0.75\profile_stats.txt
2024-08-04 14:34:45,986 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_0.75\profile_stats.txt
2024-08-04 14:34:45,986 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_0.75\profile_stats.txt
2024-08-04 14:34:45,986 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_0.75\profile_stats.txt
2024-08-04 14:34:47,535 - INFO - Training and evaluation completed.
2024-08-04 14:34:47,535 - INFO - Training and evaluation completed.
2024-08-04 14:34:47,535 - INFO - Training and evaluation completed.
2024-08-04 14:34:47,535 - INFO - Training and evaluation completed.
2024-08-04 14:34:47,536 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 14:34:47,536 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 14:34:47,536 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 14:34:47,536 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 14:34:47,536 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 14:34:47,536 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 14:34:47,536 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 14:34:47,536 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 14:34:47,538 - INFO - Using device: cuda
2024-08-04 14:34:47,538 - INFO - Using device: cuda
2024-08-04 14:34:47,538 - INFO - Using device: cuda
2024-08-04 14:34:47,538 - INFO - Using device: cuda
2024-08-04 14:34:47,538 - INFO - Using device: cuda
2024-08-04 14:34:48,516 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_1.0\profile_stats.txt
2024-08-04 14:34:48,516 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_1.0\profile_stats.txt
2024-08-04 14:34:48,516 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_1.0\profile_stats.txt
2024-08-04 14:34:48,516 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_1.0\profile_stats.txt
2024-08-04 14:34:48,516 - INFO - Profiling stats saved to results\20240804_143439\kg_completeness_1.0\profile_stats.txt
2024-08-04 14:34:49,986 - INFO - Training and evaluation completed.
2024-08-04 14:34:49,986 - INFO - Training and evaluation completed.
2024-08-04 14:34:49,986 - INFO - Training and evaluation completed.
2024-08-04 14:34:49,986 - INFO - Training and evaluation completed.
2024-08-04 14:34:49,986 - INFO - Training and evaluation completed.
2024-08-04 14:34:49,987 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 14:34:49,987 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 14:34:49,987 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 14:34:49,987 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 14:34:49,987 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 14:34:49,988 - INFO - Ablation study results saved to results\20240804_143439\ablation_study_results.json
2024-08-04 14:34:49,988 - INFO - Ablation study results saved to results\20240804_143439\ablation_study_results.json
2024-08-04 14:34:49,988 - INFO - Ablation study results saved to results\20240804_143439\ablation_study_results.json
2024-08-04 14:34:49,988 - INFO - Ablation study results saved to results\20240804_143439\ablation_study_results.json
2024-08-04 14:34:49,988 - INFO - Ablation study results saved to results\20240804_143439\ablation_study_results.json
2024-08-04 14:34:49,990 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.25_results.json
2024-08-04 14:34:49,990 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.25_results.json
2024-08-04 14:34:49,990 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.25_results.json
2024-08-04 14:34:49,990 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.25_results.json
2024-08-04 14:34:49,990 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.25_results.json
2024-08-04 14:34:49,993 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.5_results.json
2024-08-04 14:34:49,993 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.5_results.json
2024-08-04 14:34:49,993 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.5_results.json
2024-08-04 14:34:49,993 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.5_results.json
2024-08-04 14:34:49,993 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.5_results.json
2024-08-04 14:34:49,995 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.75_results.json
2024-08-04 14:34:49,995 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.75_results.json
2024-08-04 14:34:49,995 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.75_results.json
2024-08-04 14:34:49,995 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.75_results.json
2024-08-04 14:34:49,995 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_0.75_results.json
2024-08-04 14:34:49,997 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_1.0_results.json
2024-08-04 14:34:49,997 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_1.0_results.json
2024-08-04 14:34:49,997 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_1.0_results.json
2024-08-04 14:34:49,997 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_1.0_results.json
2024-08-04 14:34:49,997 - INFO - Individual experiment results saved to results\20240804_143439\kg_completeness_1.0_results.json
2024-08-04 14:34:49,998 - INFO - Base configuration saved to results\20240804_143439\base_config.json
2024-08-04 14:34:49,998 - INFO - Base configuration saved to results\20240804_143439\base_config.json
2024-08-04 14:34:49,998 - INFO - Base configuration saved to results\20240804_143439\base_config.json
2024-08-04 14:34:49,998 - INFO - Base configuration saved to results\20240804_143439\base_config.json
2024-08-04 14:34:49,998 - INFO - Base configuration saved to results\20240804_143439\base_config.json
2024-08-04 14:34:49,999 - INFO - Ablation Study completed
2024-08-04 14:34:49,999 - INFO - Ablation Study completed
2024-08-04 14:34:49,999 - INFO - Ablation Study completed
2024-08-04 14:34:49,999 - INFO - Ablation Study completed
2024-08-04 14:34:49,999 - INFO - Ablation Study completed
2024-08-04 14:36:13,252 - INFO - Created results directory: results\20240804_143613
2024-08-04 14:36:13,253 - INFO - Starting Ablation Study
2024-08-04 14:36:13,253 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 14:36:13,278 - INFO - Using device: cuda
2024-08-04 14:36:13,278 - INFO - Using device: cuda
2024-08-04 14:36:15,540 - INFO - Profiling stats saved to results\20240804_143613\kg_completeness_0.25\profile_stats.txt
2024-08-04 14:36:15,540 - INFO - Profiling stats saved to results\20240804_143613\kg_completeness_0.25\profile_stats.txt
2024-08-04 14:42:20,841 - INFO - Created results directory: results\20240804_144220
2024-08-04 14:42:20,841 - INFO - Starting Ablation Study
2024-08-04 14:42:20,841 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 14:42:20,887 - INFO - Using device: cuda
2024-08-04 14:42:20,887 - INFO - Using device: cuda
2024-08-04 14:45:23,038 - INFO - Created results directory: results\20240804_144523
2024-08-04 14:45:23,038 - INFO - Starting Ablation Study
2024-08-04 14:45:23,038 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 14:45:23,060 - INFO - Using device: cuda
2024-08-04 14:45:23,060 - INFO - Using device: cuda
2024-08-04 14:47:15,086 - INFO - Created results directory: results\20240804_144715
2024-08-04 14:47:15,086 - INFO - Starting Ablation Study
2024-08-04 14:47:15,086 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 14:47:15,112 - INFO - Using device: cuda
2024-08-04 14:47:15,112 - INFO - Using device: cuda
2024-08-04 14:47:56,604 - INFO - Created results directory: results\20240804_144756
2024-08-04 14:47:56,606 - INFO - Starting Ablation Study
2024-08-04 14:47:56,606 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 14:47:56,630 - INFO - Using device: cuda
2024-08-04 14:47:56,630 - INFO - Using device: cuda
2024-08-04 14:52:15,829 - INFO - Profiling stats saved to results\20240804_144756\kg_completeness_0.25\profile_stats.txt
2024-08-04 14:52:15,829 - INFO - Profiling stats saved to results\20240804_144756\kg_completeness_0.25\profile_stats.txt
2024-08-04 15:20:19,655 - INFO - Created results directory: results\20240804_152019
2024-08-04 15:20:19,656 - INFO - Starting Ablation Study
2024-08-04 15:20:19,656 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 15:20:19,699 - INFO - Using device: cuda
2024-08-04 15:20:19,699 - INFO - Using device: cuda
2024-08-04 15:21:43,633 - INFO - Created results directory: results\20240804_152143
2024-08-04 15:21:43,633 - INFO - Starting Ablation Study
2024-08-04 15:21:43,633 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 15:21:43,656 - INFO - Using device: cuda
2024-08-04 15:21:43,656 - INFO - Using device: cuda
2024-08-04 15:21:44,955 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_0.25\profile_stats.txt
2024-08-04 15:21:44,955 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_0.25\profile_stats.txt
2024-08-04 15:21:47,044 - INFO - Training and evaluation completed.
2024-08-04 15:21:47,044 - INFO - Training and evaluation completed.
2024-08-04 15:21:47,046 - INFO - Experiment kg_completeness_0.25 completed
2024-08-04 15:21:47,046 - INFO - Experiment kg_completeness_0.25 completed
2024-08-04 15:21:47,046 - INFO - Running experiment: kg_completeness_0.5
2024-08-04 15:21:47,046 - INFO - Running experiment: kg_completeness_0.5
2024-08-04 15:21:47,048 - INFO - Using device: cuda
2024-08-04 15:21:47,048 - INFO - Using device: cuda
2024-08-04 15:21:47,048 - INFO - Using device: cuda
2024-08-04 15:21:48,120 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_0.5\profile_stats.txt
2024-08-04 15:21:48,120 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_0.5\profile_stats.txt
2024-08-04 15:21:48,120 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_0.5\profile_stats.txt
2024-08-04 15:21:49,672 - INFO - Training and evaluation completed.
2024-08-04 15:21:49,672 - INFO - Training and evaluation completed.
2024-08-04 15:21:49,672 - INFO - Training and evaluation completed.
2024-08-04 15:21:49,673 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 15:21:49,673 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 15:21:49,673 - INFO - Experiment kg_completeness_0.5 completed
2024-08-04 15:21:49,673 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 15:21:49,673 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 15:21:49,673 - INFO - Running experiment: kg_completeness_0.75
2024-08-04 15:21:49,676 - INFO - Using device: cuda
2024-08-04 15:21:49,676 - INFO - Using device: cuda
2024-08-04 15:21:49,676 - INFO - Using device: cuda
2024-08-04 15:21:49,676 - INFO - Using device: cuda
2024-08-04 15:21:50,616 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_0.75\profile_stats.txt
2024-08-04 15:21:50,616 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_0.75\profile_stats.txt
2024-08-04 15:21:50,616 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_0.75\profile_stats.txt
2024-08-04 15:21:50,616 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_0.75\profile_stats.txt
2024-08-04 15:21:52,322 - INFO - Training and evaluation completed.
2024-08-04 15:21:52,322 - INFO - Training and evaluation completed.
2024-08-04 15:21:52,322 - INFO - Training and evaluation completed.
2024-08-04 15:21:52,322 - INFO - Training and evaluation completed.
2024-08-04 15:21:52,323 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 15:21:52,323 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 15:21:52,323 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 15:21:52,323 - INFO - Experiment kg_completeness_0.75 completed
2024-08-04 15:21:52,323 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 15:21:52,323 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 15:21:52,323 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 15:21:52,323 - INFO - Running experiment: kg_completeness_1.0
2024-08-04 15:21:52,325 - INFO - Using device: cuda
2024-08-04 15:21:52,325 - INFO - Using device: cuda
2024-08-04 15:21:52,325 - INFO - Using device: cuda
2024-08-04 15:21:52,325 - INFO - Using device: cuda
2024-08-04 15:21:52,325 - INFO - Using device: cuda
2024-08-04 15:21:53,355 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_1.0\profile_stats.txt
2024-08-04 15:21:53,355 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_1.0\profile_stats.txt
2024-08-04 15:21:53,355 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_1.0\profile_stats.txt
2024-08-04 15:21:53,355 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_1.0\profile_stats.txt
2024-08-04 15:21:53,355 - INFO - Profiling stats saved to results\20240804_152143\kg_completeness_1.0\profile_stats.txt
2024-08-04 15:21:54,953 - INFO - Training and evaluation completed.
2024-08-04 15:21:54,953 - INFO - Training and evaluation completed.
2024-08-04 15:21:54,953 - INFO - Training and evaluation completed.
2024-08-04 15:21:54,953 - INFO - Training and evaluation completed.
2024-08-04 15:21:54,953 - INFO - Training and evaluation completed.
2024-08-04 15:21:54,954 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 15:21:54,954 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 15:21:54,954 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 15:21:54,954 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 15:21:54,954 - INFO - Experiment kg_completeness_1.0 completed
2024-08-04 15:21:54,955 - INFO - Ablation study results saved to results\20240804_152143\ablation_study_results.json
2024-08-04 15:21:54,955 - INFO - Ablation study results saved to results\20240804_152143\ablation_study_results.json
2024-08-04 15:21:54,955 - INFO - Ablation study results saved to results\20240804_152143\ablation_study_results.json
2024-08-04 15:21:54,955 - INFO - Ablation study results saved to results\20240804_152143\ablation_study_results.json
2024-08-04 15:21:54,955 - INFO - Ablation study results saved to results\20240804_152143\ablation_study_results.json
2024-08-04 15:21:54,958 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.25_results.json
2024-08-04 15:21:54,958 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.25_results.json
2024-08-04 15:21:54,958 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.25_results.json
2024-08-04 15:21:54,958 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.25_results.json
2024-08-04 15:21:54,958 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.25_results.json
2024-08-04 15:21:54,960 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.5_results.json
2024-08-04 15:21:54,960 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.5_results.json
2024-08-04 15:21:54,960 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.5_results.json
2024-08-04 15:21:54,960 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.5_results.json
2024-08-04 15:21:54,960 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.5_results.json
2024-08-04 15:21:54,963 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.75_results.json
2024-08-04 15:21:54,963 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.75_results.json
2024-08-04 15:21:54,963 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.75_results.json
2024-08-04 15:21:54,963 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.75_results.json
2024-08-04 15:21:54,963 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_0.75_results.json
2024-08-04 15:21:54,965 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_1.0_results.json
2024-08-04 15:21:54,965 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_1.0_results.json
2024-08-04 15:21:54,965 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_1.0_results.json
2024-08-04 15:21:54,965 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_1.0_results.json
2024-08-04 15:21:54,965 - INFO - Individual experiment results saved to results\20240804_152143\kg_completeness_1.0_results.json
2024-08-04 15:21:54,967 - INFO - Base configuration saved to results\20240804_152143\base_config.json
2024-08-04 15:21:54,967 - INFO - Base configuration saved to results\20240804_152143\base_config.json
2024-08-04 15:21:54,967 - INFO - Base configuration saved to results\20240804_152143\base_config.json
2024-08-04 15:21:54,967 - INFO - Base configuration saved to results\20240804_152143\base_config.json
2024-08-04 15:21:54,967 - INFO - Base configuration saved to results\20240804_152143\base_config.json
2024-08-04 15:21:54,968 - INFO - Ablation Study completed
2024-08-04 15:21:54,968 - INFO - Ablation Study completed
2024-08-04 15:21:54,968 - INFO - Ablation Study completed
2024-08-04 15:21:54,968 - INFO - Ablation Study completed
2024-08-04 15:21:54,968 - INFO - Ablation Study completed
2024-08-04 15:25:45,130 - INFO - Created results directory: results\20240804_152545
2024-08-04 15:25:45,130 - INFO - Starting Ablation Study
2024-08-04 15:25:45,130 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 15:25:45,155 - INFO - Using device: cuda
2024-08-04 15:25:45,155 - INFO - Using device: cuda
2024-08-04 15:29:38,245 - INFO - Profiling stats saved to results\20240804_152545\kg_completeness_0.25\profile_stats.txt
2024-08-04 15:29:38,245 - INFO - Profiling stats saved to results\20240804_152545\kg_completeness_0.25\profile_stats.txt
2024-08-04 15:35:50,675 - INFO - Created results directory: results\20240804_153550
2024-08-04 15:35:50,675 - INFO - Starting Ablation Study
2024-08-04 15:35:50,675 - INFO - Running experiment: kg_completeness_0.25
2024-08-04 15:35:50,698 - INFO - Using device: cuda
2024-08-04 15:35:50,698 - INFO - Using device: cuda
2024-08-05 22:11:03,550 - INFO - Created results directory: results\20240805_221103
2024-08-05 22:11:03,551 - INFO - Starting Ablation Study
2024-08-05 22:11:03,551 - INFO - Running experiment: kg_completeness_0.3
2024-08-05 22:11:03,625 - INFO - Using device: cuda
2024-08-05 22:11:03,625 - INFO - Using device: cuda
2024-08-06 22:20:37,519 - INFO - Created results directory: results\20240806_222037
2024-08-06 22:20:37,519 - INFO - Starting Ablation Study
2024-08-06 22:20:37,520 - INFO - Running experiment: kg_completeness_0.3
2024-08-06 22:20:37,609 - INFO - Using device: cuda
2024-08-06 22:20:37,609 - INFO - Using device: cuda
2024-08-11 22:21:13,448 - INFO - Created results directory: results\20240811_222113
2024-08-11 22:21:13,449 - INFO - Starting Ablation Study
2024-08-11 22:21:13,449 - INFO - Running experiment: kg_completeness_0.3
2024-08-11 22:21:13,517 - INFO - Using device: cuda
2024-08-11 22:21:13,517 - INFO - Using device: cuda
2024-08-12 00:46:59,716 - ERROR - An error occurred during the ablation study: Tried to step environment that needs reset
2024-08-12 00:46:59,716 - ERROR - An error occurred during the ablation study: Tried to step environment that needs reset
2024-08-12 00:46:59,742 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 282, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 157, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 226, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-12 00:46:59,742 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 282, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 157, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 226, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-12 07:19:23,630 - INFO - Created results directory: results\20240812_071923
2024-08-12 07:19:23,630 - INFO - Starting Ablation Study
2024-08-12 07:19:23,630 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 07:19:23,705 - INFO - Using device: cuda
2024-08-12 07:19:23,705 - INFO - Using device: cuda
2024-08-12 07:20:52,517 - INFO - Created results directory: results\20240812_072052
2024-08-12 07:20:52,518 - INFO - Starting Ablation Study
2024-08-12 07:20:52,518 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 07:20:52,599 - INFO - Using device: cuda
2024-08-12 07:20:52,599 - INFO - Using device: cuda
2024-08-12 07:21:45,744 - INFO - Created results directory: results\20240812_072145
2024-08-12 07:21:45,745 - INFO - Starting Ablation Study
2024-08-12 07:21:45,745 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 07:21:45,769 - INFO - Using device: cuda
2024-08-12 07:21:45,769 - INFO - Using device: cuda
2024-08-12 07:22:36,551 - INFO - Created results directory: results\20240812_072236
2024-08-12 07:22:36,551 - INFO - Starting Ablation Study
2024-08-12 07:22:36,552 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 07:22:36,606 - INFO - Using device: cuda
2024-08-12 07:22:36,606 - INFO - Using device: cuda
2024-08-12 07:23:23,326 - INFO - Created results directory: results\20240812_072323
2024-08-12 07:23:23,326 - INFO - Starting Ablation Study
2024-08-12 07:23:23,326 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 07:23:23,351 - INFO - Using device: cuda
2024-08-12 07:23:23,351 - INFO - Using device: cuda
2024-08-12 07:45:24,150 - INFO - Created results directory: results\20240812_074524
2024-08-12 07:45:24,150 - INFO - Starting Ablation Study
2024-08-12 07:45:24,150 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 07:45:24,180 - INFO - Using device: cuda
2024-08-12 07:45:24,180 - INFO - Using device: cuda
2024-08-12 07:45:31,899 - ERROR - An error occurred during the ablation study: 'SimulationManager' object has no attribute 'current_game_index'
2024-08-12 07:45:31,899 - ERROR - An error occurred during the ablation study: 'SimulationManager' object has no attribute 'current_game_index'
2024-08-12 07:45:31,903 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 287, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 162, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 231, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
  File "c:\Users\anton\Dev\ABM\training.py", line 68, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 208, in reset
    self.current_gm = self.simulation_manager.get_next_game_manager()
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 59, in get_next_game_manager
    self.current_game_index = (self.current_game_index + 1) % (next_curriculum - current_curriculum)
                               ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'current_game_index'

2024-08-12 07:45:31,903 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 287, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 162, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 231, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
  File "c:\Users\anton\Dev\ABM\training.py", line 68, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 208, in reset
    self.current_gm = self.simulation_manager.get_next_game_manager()
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 59, in get_next_game_manager
    self.current_game_index = (self.current_game_index + 1) % (next_curriculum - current_curriculum)
                               ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'current_game_index'

2024-08-12 07:46:12,798 - INFO - Created results directory: results\20240812_074612
2024-08-12 07:46:12,798 - INFO - Starting Ablation Study
2024-08-12 07:46:12,799 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 07:46:12,819 - INFO - Using device: cuda
2024-08-12 07:46:12,819 - INFO - Using device: cuda
2024-08-12 07:46:21,292 - ERROR - An error occurred during the ablation study: 'GameManager' object has no attribute 'target'
2024-08-12 07:46:21,292 - ERROR - An error occurred during the ablation study: 'GameManager' object has no attribute 'target'
2024-08-12 07:46:21,295 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 287, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 162, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 231, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
  File "c:\Users\anton\Dev\ABM\training.py", line 78, in train
    obs, reward, terminated, truncated, info = self.env.step(action)
                                               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 235, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 122, in _calculate_reward
    current_terrain_energy_requirement = self.current_gm.target.energy_req_grid[agent_pos]
                                         ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'GameManager' object has no attribute 'target'

2024-08-12 07:46:21,295 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 287, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 162, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 231, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
  File "c:\Users\anton\Dev\ABM\training.py", line 78, in train
    obs, reward, terminated, truncated, info = self.env.step(action)
                                               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 235, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 122, in _calculate_reward
    current_terrain_energy_requirement = self.current_gm.target.energy_req_grid[agent_pos]
                                         ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'GameManager' object has no attribute 'target'

2024-08-12 07:46:50,748 - INFO - Created results directory: results\20240812_074650
2024-08-12 07:46:50,749 - INFO - Starting Ablation Study
2024-08-12 07:46:50,749 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 07:46:50,775 - INFO - Using device: cuda
2024-08-12 07:46:50,775 - INFO - Using device: cuda
2024-08-12 09:09:19,473 - ERROR - An error occurred during the ablation study: Tried to step environment that needs reset
2024-08-12 09:09:19,473 - ERROR - An error occurred during the ablation study: Tried to step environment that needs reset
2024-08-12 09:09:19,490 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 287, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 162, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 231, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
  File "c:\Users\anton\Dev\ABM\training.py", line 84, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-12 09:09:19,490 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 287, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 162, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 231, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
  File "c:\Users\anton\Dev\ABM\training.py", line 84, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-12 18:52:11,749 - INFO - Created results directory: results\20240812_185211
2024-08-12 18:52:11,749 - INFO - Starting Ablation Study
2024-08-12 18:52:11,749 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 18:52:11,828 - INFO - Using device: cuda
2024-08-12 18:52:11,828 - INFO - Using device: cuda
2024-08-12 18:52:13,336 - ERROR - An error occurred during the ablation study: 'ModelTrainer' object has no attribute 'train'
2024-08-12 18:52:13,336 - ERROR - An error occurred during the ablation study: 'ModelTrainer' object has no attribute 'train'
2024-08-12 18:52:13,338 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 287, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 162, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 231, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
    ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ModelTrainer' object has no attribute 'train'

2024-08-12 18:52:13,338 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 287, in <module>
    ablation_study.run()
  File "c:\Users\anton\Dev\ABM\training.py", line 162, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 231, in run
    self.model_trainer.train(total_timesteps=self.config['total_timesteps'],
    ^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ModelTrainer' object has no attribute 'train'

2024-08-12 22:19:41,290 - INFO - Created results directory: results\20240812_221941
2024-08-12 22:19:41,291 - INFO - Starting Ablation Study
2024-08-12 22:19:41,291 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:19:41,374 - INFO - Using device: cuda
2024-08-12 22:19:41,374 - INFO - Using device: cuda
2024-08-12 22:22:34,254 - INFO - Created results directory: results\20240812_222234
2024-08-12 22:22:34,254 - INFO - Starting Ablation Study
2024-08-12 22:22:34,254 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:22:34,297 - INFO - Using device: cuda
2024-08-12 22:22:34,297 - INFO - Using device: cuda
2024-08-12 22:32:01,450 - INFO - Created results directory: results\20240812_223201
2024-08-12 22:32:01,451 - INFO - Starting Ablation Study
2024-08-12 22:32:01,451 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:32:01,470 - INFO - Using device: cuda
2024-08-12 22:32:01,470 - INFO - Using device: cuda
2024-08-12 22:32:35,696 - INFO - Created results directory: results\20240812_223235
2024-08-12 22:32:35,696 - INFO - Starting Ablation Study
2024-08-12 22:32:35,696 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:32:35,717 - INFO - Using device: cuda
2024-08-12 22:32:35,717 - INFO - Using device: cuda
2024-08-12 22:33:16,762 - INFO - Created results directory: results\20240812_223316
2024-08-12 22:33:16,762 - INFO - Starting Ablation Study
2024-08-12 22:33:16,762 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:33:16,784 - INFO - Using device: cuda
2024-08-12 22:33:16,784 - INFO - Using device: cuda
2024-08-12 22:52:51,016 - INFO - Created results directory: results\20240812_225251
2024-08-12 22:52:51,016 - INFO - Starting Ablation Study
2024-08-12 22:52:51,016 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:52:51,036 - INFO - Using device: cuda
2024-08-12 22:52:51,036 - INFO - Using device: cuda
2024-08-12 22:52:51,448 - ERROR - An error occurred during experiment kg_completeness_0.3: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:52:51,448 - ERROR - An error occurred during experiment kg_completeness_0.3: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:52:51,450 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:52:51,450 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:52:51,452 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 22:52:51,452 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 22:52:51,453 - INFO - Using device: cuda
2024-08-12 22:52:51,453 - INFO - Using device: cuda
2024-08-12 22:52:51,453 - INFO - Using device: cuda
2024-08-12 22:52:51,717 - ERROR - An error occurred during experiment kg_completeness_0.65: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:52:51,717 - ERROR - An error occurred during experiment kg_completeness_0.65: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:52:51,717 - ERROR - An error occurred during experiment kg_completeness_0.65: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:52:51,719 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:52:51,719 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:52:51,719 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:52:51,723 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:52:51,723 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:52:51,723 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:52:51,724 - INFO - Using device: cuda
2024-08-12 22:52:51,724 - INFO - Using device: cuda
2024-08-12 22:52:51,724 - INFO - Using device: cuda
2024-08-12 22:52:51,724 - INFO - Using device: cuda
2024-08-12 22:52:52,111 - ERROR - An error occurred during experiment kg_completeness_1.0: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:52:52,111 - ERROR - An error occurred during experiment kg_completeness_1.0: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:52:52,111 - ERROR - An error occurred during experiment kg_completeness_1.0: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:52:52,111 - ERROR - An error occurred during experiment kg_completeness_1.0: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:52:52,113 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:52:52,113 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:52:52,113 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:52:52,113 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:52:52,120 - INFO - Ablation study results saved to results\20240812_225251\ablation_study_results.json
2024-08-12 22:52:52,120 - INFO - Ablation study results saved to results\20240812_225251\ablation_study_results.json
2024-08-12 22:52:52,120 - INFO - Ablation study results saved to results\20240812_225251\ablation_study_results.json
2024-08-12 22:52:52,120 - INFO - Ablation study results saved to results\20240812_225251\ablation_study_results.json
2024-08-12 22:52:52,122 - INFO - Base configuration saved to results\20240812_225251\base_config.json
2024-08-12 22:52:52,122 - INFO - Base configuration saved to results\20240812_225251\base_config.json
2024-08-12 22:52:52,122 - INFO - Base configuration saved to results\20240812_225251\base_config.json
2024-08-12 22:52:52,122 - INFO - Base configuration saved to results\20240812_225251\base_config.json
2024-08-12 22:52:52,123 - INFO - Ablation Study completed
2024-08-12 22:52:52,123 - INFO - Ablation Study completed
2024-08-12 22:52:52,123 - INFO - Ablation Study completed
2024-08-12 22:52:52,123 - INFO - Ablation Study completed
2024-08-12 22:54:10,096 - INFO - Created results directory: results\20240812_225410
2024-08-12 22:54:10,096 - INFO - Starting Ablation Study
2024-08-12 22:54:10,097 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:54:10,119 - INFO - Using device: cuda
2024-08-12 22:54:10,119 - INFO - Using device: cuda
2024-08-12 22:54:10,518 - ERROR - An error occurred during experiment kg_completeness_0.3: 'list' object is not callable
2024-08-12 22:54:10,518 - ERROR - An error occurred during experiment kg_completeness_0.3: 'list' object is not callable
2024-08-12 22:54:10,520 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager()
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 106, in set_current_game_manager
    self.current_gm = self.simulation_manager.game_managers(self.current_game_index)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'list' object is not callable

2024-08-12 22:54:10,520 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager()
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 106, in set_current_game_manager
    self.current_gm = self.simulation_manager.game_managers(self.current_game_index)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'list' object is not callable

2024-08-12 22:54:10,522 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 22:54:10,522 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 22:54:10,523 - INFO - Using device: cuda
2024-08-12 22:54:10,523 - INFO - Using device: cuda
2024-08-12 22:54:10,523 - INFO - Using device: cuda
2024-08-12 22:54:10,772 - ERROR - An error occurred during experiment kg_completeness_0.65: 'list' object is not callable
2024-08-12 22:54:10,772 - ERROR - An error occurred during experiment kg_completeness_0.65: 'list' object is not callable
2024-08-12 22:54:10,772 - ERROR - An error occurred during experiment kg_completeness_0.65: 'list' object is not callable
2024-08-12 22:54:10,774 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager()
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 106, in set_current_game_manager
    self.current_gm = self.simulation_manager.game_managers(self.current_game_index)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'list' object is not callable

2024-08-12 22:54:10,774 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager()
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 106, in set_current_game_manager
    self.current_gm = self.simulation_manager.game_managers(self.current_game_index)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'list' object is not callable

2024-08-12 22:54:10,774 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager()
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 106, in set_current_game_manager
    self.current_gm = self.simulation_manager.game_managers(self.current_game_index)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'list' object is not callable

2024-08-12 22:54:10,779 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:54:10,779 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:54:10,779 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:54:10,780 - INFO - Using device: cuda
2024-08-12 22:54:10,780 - INFO - Using device: cuda
2024-08-12 22:54:10,780 - INFO - Using device: cuda
2024-08-12 22:54:10,780 - INFO - Using device: cuda
2024-08-12 22:54:11,141 - ERROR - An error occurred during experiment kg_completeness_1.0: 'list' object is not callable
2024-08-12 22:54:11,141 - ERROR - An error occurred during experiment kg_completeness_1.0: 'list' object is not callable
2024-08-12 22:54:11,141 - ERROR - An error occurred during experiment kg_completeness_1.0: 'list' object is not callable
2024-08-12 22:54:11,141 - ERROR - An error occurred during experiment kg_completeness_1.0: 'list' object is not callable
2024-08-12 22:54:11,143 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager()
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 106, in set_current_game_manager
    self.current_gm = self.simulation_manager.game_managers(self.current_game_index)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'list' object is not callable

2024-08-12 22:54:11,143 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager()
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 106, in set_current_game_manager
    self.current_gm = self.simulation_manager.game_managers(self.current_game_index)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'list' object is not callable

2024-08-12 22:54:11,143 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager()
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 106, in set_current_game_manager
    self.current_gm = self.simulation_manager.game_managers(self.current_game_index)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'list' object is not callable

2024-08-12 22:54:11,143 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 159, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 209, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 65, in __init__
    self.set_current_game_manager()
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 106, in set_current_game_manager
    self.current_gm = self.simulation_manager.game_managers(self.current_game_index)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'list' object is not callable

2024-08-12 22:54:11,150 - INFO - Ablation study results saved to results\20240812_225410\ablation_study_results.json
2024-08-12 22:54:11,150 - INFO - Ablation study results saved to results\20240812_225410\ablation_study_results.json
2024-08-12 22:54:11,150 - INFO - Ablation study results saved to results\20240812_225410\ablation_study_results.json
2024-08-12 22:54:11,150 - INFO - Ablation study results saved to results\20240812_225410\ablation_study_results.json
2024-08-12 22:54:11,152 - INFO - Base configuration saved to results\20240812_225410\base_config.json
2024-08-12 22:54:11,152 - INFO - Base configuration saved to results\20240812_225410\base_config.json
2024-08-12 22:54:11,152 - INFO - Base configuration saved to results\20240812_225410\base_config.json
2024-08-12 22:54:11,152 - INFO - Base configuration saved to results\20240812_225410\base_config.json
2024-08-12 22:54:11,154 - INFO - Ablation Study completed
2024-08-12 22:54:11,154 - INFO - Ablation Study completed
2024-08-12 22:54:11,154 - INFO - Ablation Study completed
2024-08-12 22:54:11,154 - INFO - Ablation Study completed
2024-08-12 22:54:52,343 - INFO - Created results directory: results\20240812_225452
2024-08-12 22:54:52,343 - INFO - Starting Ablation Study
2024-08-12 22:54:52,343 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:54:52,361 - INFO - Using device: cuda
2024-08-12 22:54:52,361 - INFO - Using device: cuda
2024-08-12 22:54:54,137 - ERROR - An error occurred during experiment kg_completeness_0.3: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:54:54,137 - ERROR - An error occurred during experiment kg_completeness_0.3: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:54:54,140 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 66, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 211, in reset
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:54:54,140 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 66, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 211, in reset
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:54:54,144 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 22:54:54,144 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 22:54:54,145 - INFO - Using device: cuda
2024-08-12 22:54:54,145 - INFO - Using device: cuda
2024-08-12 22:54:54,145 - INFO - Using device: cuda
2024-08-12 22:54:56,131 - ERROR - An error occurred during experiment kg_completeness_0.65: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:54:56,131 - ERROR - An error occurred during experiment kg_completeness_0.65: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:54:56,131 - ERROR - An error occurred during experiment kg_completeness_0.65: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:54:56,134 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 66, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 211, in reset
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:54:56,134 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 66, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 211, in reset
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:54:56,134 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 66, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 211, in reset
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:54:56,140 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:54:56,140 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:54:56,140 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:54:56,144 - INFO - Using device: cuda
2024-08-12 22:54:56,144 - INFO - Using device: cuda
2024-08-12 22:54:56,144 - INFO - Using device: cuda
2024-08-12 22:54:56,144 - INFO - Using device: cuda
2024-08-12 22:54:58,241 - ERROR - An error occurred during experiment kg_completeness_1.0: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:54:58,241 - ERROR - An error occurred during experiment kg_completeness_1.0: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:54:58,241 - ERROR - An error occurred during experiment kg_completeness_1.0: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:54:58,241 - ERROR - An error occurred during experiment kg_completeness_1.0: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-12 22:54:58,245 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 66, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 211, in reset
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:54:58,245 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 66, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 211, in reset
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:54:58,245 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 66, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 211, in reset
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:54:58,245 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 66, in train
    obs, _ = self.env.reset()
             ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 83, in reset
    return self.env.reset(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 211, in reset
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-12 22:54:58,256 - INFO - Ablation study results saved to results\20240812_225452\ablation_study_results.json
2024-08-12 22:54:58,256 - INFO - Ablation study results saved to results\20240812_225452\ablation_study_results.json
2024-08-12 22:54:58,256 - INFO - Ablation study results saved to results\20240812_225452\ablation_study_results.json
2024-08-12 22:54:58,256 - INFO - Ablation study results saved to results\20240812_225452\ablation_study_results.json
2024-08-12 22:54:58,259 - INFO - Base configuration saved to results\20240812_225452\base_config.json
2024-08-12 22:54:58,259 - INFO - Base configuration saved to results\20240812_225452\base_config.json
2024-08-12 22:54:58,259 - INFO - Base configuration saved to results\20240812_225452\base_config.json
2024-08-12 22:54:58,259 - INFO - Base configuration saved to results\20240812_225452\base_config.json
2024-08-12 22:54:58,261 - INFO - Ablation Study completed
2024-08-12 22:54:58,261 - INFO - Ablation Study completed
2024-08-12 22:54:58,261 - INFO - Ablation Study completed
2024-08-12 22:54:58,261 - INFO - Ablation Study completed
2024-08-12 22:55:36,767 - INFO - Created results directory: results\20240812_225536
2024-08-12 22:55:36,767 - INFO - Starting Ablation Study
2024-08-12 22:55:36,768 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:55:36,785 - INFO - Using device: cuda
2024-08-12 22:55:36,785 - INFO - Using device: cuda
2024-08-12 22:56:00,649 - ERROR - An error occurred during experiment kg_completeness_0.3: 'SimulationManager' object has no attribute 'logger'
2024-08-12 22:56:00,649 - ERROR - An error occurred during experiment kg_completeness_0.3: 'SimulationManager' object has no attribute 'logger'
2024-08-12 22:56:00,653 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 250, in step
    if self.simulation_manager.should_advance_curriculum():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 83, in should_advance_curriculum
    self.logger.info(f"Curriculum advancement check: Performance: {avg_performance:.2f}, "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 22:56:00,653 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 250, in step
    if self.simulation_manager.should_advance_curriculum():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 83, in should_advance_curriculum
    self.logger.info(f"Curriculum advancement check: Performance: {avg_performance:.2f}, "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 22:56:00,664 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 22:56:00,664 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 22:56:00,666 - INFO - Using device: cuda
2024-08-12 22:56:00,666 - INFO - Using device: cuda
2024-08-12 22:56:00,666 - INFO - Using device: cuda
2024-08-12 22:56:27,445 - ERROR - An error occurred during experiment kg_completeness_0.65: 'SimulationManager' object has no attribute 'logger'
2024-08-12 22:56:27,445 - ERROR - An error occurred during experiment kg_completeness_0.65: 'SimulationManager' object has no attribute 'logger'
2024-08-12 22:56:27,445 - ERROR - An error occurred during experiment kg_completeness_0.65: 'SimulationManager' object has no attribute 'logger'
2024-08-12 22:56:27,449 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 250, in step
    if self.simulation_manager.should_advance_curriculum():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 83, in should_advance_curriculum
    self.logger.info(f"Curriculum advancement check: Performance: {avg_performance:.2f}, "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 22:56:27,449 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 250, in step
    if self.simulation_manager.should_advance_curriculum():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 83, in should_advance_curriculum
    self.logger.info(f"Curriculum advancement check: Performance: {avg_performance:.2f}, "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 22:56:27,449 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 250, in step
    if self.simulation_manager.should_advance_curriculum():
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 83, in should_advance_curriculum
    self.logger.info(f"Curriculum advancement check: Performance: {avg_performance:.2f}, "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 22:56:27,463 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:56:27,463 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:56:27,463 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 22:56:27,465 - INFO - Using device: cuda
2024-08-12 22:56:27,465 - INFO - Using device: cuda
2024-08-12 22:56:27,465 - INFO - Using device: cuda
2024-08-12 22:56:27,465 - INFO - Using device: cuda
2024-08-12 22:57:02,738 - INFO - Created results directory: results\20240812_225702
2024-08-12 22:57:02,738 - INFO - Starting Ablation Study
2024-08-12 22:57:02,738 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 22:57:02,755 - INFO - Using device: cuda
2024-08-12 22:57:02,755 - INFO - Using device: cuda
2024-08-12 22:57:27,575 - INFO - Curriculum advancement check: Performance: 12252.67, Success rate: 0.00, Plateau counter: 4
2024-08-12 22:57:27,575 - INFO - Curriculum advancement check: Performance: 12252.67, Success rate: 0.00, Plateau counter: 4
2024-08-12 22:57:30,842 - INFO - Curriculum advancement check: Performance: 12207.18, Success rate: 0.00, Plateau counter: 5
2024-08-12 22:57:30,842 - INFO - Curriculum advancement check: Performance: 12207.18, Success rate: 0.00, Plateau counter: 5
2024-08-12 22:57:40,527 - INFO - Curriculum advancement check: Performance: 11995.66, Success rate: 0.00, Plateau counter: 6
2024-08-12 22:57:40,527 - INFO - Curriculum advancement check: Performance: 11995.66, Success rate: 0.00, Plateau counter: 6
2024-08-12 22:57:43,184 - INFO - Curriculum advancement check: Performance: 11775.88, Success rate: 0.00, Plateau counter: 7
2024-08-12 22:57:43,184 - INFO - Curriculum advancement check: Performance: 11775.88, Success rate: 0.00, Plateau counter: 7
2024-08-12 22:57:49,907 - INFO - Curriculum advancement check: Performance: 13132.80, Success rate: 0.00, Plateau counter: 0
2024-08-12 22:57:49,907 - INFO - Curriculum advancement check: Performance: 13132.80, Success rate: 0.00, Plateau counter: 0
2024-08-12 22:58:00,364 - INFO - Curriculum advancement check: Performance: 13365.84, Success rate: 0.00, Plateau counter: 1
2024-08-12 22:58:00,364 - INFO - Curriculum advancement check: Performance: 13365.84, Success rate: 0.00, Plateau counter: 1
2024-08-12 22:58:05,398 - INFO - Curriculum advancement check: Performance: 13921.42, Success rate: 0.00, Plateau counter: 2
2024-08-12 22:58:05,398 - INFO - Curriculum advancement check: Performance: 13921.42, Success rate: 0.00, Plateau counter: 2
2024-08-12 22:58:16,682 - INFO - Curriculum advancement check: Performance: 14235.41, Success rate: 0.00, Plateau counter: 3
2024-08-12 22:58:16,682 - INFO - Curriculum advancement check: Performance: 14235.41, Success rate: 0.00, Plateau counter: 3
2024-08-12 22:58:20,064 - INFO - Curriculum advancement check: Performance: 14260.02, Success rate: 0.00, Plateau counter: 4
2024-08-12 22:58:20,064 - INFO - Curriculum advancement check: Performance: 14260.02, Success rate: 0.00, Plateau counter: 4
2024-08-12 22:58:34,704 - INFO - Curriculum advancement check: Performance: 10223.54, Success rate: 0.00, Plateau counter: 4
2024-08-12 22:58:34,704 - INFO - Curriculum advancement check: Performance: 10223.54, Success rate: 0.00, Plateau counter: 4
2024-08-12 22:58:35,690 - INFO - Curriculum advancement check: Performance: 14633.19, Success rate: 0.00, Plateau counter: 5
2024-08-12 22:58:35,690 - INFO - Curriculum advancement check: Performance: 14633.19, Success rate: 0.00, Plateau counter: 5
2024-08-12 22:58:47,605 - INFO - Curriculum advancement check: Performance: 14991.27, Success rate: 0.00, Plateau counter: 6
2024-08-12 22:58:47,605 - INFO - Curriculum advancement check: Performance: 14991.27, Success rate: 0.00, Plateau counter: 6
2024-08-12 22:58:50,195 - INFO - Curriculum advancement check: Performance: 14694.10, Success rate: 0.00, Plateau counter: 7
2024-08-12 22:58:50,195 - INFO - Curriculum advancement check: Performance: 14694.10, Success rate: 0.00, Plateau counter: 7
2024-08-12 22:58:53,125 - INFO - Curriculum advancement check: Performance: 14445.23, Success rate: 0.00, Plateau counter: 8
2024-08-12 22:58:53,125 - INFO - Curriculum advancement check: Performance: 14445.23, Success rate: 0.00, Plateau counter: 8
2024-08-12 22:59:02,776 - INFO - Curriculum advancement check: Performance: 14229.68, Success rate: 0.00, Plateau counter: 9
2024-08-12 22:59:02,776 - INFO - Curriculum advancement check: Performance: 14229.68, Success rate: 0.00, Plateau counter: 9
2024-08-12 22:59:05,524 - INFO - Curriculum advancement check: Performance: 14033.65, Success rate: 0.00, Plateau counter: 10
2024-08-12 22:59:05,524 - INFO - Curriculum advancement check: Performance: 14033.65, Success rate: 0.00, Plateau counter: 10
2024-08-12 22:59:10,110 - INFO - Curriculum advancement check: Performance: 14201.58, Success rate: 0.00, Plateau counter: 11
2024-08-12 22:59:10,110 - INFO - Curriculum advancement check: Performance: 14201.58, Success rate: 0.00, Plateau counter: 11
2024-08-12 22:59:19,530 - INFO - Curriculum advancement check: Performance: 14079.45, Success rate: 0.00, Plateau counter: 12
2024-08-12 22:59:19,530 - INFO - Curriculum advancement check: Performance: 14079.45, Success rate: 0.00, Plateau counter: 12
2024-08-12 22:59:27,006 - INFO - Curriculum advancement check: Performance: 14723.25, Success rate: 0.00, Plateau counter: 0
2024-08-12 22:59:27,006 - INFO - Curriculum advancement check: Performance: 14723.25, Success rate: 0.00, Plateau counter: 0
2024-08-12 22:59:36,505 - INFO - Curriculum advancement check: Performance: 14543.26, Success rate: 0.00, Plateau counter: 1
2024-08-12 22:59:36,505 - INFO - Curriculum advancement check: Performance: 14543.26, Success rate: 0.00, Plateau counter: 1
2024-08-12 22:59:41,518 - INFO - Curriculum advancement check: Performance: 14786.72, Success rate: 0.00, Plateau counter: 2
2024-08-12 22:59:41,518 - INFO - Curriculum advancement check: Performance: 14786.72, Success rate: 0.00, Plateau counter: 2
2024-08-12 22:59:44,321 - INFO - Curriculum advancement check: Performance: 14632.49, Success rate: 0.00, Plateau counter: 3
2024-08-12 22:59:44,321 - INFO - Curriculum advancement check: Performance: 14632.49, Success rate: 0.00, Plateau counter: 3
2024-08-12 22:59:53,674 - INFO - Curriculum advancement check: Performance: 14468.08, Success rate: 0.00, Plateau counter: 4
2024-08-12 22:59:53,674 - INFO - Curriculum advancement check: Performance: 14468.08, Success rate: 0.00, Plateau counter: 4
2024-08-12 22:59:56,375 - INFO - Curriculum advancement check: Performance: 14315.13, Success rate: 0.00, Plateau counter: 5
2024-08-12 22:59:56,375 - INFO - Curriculum advancement check: Performance: 14315.13, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:00:04,776 - INFO - Curriculum advancement check: Performance: 10223.33, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:00:04,776 - INFO - Curriculum advancement check: Performance: 10223.33, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:00:07,369 - INFO - Curriculum advancement check: Performance: 10223.18, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:00:07,369 - INFO - Curriculum advancement check: Performance: 10223.18, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:00:10,039 - INFO - Curriculum advancement check: Performance: 10223.42, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:00:10,039 - INFO - Curriculum advancement check: Performance: 10223.42, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:00:12,586 - INFO - Curriculum advancement check: Performance: 10223.29, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:00:12,586 - INFO - Curriculum advancement check: Performance: 10223.29, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:00:15,058 - INFO - Curriculum advancement check: Performance: 10223.40, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:00:15,058 - INFO - Curriculum advancement check: Performance: 10223.40, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:00:15,184 - INFO - Curriculum advancement check: Performance: 14529.33, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:00:15,184 - INFO - Curriculum advancement check: Performance: 14529.33, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:00:25,181 - INFO - Curriculum advancement check: Performance: 14479.42, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:00:25,181 - INFO - Curriculum advancement check: Performance: 14479.42, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:00:28,263 - INFO - Curriculum advancement check: Performance: 14361.77, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:00:28,263 - INFO - Curriculum advancement check: Performance: 14361.77, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:00:31,319 - INFO - Curriculum advancement check: Performance: 14274.47, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:00:31,319 - INFO - Curriculum advancement check: Performance: 14274.47, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:00:34,525 - INFO - Curriculum advancement check: Performance: 14159.97, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:00:34,525 - INFO - Curriculum advancement check: Performance: 14159.97, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:00:44,811 - INFO - Curriculum advancement check: Performance: 14066.23, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:00:44,811 - INFO - Curriculum advancement check: Performance: 14066.23, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:00:51,526 - INFO - Curriculum advancement check: Performance: 14316.69, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:00:51,526 - INFO - Curriculum advancement check: Performance: 14316.69, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:00:54,658 - INFO - Curriculum advancement check: Performance: 14205.48, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:00:54,658 - INFO - Curriculum advancement check: Performance: 14205.48, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:01:06,819 - INFO - Curriculum advancement check: Performance: 14355.64, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:01:06,819 - INFO - Curriculum advancement check: Performance: 14355.64, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:01:10,100 - INFO - Curriculum advancement check: Performance: 14278.86, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:01:10,100 - INFO - Curriculum advancement check: Performance: 14278.86, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:01:13,231 - INFO - Curriculum advancement check: Performance: 14180.47, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:01:13,231 - INFO - Curriculum advancement check: Performance: 14180.47, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:01:22,404 - INFO - Curriculum advancement check: Performance: 14079.17, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:01:22,404 - INFO - Curriculum advancement check: Performance: 14079.17, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:01:25,381 - INFO - Curriculum advancement check: Performance: 13993.78, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:01:25,381 - INFO - Curriculum advancement check: Performance: 13993.78, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:01:28,177 - INFO - Curriculum advancement check: Performance: 13902.07, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:01:28,177 - INFO - Curriculum advancement check: Performance: 13902.07, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:01:31,809 - INFO - Curriculum advancement check: Performance: 13874.00, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:01:31,809 - INFO - Curriculum advancement check: Performance: 13874.00, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:01:41,094 - INFO - Curriculum advancement check: Performance: 13790.41, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:01:41,094 - INFO - Curriculum advancement check: Performance: 13790.41, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:01:43,809 - INFO - Curriculum advancement check: Performance: 13717.97, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:01:43,809 - INFO - Curriculum advancement check: Performance: 13717.97, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:01:48,625 - INFO - Curriculum advancement check: Performance: 10223.30, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:01:48,625 - INFO - Curriculum advancement check: Performance: 10223.30, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:01:51,239 - INFO - Curriculum advancement check: Performance: 10223.23, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:01:51,239 - INFO - Curriculum advancement check: Performance: 10223.23, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:01:53,742 - INFO - Curriculum advancement check: Performance: 10223.16, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:01:53,742 - INFO - Curriculum advancement check: Performance: 10223.16, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:01:56,590 - INFO - Curriculum advancement check: Performance: 10223.26, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:01:56,590 - INFO - Curriculum advancement check: Performance: 10223.26, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:01:59,454 - INFO - Curriculum advancement check: Performance: 10223.20, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:01:59,454 - INFO - Curriculum advancement check: Performance: 10223.20, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:02:00,527 - INFO - Curriculum advancement check: Performance: 13640.62, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:02:00,527 - INFO - Curriculum advancement check: Performance: 13640.62, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:02:03,633 - INFO - Curriculum advancement check: Performance: 13568.91, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:02:03,633 - INFO - Curriculum advancement check: Performance: 13568.91, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:02:13,777 - INFO - Curriculum advancement check: Performance: 13578.31, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:02:13,777 - INFO - Curriculum advancement check: Performance: 13578.31, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:02:18,768 - INFO - Curriculum advancement check: Performance: 13668.45, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:02:18,768 - INFO - Curriculum advancement check: Performance: 13668.45, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:02:21,781 - INFO - Curriculum advancement check: Performance: 13598.50, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:02:21,781 - INFO - Curriculum advancement check: Performance: 13598.50, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:02:31,192 - INFO - Curriculum advancement check: Performance: 13531.32, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:02:31,192 - INFO - Curriculum advancement check: Performance: 13531.32, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:02:34,319 - INFO - Curriculum advancement check: Performance: 13473.59, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:02:34,319 - INFO - Curriculum advancement check: Performance: 13473.59, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:02:37,245 - INFO - Curriculum advancement check: Performance: 13411.47, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:02:37,245 - INFO - Curriculum advancement check: Performance: 13411.47, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:02:40,297 - INFO - Curriculum advancement check: Performance: 13368.55, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:02:40,297 - INFO - Curriculum advancement check: Performance: 13368.55, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:02:49,902 - INFO - Curriculum advancement check: Performance: 13310.35, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:02:49,902 - INFO - Curriculum advancement check: Performance: 13310.35, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:02:52,952 - INFO - Curriculum advancement check: Performance: 13257.71, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:02:52,952 - INFO - Curriculum advancement check: Performance: 13257.71, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:02:55,824 - INFO - Curriculum advancement check: Performance: 13203.81, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:02:55,824 - INFO - Curriculum advancement check: Performance: 13203.81, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:03:06,008 - INFO - Curriculum advancement check: Performance: 13171.66, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:03:06,008 - INFO - Curriculum advancement check: Performance: 13171.66, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:03:09,151 - INFO - Curriculum advancement check: Performance: 13131.25, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:03:09,151 - INFO - Curriculum advancement check: Performance: 13131.25, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:03:12,515 - INFO - Curriculum advancement check: Performance: 13093.53, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:03:12,515 - INFO - Curriculum advancement check: Performance: 13093.53, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:03:15,508 - INFO - Curriculum advancement check: Performance: 13045.85, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:03:15,508 - INFO - Curriculum advancement check: Performance: 13045.85, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:03:27,281 - INFO - Curriculum advancement check: Performance: 13144.33, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:03:27,281 - INFO - Curriculum advancement check: Performance: 13144.33, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:03:30,363 - INFO - Curriculum advancement check: Performance: 13098.43, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:03:30,363 - INFO - Curriculum advancement check: Performance: 13098.43, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:03:34,231 - INFO - Curriculum advancement check: Performance: 10222.24, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:03:34,231 - INFO - Curriculum advancement check: Performance: 10222.24, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:03:36,696 - INFO - Curriculum advancement check: Performance: 10222.24, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:03:36,696 - INFO - Curriculum advancement check: Performance: 10222.24, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:03:39,381 - INFO - Curriculum advancement check: Performance: 10221.91, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:03:39,381 - INFO - Curriculum advancement check: Performance: 10221.91, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:03:42,636 - INFO - Curriculum advancement check: Performance: 10223.87, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:03:42,636 - INFO - Curriculum advancement check: Performance: 10223.87, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:03:45,444 - INFO - Curriculum advancement check: Performance: 10223.79, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:03:45,444 - INFO - Curriculum advancement check: Performance: 10223.79, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:03:48,099 - INFO - Curriculum advancement check: Performance: 13054.29, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:03:48,099 - INFO - Curriculum advancement check: Performance: 13054.29, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:03:51,307 - INFO - Curriculum advancement check: Performance: 13010.19, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:03:51,307 - INFO - Curriculum advancement check: Performance: 13010.19, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:04:01,576 - INFO - Curriculum advancement check: Performance: 12980.41, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:04:01,576 - INFO - Curriculum advancement check: Performance: 12980.41, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:04:04,707 - INFO - Curriculum advancement check: Performance: 12940.97, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:04:04,707 - INFO - Curriculum advancement check: Performance: 12940.97, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:04:08,242 - INFO - Curriculum advancement check: Performance: 12910.34, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:04:08,242 - INFO - Curriculum advancement check: Performance: 12910.34, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:04:11,332 - INFO - Curriculum advancement check: Performance: 12870.92, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:04:11,332 - INFO - Curriculum advancement check: Performance: 12870.92, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:04:21,412 - INFO - Curriculum advancement check: Performance: 12853.94, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:04:21,412 - INFO - Curriculum advancement check: Performance: 12853.94, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:04:24,796 - INFO - Curriculum advancement check: Performance: 12816.60, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:04:24,796 - INFO - Curriculum advancement check: Performance: 12816.60, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:04:31,419 - INFO - Curriculum advancement check: Performance: 12923.57, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:04:31,419 - INFO - Curriculum advancement check: Performance: 12923.57, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:04:45,005 - INFO - Curriculum advancement check: Performance: 13073.56, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:04:45,005 - INFO - Curriculum advancement check: Performance: 13073.56, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:04:45,006 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:04:45,006 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:04:45,007 - ERROR - An error occurred during experiment kg_completeness_0.3: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:04:45,007 - ERROR - An error occurred during experiment kg_completeness_0.3: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:04:45,011 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 251, in step
    self.simulation_manager.add_episode_performance(self.total_reward, success)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:04:45,011 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 251, in step
    self.simulation_manager.add_episode_performance(self.total_reward, success)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:04:45,018 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 23:04:45,018 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 23:04:45,021 - INFO - Using device: cuda
2024-08-12 23:04:45,021 - INFO - Using device: cuda
2024-08-12 23:04:45,021 - INFO - Using device: cuda
2024-08-12 23:05:13,083 - INFO - Curriculum advancement check: Performance: 13174.81, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:05:13,083 - INFO - Curriculum advancement check: Performance: 13174.81, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:05:13,083 - INFO - Curriculum advancement check: Performance: 13174.81, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:05:25,753 - INFO - Curriculum advancement check: Performance: 14331.35, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:05:25,753 - INFO - Curriculum advancement check: Performance: 14331.35, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:05:25,753 - INFO - Curriculum advancement check: Performance: 14331.35, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:05:28,486 - INFO - Curriculum advancement check: Performance: 13807.89, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:05:28,486 - INFO - Curriculum advancement check: Performance: 13807.89, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:05:28,486 - INFO - Curriculum advancement check: Performance: 13807.89, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:05:31,251 - INFO - Curriculum advancement check: Performance: 13361.35, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:05:31,251 - INFO - Curriculum advancement check: Performance: 13361.35, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:05:31,251 - INFO - Curriculum advancement check: Performance: 13361.35, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:05:44,124 - INFO - Curriculum advancement check: Performance: 14311.89, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:05:44,124 - INFO - Curriculum advancement check: Performance: 14311.89, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:05:44,124 - INFO - Curriculum advancement check: Performance: 14311.89, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:05:47,741 - INFO - Curriculum advancement check: Performance: 14183.93, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:05:47,741 - INFO - Curriculum advancement check: Performance: 14183.93, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:05:47,741 - INFO - Curriculum advancement check: Performance: 14183.93, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:05:53,971 - INFO - Curriculum advancement check: Performance: 14919.44, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:05:53,971 - INFO - Curriculum advancement check: Performance: 14919.44, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:05:53,971 - INFO - Curriculum advancement check: Performance: 14919.44, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:06:03,200 - INFO - Curriculum advancement check: Performance: 14529.66, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:06:03,200 - INFO - Curriculum advancement check: Performance: 14529.66, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:06:03,200 - INFO - Curriculum advancement check: Performance: 14529.66, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:06:06,110 - INFO - Curriculum advancement check: Performance: 14249.37, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:06:06,110 - INFO - Curriculum advancement check: Performance: 14249.37, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:06:06,110 - INFO - Curriculum advancement check: Performance: 14249.37, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:06:09,588 - INFO - Curriculum advancement check: Performance: 14136.74, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:06:09,588 - INFO - Curriculum advancement check: Performance: 14136.74, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:06:09,588 - INFO - Curriculum advancement check: Performance: 14136.74, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:06:22,089 - INFO - Curriculum advancement check: Performance: 10223.54, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:06:22,089 - INFO - Curriculum advancement check: Performance: 10223.54, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:06:22,089 - INFO - Curriculum advancement check: Performance: 10223.54, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:06:30,874 - INFO - Curriculum advancement check: Performance: 13974.30, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:06:30,874 - INFO - Curriculum advancement check: Performance: 13974.30, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:06:30,874 - INFO - Curriculum advancement check: Performance: 13974.30, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:06:35,911 - INFO - Curriculum advancement check: Performance: 14355.49, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:06:35,911 - INFO - Curriculum advancement check: Performance: 14355.49, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:06:35,911 - INFO - Curriculum advancement check: Performance: 14355.49, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:06:38,810 - INFO - Curriculum advancement check: Performance: 14120.72, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:06:38,810 - INFO - Curriculum advancement check: Performance: 14120.72, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:06:38,810 - INFO - Curriculum advancement check: Performance: 14120.72, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:06:48,367 - INFO - Curriculum advancement check: Performance: 13910.79, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:06:48,367 - INFO - Curriculum advancement check: Performance: 13910.79, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:06:48,367 - INFO - Curriculum advancement check: Performance: 13910.79, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:06:50,926 - INFO - Curriculum advancement check: Performance: 13717.65, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:06:50,926 - INFO - Curriculum advancement check: Performance: 13717.65, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:06:50,926 - INFO - Curriculum advancement check: Performance: 13717.65, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:06:53,685 - INFO - Curriculum advancement check: Performance: 13543.91, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:06:53,685 - INFO - Curriculum advancement check: Performance: 13543.91, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:06:53,685 - INFO - Curriculum advancement check: Performance: 13543.91, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:06:56,758 - INFO - Curriculum advancement check: Performance: 13414.75, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:06:56,758 - INFO - Curriculum advancement check: Performance: 13414.75, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:06:56,758 - INFO - Curriculum advancement check: Performance: 13414.75, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:07:06,551 - INFO - Curriculum advancement check: Performance: 13282.50, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:07:06,551 - INFO - Curriculum advancement check: Performance: 13282.50, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:07:06,551 - INFO - Curriculum advancement check: Performance: 13282.50, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:07:09,332 - INFO - Curriculum advancement check: Performance: 13173.10, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:07:09,332 - INFO - Curriculum advancement check: Performance: 13173.10, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:07:09,332 - INFO - Curriculum advancement check: Performance: 13173.10, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:07:12,305 - INFO - Curriculum advancement check: Performance: 13072.18, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:07:12,305 - INFO - Curriculum advancement check: Performance: 13072.18, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:07:12,305 - INFO - Curriculum advancement check: Performance: 13072.18, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:07:15,791 - INFO - Curriculum advancement check: Performance: 13050.28, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:07:15,791 - INFO - Curriculum advancement check: Performance: 13050.28, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:07:15,791 - INFO - Curriculum advancement check: Performance: 13050.28, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:07:25,310 - INFO - Curriculum advancement check: Performance: 12943.88, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:07:25,310 - INFO - Curriculum advancement check: Performance: 12943.88, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:07:25,310 - INFO - Curriculum advancement check: Performance: 12943.88, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:07:28,382 - INFO - Curriculum advancement check: Performance: 12893.18, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:07:28,382 - INFO - Curriculum advancement check: Performance: 12893.18, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:07:28,382 - INFO - Curriculum advancement check: Performance: 12893.18, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:07:31,409 - INFO - Curriculum advancement check: Performance: 12808.44, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:07:31,409 - INFO - Curriculum advancement check: Performance: 12808.44, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:07:31,409 - INFO - Curriculum advancement check: Performance: 12808.44, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:07:34,875 - INFO - Curriculum advancement check: Performance: 12786.90, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:07:34,875 - INFO - Curriculum advancement check: Performance: 12786.90, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:07:34,875 - INFO - Curriculum advancement check: Performance: 12786.90, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:07:44,399 - INFO - Curriculum advancement check: Performance: 12718.24, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:07:44,399 - INFO - Curriculum advancement check: Performance: 12718.24, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:07:44,399 - INFO - Curriculum advancement check: Performance: 12718.24, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:07:47,111 - INFO - Curriculum advancement check: Performance: 12638.35, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:07:47,111 - INFO - Curriculum advancement check: Performance: 12638.35, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:07:47,111 - INFO - Curriculum advancement check: Performance: 12638.35, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:07:50,819 - INFO - Curriculum advancement check: Performance: 12659.50, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:07:50,819 - INFO - Curriculum advancement check: Performance: 12659.50, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:07:50,819 - INFO - Curriculum advancement check: Performance: 12659.50, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:07:54,466 - INFO - Curriculum advancement check: Performance: 10223.33, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:07:54,466 - INFO - Curriculum advancement check: Performance: 10223.33, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:07:54,466 - INFO - Curriculum advancement check: Performance: 10223.33, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:07:57,773 - INFO - Curriculum advancement check: Performance: 10223.18, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:07:57,773 - INFO - Curriculum advancement check: Performance: 10223.18, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:07:57,773 - INFO - Curriculum advancement check: Performance: 10223.18, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:08:00,374 - INFO - Curriculum advancement check: Performance: 10223.33, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:08:00,374 - INFO - Curriculum advancement check: Performance: 10223.33, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:08:00,374 - INFO - Curriculum advancement check: Performance: 10223.33, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:08:03,376 - INFO - Curriculum advancement check: Performance: 10222.52, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:08:03,376 - INFO - Curriculum advancement check: Performance: 10222.52, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:08:03,376 - INFO - Curriculum advancement check: Performance: 10222.52, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:08:06,016 - INFO - Curriculum advancement check: Performance: 10222.50, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:08:06,016 - INFO - Curriculum advancement check: Performance: 10222.50, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:08:06,016 - INFO - Curriculum advancement check: Performance: 10222.50, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:08:15,892 - INFO - Curriculum advancement check: Performance: 12710.96, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:08:15,892 - INFO - Curriculum advancement check: Performance: 12710.96, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:08:15,892 - INFO - Curriculum advancement check: Performance: 12710.96, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:08:19,439 - INFO - Curriculum advancement check: Performance: 12739.37, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:08:19,439 - INFO - Curriculum advancement check: Performance: 12739.37, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:08:19,439 - INFO - Curriculum advancement check: Performance: 12739.37, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:08:22,347 - INFO - Curriculum advancement check: Performance: 12671.48, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:08:22,347 - INFO - Curriculum advancement check: Performance: 12671.48, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:08:22,347 - INFO - Curriculum advancement check: Performance: 12671.48, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:08:25,207 - INFO - Curriculum advancement check: Performance: 12605.01, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:08:25,207 - INFO - Curriculum advancement check: Performance: 12605.01, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:08:25,207 - INFO - Curriculum advancement check: Performance: 12605.01, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:08:35,043 - INFO - Curriculum advancement check: Performance: 12565.75, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:08:35,043 - INFO - Curriculum advancement check: Performance: 12565.75, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:08:35,043 - INFO - Curriculum advancement check: Performance: 12565.75, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:08:37,969 - INFO - Curriculum advancement check: Performance: 12506.10, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:08:37,969 - INFO - Curriculum advancement check: Performance: 12506.10, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:08:37,969 - INFO - Curriculum advancement check: Performance: 12506.10, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:08:41,142 - INFO - Curriculum advancement check: Performance: 12467.77, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:08:41,142 - INFO - Curriculum advancement check: Performance: 12467.77, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:08:41,142 - INFO - Curriculum advancement check: Performance: 12467.77, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:08:44,017 - INFO - Curriculum advancement check: Performance: 12412.07, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:08:44,017 - INFO - Curriculum advancement check: Performance: 12412.07, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:08:44,017 - INFO - Curriculum advancement check: Performance: 12412.07, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:08:57,466 - INFO - Curriculum advancement check: Performance: 12730.40, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:08:57,466 - INFO - Curriculum advancement check: Performance: 12730.40, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:08:57,466 - INFO - Curriculum advancement check: Performance: 12730.40, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:09:10,441 - INFO - Curriculum advancement check: Performance: 12936.88, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:09:10,441 - INFO - Curriculum advancement check: Performance: 12936.88, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:09:10,441 - INFO - Curriculum advancement check: Performance: 12936.88, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:09:13,821 - INFO - Curriculum advancement check: Performance: 12930.19, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:09:13,821 - INFO - Curriculum advancement check: Performance: 12930.19, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:09:13,821 - INFO - Curriculum advancement check: Performance: 12930.19, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:09:19,953 - INFO - Curriculum advancement check: Performance: 13134.32, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:09:19,953 - INFO - Curriculum advancement check: Performance: 13134.32, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:09:19,953 - INFO - Curriculum advancement check: Performance: 13134.32, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:09:31,101 - INFO - Curriculum advancement check: Performance: 13225.31, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:09:31,101 - INFO - Curriculum advancement check: Performance: 13225.31, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:09:31,101 - INFO - Curriculum advancement check: Performance: 13225.31, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:09:34,443 - INFO - Curriculum advancement check: Performance: 13181.74, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:09:34,443 - INFO - Curriculum advancement check: Performance: 13181.74, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:09:34,443 - INFO - Curriculum advancement check: Performance: 13181.74, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:09:38,560 - INFO - Curriculum advancement check: Performance: 10221.22, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:09:38,560 - INFO - Curriculum advancement check: Performance: 10221.22, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:09:38,560 - INFO - Curriculum advancement check: Performance: 10221.22, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:09:41,299 - INFO - Curriculum advancement check: Performance: 10221.31, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:09:41,299 - INFO - Curriculum advancement check: Performance: 10221.31, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:09:41,299 - INFO - Curriculum advancement check: Performance: 10221.31, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:09:44,073 - INFO - Curriculum advancement check: Performance: 10220.96, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:09:44,073 - INFO - Curriculum advancement check: Performance: 10220.96, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:09:44,073 - INFO - Curriculum advancement check: Performance: 10220.96, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:09:46,672 - INFO - Curriculum advancement check: Performance: 10221.05, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:09:46,672 - INFO - Curriculum advancement check: Performance: 10221.05, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:09:46,672 - INFO - Curriculum advancement check: Performance: 10221.05, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:09:49,469 - INFO - Curriculum advancement check: Performance: 10221.14, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:09:49,469 - INFO - Curriculum advancement check: Performance: 10221.14, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:09:49,469 - INFO - Curriculum advancement check: Performance: 10221.14, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:09:51,333 - INFO - Curriculum advancement check: Performance: 13135.27, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:09:51,333 - INFO - Curriculum advancement check: Performance: 13135.27, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:09:51,333 - INFO - Curriculum advancement check: Performance: 13135.27, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:10:01,100 - INFO - Curriculum advancement check: Performance: 13074.98, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:10:01,100 - INFO - Curriculum advancement check: Performance: 13074.98, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:10:01,100 - INFO - Curriculum advancement check: Performance: 13074.98, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:10:04,086 - INFO - Curriculum advancement check: Performance: 13036.78, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:10:04,086 - INFO - Curriculum advancement check: Performance: 13036.78, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:10:04,086 - INFO - Curriculum advancement check: Performance: 13036.78, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:10:08,871 - INFO - Curriculum advancement check: Performance: 13113.42, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:10:08,871 - INFO - Curriculum advancement check: Performance: 13113.42, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:10:08,871 - INFO - Curriculum advancement check: Performance: 13113.42, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:10:11,979 - INFO - Curriculum advancement check: Performance: 13073.03, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:10:11,979 - INFO - Curriculum advancement check: Performance: 13073.03, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:10:11,979 - INFO - Curriculum advancement check: Performance: 13073.03, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:10:21,137 - INFO - Curriculum advancement check: Performance: 13018.64, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:10:21,137 - INFO - Curriculum advancement check: Performance: 13018.64, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:10:21,137 - INFO - Curriculum advancement check: Performance: 13018.64, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:10:23,941 - INFO - Curriculum advancement check: Performance: 12966.88, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:10:23,941 - INFO - Curriculum advancement check: Performance: 12966.88, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:10:23,941 - INFO - Curriculum advancement check: Performance: 12966.88, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:10:26,822 - INFO - Curriculum advancement check: Performance: 12916.41, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:10:26,822 - INFO - Curriculum advancement check: Performance: 12916.41, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:10:26,822 - INFO - Curriculum advancement check: Performance: 12916.41, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:10:38,296 - INFO - Curriculum advancement check: Performance: 12996.94, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:10:38,296 - INFO - Curriculum advancement check: Performance: 12996.94, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:10:38,296 - INFO - Curriculum advancement check: Performance: 12996.94, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:10:43,527 - INFO - Curriculum advancement check: Performance: 13120.86, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:10:43,527 - INFO - Curriculum advancement check: Performance: 13120.86, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:10:43,527 - INFO - Curriculum advancement check: Performance: 13120.86, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:10:46,522 - INFO - Curriculum advancement check: Performance: 13070.66, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:10:46,522 - INFO - Curriculum advancement check: Performance: 13070.66, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:10:46,522 - INFO - Curriculum advancement check: Performance: 13070.66, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:10:56,015 - INFO - Curriculum advancement check: Performance: 13025.08, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:10:56,015 - INFO - Curriculum advancement check: Performance: 13025.08, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:10:56,015 - INFO - Curriculum advancement check: Performance: 13025.08, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:10:59,921 - INFO - Curriculum advancement check: Performance: 13044.39, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:10:59,921 - INFO - Curriculum advancement check: Performance: 13044.39, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:10:59,921 - INFO - Curriculum advancement check: Performance: 13044.39, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:11:03,284 - INFO - Curriculum advancement check: Performance: 13020.30, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:11:03,284 - INFO - Curriculum advancement check: Performance: 13020.30, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:11:03,284 - INFO - Curriculum advancement check: Performance: 13020.30, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:11:06,526 - INFO - Curriculum advancement check: Performance: 12998.34, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:11:06,526 - INFO - Curriculum advancement check: Performance: 12998.34, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:11:06,526 - INFO - Curriculum advancement check: Performance: 12998.34, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:11:16,556 - INFO - Curriculum advancement check: Performance: 12982.97, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:11:16,556 - INFO - Curriculum advancement check: Performance: 12982.97, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:11:16,556 - INFO - Curriculum advancement check: Performance: 12982.97, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:11:22,184 - INFO - Curriculum advancement check: Performance: 10221.21, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:11:22,184 - INFO - Curriculum advancement check: Performance: 10221.21, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:11:22,184 - INFO - Curriculum advancement check: Performance: 10221.21, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:11:24,880 - INFO - Curriculum advancement check: Performance: 10221.27, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:11:24,880 - INFO - Curriculum advancement check: Performance: 10221.27, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:11:24,880 - INFO - Curriculum advancement check: Performance: 10221.27, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:11:28,037 - INFO - Curriculum advancement check: Performance: 10221.35, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:11:28,037 - INFO - Curriculum advancement check: Performance: 10221.35, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:11:28,037 - INFO - Curriculum advancement check: Performance: 10221.35, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:11:30,704 - INFO - Curriculum advancement check: Performance: 10221.40, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:11:30,704 - INFO - Curriculum advancement check: Performance: 10221.40, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:11:30,704 - INFO - Curriculum advancement check: Performance: 10221.40, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:11:33,334 - INFO - Curriculum advancement check: Performance: 10221.44, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:11:33,334 - INFO - Curriculum advancement check: Performance: 10221.44, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:11:33,334 - INFO - Curriculum advancement check: Performance: 10221.44, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:11:33,729 - INFO - Curriculum advancement check: Performance: 12954.37, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:11:33,729 - INFO - Curriculum advancement check: Performance: 12954.37, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:11:33,729 - INFO - Curriculum advancement check: Performance: 12954.37, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:11:36,781 - INFO - Curriculum advancement check: Performance: 12915.41, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:11:36,781 - INFO - Curriculum advancement check: Performance: 12915.41, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:11:36,781 - INFO - Curriculum advancement check: Performance: 12915.41, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:11:46,609 - INFO - Curriculum advancement check: Performance: 12875.89, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:11:46,609 - INFO - Curriculum advancement check: Performance: 12875.89, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:11:46,609 - INFO - Curriculum advancement check: Performance: 12875.89, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:11:51,940 - INFO - Curriculum advancement check: Performance: 12967.58, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:11:51,940 - INFO - Curriculum advancement check: Performance: 12967.58, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:11:51,940 - INFO - Curriculum advancement check: Performance: 12967.58, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:11:55,168 - INFO - Curriculum advancement check: Performance: 12937.68, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:11:55,168 - INFO - Curriculum advancement check: Performance: 12937.68, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:11:55,168 - INFO - Curriculum advancement check: Performance: 12937.68, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:12:04,860 - INFO - Curriculum advancement check: Performance: 12897.93, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:12:04,860 - INFO - Curriculum advancement check: Performance: 12897.93, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:12:04,860 - INFO - Curriculum advancement check: Performance: 12897.93, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:12:08,263 - INFO - Curriculum advancement check: Performance: 12892.97, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:12:08,263 - INFO - Curriculum advancement check: Performance: 12892.97, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:12:08,263 - INFO - Curriculum advancement check: Performance: 12892.97, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:12:11,045 - INFO - Curriculum advancement check: Performance: 12855.10, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:12:11,045 - INFO - Curriculum advancement check: Performance: 12855.10, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:12:11,045 - INFO - Curriculum advancement check: Performance: 12855.10, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:12:14,495 - INFO - Curriculum advancement check: Performance: 12852.77, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:12:14,495 - INFO - Curriculum advancement check: Performance: 12852.77, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:12:14,495 - INFO - Curriculum advancement check: Performance: 12852.77, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:12:24,338 - INFO - Curriculum advancement check: Performance: 12832.75, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:12:24,338 - INFO - Curriculum advancement check: Performance: 12832.75, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:12:24,338 - INFO - Curriculum advancement check: Performance: 12832.75, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:12:27,555 - INFO - Curriculum advancement check: Performance: 12807.59, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:12:27,555 - INFO - Curriculum advancement check: Performance: 12807.59, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:12:27,555 - INFO - Curriculum advancement check: Performance: 12807.59, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:12:30,739 - INFO - Curriculum advancement check: Performance: 12786.60, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:12:30,739 - INFO - Curriculum advancement check: Performance: 12786.60, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:12:30,739 - INFO - Curriculum advancement check: Performance: 12786.60, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:12:33,590 - INFO - Curriculum advancement check: Performance: 12752.65, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:12:33,590 - INFO - Curriculum advancement check: Performance: 12752.65, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:12:33,590 - INFO - Curriculum advancement check: Performance: 12752.65, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:12:42,981 - INFO - Curriculum advancement check: Performance: 12719.56, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:12:42,981 - INFO - Curriculum advancement check: Performance: 12719.56, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:12:42,981 - INFO - Curriculum advancement check: Performance: 12719.56, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:12:46,288 - INFO - Curriculum advancement check: Performance: 12699.42, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:12:46,288 - INFO - Curriculum advancement check: Performance: 12699.42, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:12:46,288 - INFO - Curriculum advancement check: Performance: 12699.42, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:12:49,117 - INFO - Curriculum advancement check: Performance: 12668.13, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:12:49,117 - INFO - Curriculum advancement check: Performance: 12668.13, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:12:49,117 - INFO - Curriculum advancement check: Performance: 12668.13, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:12:52,168 - INFO - Curriculum advancement check: Performance: 12641.23, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:12:52,168 - INFO - Curriculum advancement check: Performance: 12641.23, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:12:52,168 - INFO - Curriculum advancement check: Performance: 12641.23, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:13:01,591 - INFO - Curriculum advancement check: Performance: 12613.21, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:13:01,591 - INFO - Curriculum advancement check: Performance: 12613.21, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:13:01,591 - INFO - Curriculum advancement check: Performance: 12613.21, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:13:07,361 - INFO - Curriculum advancement check: Performance: 10222.45, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:13:07,361 - INFO - Curriculum advancement check: Performance: 10222.45, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:13:07,361 - INFO - Curriculum advancement check: Performance: 10222.45, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:13:09,993 - INFO - Curriculum advancement check: Performance: 10222.16, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:13:09,993 - INFO - Curriculum advancement check: Performance: 10222.16, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:13:09,993 - INFO - Curriculum advancement check: Performance: 10222.16, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:13:12,790 - INFO - Curriculum advancement check: Performance: 10222.26, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:13:12,790 - INFO - Curriculum advancement check: Performance: 10222.26, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:13:12,790 - INFO - Curriculum advancement check: Performance: 10222.26, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:13:15,531 - INFO - Curriculum advancement check: Performance: 10222.26, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:13:15,531 - INFO - Curriculum advancement check: Performance: 10222.26, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:13:15,531 - INFO - Curriculum advancement check: Performance: 10222.26, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:13:18,371 - INFO - Curriculum advancement check: Performance: 10222.35, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:13:18,371 - INFO - Curriculum advancement check: Performance: 10222.35, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:13:18,371 - INFO - Curriculum advancement check: Performance: 10222.35, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:13:18,861 - INFO - Curriculum advancement check: Performance: 12587.88, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:13:18,861 - INFO - Curriculum advancement check: Performance: 12587.88, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:13:18,861 - INFO - Curriculum advancement check: Performance: 12587.88, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:13:21,911 - INFO - Curriculum advancement check: Performance: 12559.68, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:13:21,911 - INFO - Curriculum advancement check: Performance: 12559.68, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:13:21,911 - INFO - Curriculum advancement check: Performance: 12559.68, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:13:25,201 - INFO - Curriculum advancement check: Performance: 12544.36, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:13:25,201 - INFO - Curriculum advancement check: Performance: 12544.36, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:13:25,201 - INFO - Curriculum advancement check: Performance: 12544.36, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:13:34,726 - INFO - Curriculum advancement check: Performance: 12524.61, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:13:34,726 - INFO - Curriculum advancement check: Performance: 12524.61, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:13:34,726 - INFO - Curriculum advancement check: Performance: 12524.61, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:13:39,234 - INFO - Curriculum advancement check: Performance: 12555.50, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:13:39,234 - INFO - Curriculum advancement check: Performance: 12555.50, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:13:39,234 - INFO - Curriculum advancement check: Performance: 12555.50, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:13:51,583 - INFO - Curriculum advancement check: Performance: 12635.46, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:13:51,583 - INFO - Curriculum advancement check: Performance: 12635.46, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:13:51,583 - INFO - Curriculum advancement check: Performance: 12635.46, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:13:54,429 - INFO - Curriculum advancement check: Performance: 12608.73, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:13:54,429 - INFO - Curriculum advancement check: Performance: 12608.73, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:13:54,429 - INFO - Curriculum advancement check: Performance: 12608.73, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:14:00,116 - INFO - Curriculum advancement check: Performance: 12674.23, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:14:00,116 - INFO - Curriculum advancement check: Performance: 12674.23, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:14:00,116 - INFO - Curriculum advancement check: Performance: 12674.23, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:14:12,368 - INFO - Curriculum advancement check: Performance: 12749.60, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:14:12,368 - INFO - Curriculum advancement check: Performance: 12749.60, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:14:12,368 - INFO - Curriculum advancement check: Performance: 12749.60, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:14:15,514 - INFO - Curriculum advancement check: Performance: 12736.68, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:14:15,514 - INFO - Curriculum advancement check: Performance: 12736.68, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:14:15,514 - INFO - Curriculum advancement check: Performance: 12736.68, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:14:18,948 - INFO - Curriculum advancement check: Performance: 12730.95, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:14:18,948 - INFO - Curriculum advancement check: Performance: 12730.95, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:14:18,948 - INFO - Curriculum advancement check: Performance: 12730.95, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:14:18,950 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:14:18,950 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:14:18,950 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:14:18,952 - ERROR - An error occurred during experiment kg_completeness_0.65: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:14:18,952 - ERROR - An error occurred during experiment kg_completeness_0.65: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:14:18,952 - ERROR - An error occurred during experiment kg_completeness_0.65: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:14:18,955 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 251, in step
    self.simulation_manager.add_episode_performance(self.total_reward, success)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:14:18,955 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 251, in step
    self.simulation_manager.add_episode_performance(self.total_reward, success)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:14:18,955 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 251, in step
    self.simulation_manager.add_episode_performance(self.total_reward, success)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:14:18,967 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 23:14:18,967 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 23:14:18,967 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 23:14:18,969 - INFO - Using device: cuda
2024-08-12 23:14:18,969 - INFO - Using device: cuda
2024-08-12 23:14:18,969 - INFO - Using device: cuda
2024-08-12 23:14:18,969 - INFO - Using device: cuda
2024-08-12 23:14:58,974 - INFO - Curriculum advancement check: Performance: 17551.54, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:14:58,974 - INFO - Curriculum advancement check: Performance: 17551.54, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:14:58,974 - INFO - Curriculum advancement check: Performance: 17551.54, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:14:58,974 - INFO - Curriculum advancement check: Performance: 17551.54, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:15:01,991 - INFO - Curriculum advancement check: Performance: 16414.42, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:15:01,991 - INFO - Curriculum advancement check: Performance: 16414.42, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:15:01,991 - INFO - Curriculum advancement check: Performance: 16414.42, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:15:01,991 - INFO - Curriculum advancement check: Performance: 16414.42, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:15:06,799 - INFO - Curriculum advancement check: Performance: 16532.66, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:15:06,799 - INFO - Curriculum advancement check: Performance: 16532.66, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:15:06,799 - INFO - Curriculum advancement check: Performance: 16532.66, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:15:06,799 - INFO - Curriculum advancement check: Performance: 16532.66, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:15:16,214 - INFO - Curriculum advancement check: Performance: 15745.94, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:15:16,214 - INFO - Curriculum advancement check: Performance: 15745.94, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:15:16,214 - INFO - Curriculum advancement check: Performance: 15745.94, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:15:16,214 - INFO - Curriculum advancement check: Performance: 15745.94, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:15:19,012 - INFO - Curriculum advancement check: Performance: 15145.72, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:15:19,012 - INFO - Curriculum advancement check: Performance: 15145.72, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:15:19,012 - INFO - Curriculum advancement check: Performance: 15145.72, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:15:19,012 - INFO - Curriculum advancement check: Performance: 15145.72, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:15:21,959 - INFO - Curriculum advancement check: Performance: 14677.83, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:15:21,959 - INFO - Curriculum advancement check: Performance: 14677.83, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:15:21,959 - INFO - Curriculum advancement check: Performance: 14677.83, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:15:21,959 - INFO - Curriculum advancement check: Performance: 14677.83, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:15:25,789 - INFO - Curriculum advancement check: Performance: 14629.15, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:15:25,789 - INFO - Curriculum advancement check: Performance: 14629.15, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:15:25,789 - INFO - Curriculum advancement check: Performance: 14629.15, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:15:25,789 - INFO - Curriculum advancement check: Performance: 14629.15, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:15:35,518 - INFO - Curriculum advancement check: Performance: 14338.02, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:15:35,518 - INFO - Curriculum advancement check: Performance: 14338.02, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:15:35,518 - INFO - Curriculum advancement check: Performance: 14338.02, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:15:35,518 - INFO - Curriculum advancement check: Performance: 14338.02, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:15:40,442 - INFO - Curriculum advancement check: Performance: 14659.85, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:15:40,442 - INFO - Curriculum advancement check: Performance: 14659.85, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:15:40,442 - INFO - Curriculum advancement check: Performance: 14659.85, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:15:40,442 - INFO - Curriculum advancement check: Performance: 14659.85, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:15:43,331 - INFO - Curriculum advancement check: Performance: 14351.04, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:15:43,331 - INFO - Curriculum advancement check: Performance: 14351.04, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:15:43,331 - INFO - Curriculum advancement check: Performance: 14351.04, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:15:43,331 - INFO - Curriculum advancement check: Performance: 14351.04, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:15:54,728 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:15:54,728 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:15:54,728 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:15:54,728 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:16:04,306 - INFO - Curriculum advancement check: Performance: 14122.95, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:16:04,306 - INFO - Curriculum advancement check: Performance: 14122.95, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:16:04,306 - INFO - Curriculum advancement check: Performance: 14122.95, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:16:04,306 - INFO - Curriculum advancement check: Performance: 14122.95, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:16:07,603 - INFO - Curriculum advancement check: Performance: 14029.18, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:16:07,603 - INFO - Curriculum advancement check: Performance: 14029.18, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:16:07,603 - INFO - Curriculum advancement check: Performance: 14029.18, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:16:07,603 - INFO - Curriculum advancement check: Performance: 14029.18, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:16:10,800 - INFO - Curriculum advancement check: Performance: 13894.57, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:16:10,800 - INFO - Curriculum advancement check: Performance: 13894.57, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:16:10,800 - INFO - Curriculum advancement check: Performance: 13894.57, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:16:10,800 - INFO - Curriculum advancement check: Performance: 13894.57, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:16:13,561 - INFO - Curriculum advancement check: Performance: 13691.58, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:16:13,561 - INFO - Curriculum advancement check: Performance: 13691.58, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:16:13,561 - INFO - Curriculum advancement check: Performance: 13691.58, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:16:13,561 - INFO - Curriculum advancement check: Performance: 13691.58, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:16:22,956 - INFO - Curriculum advancement check: Performance: 13517.66, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:16:22,956 - INFO - Curriculum advancement check: Performance: 13517.66, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:16:22,956 - INFO - Curriculum advancement check: Performance: 13517.66, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:16:22,956 - INFO - Curriculum advancement check: Performance: 13517.66, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:16:27,129 - INFO - Curriculum advancement check: Performance: 13617.70, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:16:27,129 - INFO - Curriculum advancement check: Performance: 13617.70, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:16:27,129 - INFO - Curriculum advancement check: Performance: 13617.70, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:16:27,129 - INFO - Curriculum advancement check: Performance: 13617.70, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:16:30,368 - INFO - Curriculum advancement check: Performance: 13519.38, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:16:30,368 - INFO - Curriculum advancement check: Performance: 13519.38, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:16:30,368 - INFO - Curriculum advancement check: Performance: 13519.38, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:16:30,368 - INFO - Curriculum advancement check: Performance: 13519.38, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:16:39,774 - INFO - Curriculum advancement check: Performance: 13370.36, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:16:39,774 - INFO - Curriculum advancement check: Performance: 13370.36, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:16:39,774 - INFO - Curriculum advancement check: Performance: 13370.36, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:16:39,774 - INFO - Curriculum advancement check: Performance: 13370.36, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:16:42,816 - INFO - Curriculum advancement check: Performance: 13296.77, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:16:42,816 - INFO - Curriculum advancement check: Performance: 13296.77, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:16:42,816 - INFO - Curriculum advancement check: Performance: 13296.77, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:16:42,816 - INFO - Curriculum advancement check: Performance: 13296.77, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:16:47,804 - INFO - Curriculum advancement check: Performance: 13449.66, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:16:47,804 - INFO - Curriculum advancement check: Performance: 13449.66, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:16:47,804 - INFO - Curriculum advancement check: Performance: 13449.66, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:16:47,804 - INFO - Curriculum advancement check: Performance: 13449.66, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:16:57,859 - INFO - Curriculum advancement check: Performance: 13424.64, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:16:57,859 - INFO - Curriculum advancement check: Performance: 13424.64, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:16:57,859 - INFO - Curriculum advancement check: Performance: 13424.64, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:16:57,859 - INFO - Curriculum advancement check: Performance: 13424.64, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:17:00,677 - INFO - Curriculum advancement check: Performance: 13303.64, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:17:00,677 - INFO - Curriculum advancement check: Performance: 13303.64, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:17:00,677 - INFO - Curriculum advancement check: Performance: 13303.64, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:17:00,677 - INFO - Curriculum advancement check: Performance: 13303.64, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:17:03,645 - INFO - Curriculum advancement check: Performance: 13223.10, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:17:03,645 - INFO - Curriculum advancement check: Performance: 13223.10, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:17:03,645 - INFO - Curriculum advancement check: Performance: 13223.10, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:17:03,645 - INFO - Curriculum advancement check: Performance: 13223.10, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:17:06,699 - INFO - Curriculum advancement check: Performance: 13138.27, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:17:06,699 - INFO - Curriculum advancement check: Performance: 13138.27, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:17:06,699 - INFO - Curriculum advancement check: Performance: 13138.27, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:17:06,699 - INFO - Curriculum advancement check: Performance: 13138.27, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:17:16,204 - INFO - Curriculum advancement check: Performance: 13061.16, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:17:16,204 - INFO - Curriculum advancement check: Performance: 13061.16, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:17:16,204 - INFO - Curriculum advancement check: Performance: 13061.16, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:17:16,204 - INFO - Curriculum advancement check: Performance: 13061.16, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:17:19,060 - INFO - Curriculum advancement check: Performance: 12981.34, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:17:19,060 - INFO - Curriculum advancement check: Performance: 12981.34, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:17:19,060 - INFO - Curriculum advancement check: Performance: 12981.34, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:17:19,060 - INFO - Curriculum advancement check: Performance: 12981.34, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:17:21,900 - INFO - Curriculum advancement check: Performance: 12901.98, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:17:21,900 - INFO - Curriculum advancement check: Performance: 12901.98, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:17:21,900 - INFO - Curriculum advancement check: Performance: 12901.98, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:17:21,900 - INFO - Curriculum advancement check: Performance: 12901.98, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:17:26,128 - INFO - Curriculum advancement check: Performance: 10222.64, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:17:26,128 - INFO - Curriculum advancement check: Performance: 10222.64, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:17:26,128 - INFO - Curriculum advancement check: Performance: 10222.64, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:17:26,128 - INFO - Curriculum advancement check: Performance: 10222.64, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:17:28,259 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:17:28,259 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:17:28,259 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:17:28,259 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:17:30,375 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:17:30,375 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:17:30,375 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:17:30,375 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:17:32,452 - INFO - Curriculum advancement check: Performance: 10222.75, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:17:32,452 - INFO - Curriculum advancement check: Performance: 10222.75, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:17:32,452 - INFO - Curriculum advancement check: Performance: 10222.75, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:17:32,452 - INFO - Curriculum advancement check: Performance: 10222.75, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:17:34,562 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:17:34,562 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:17:34,562 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:17:34,562 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:17:35,402 - INFO - Curriculum advancement check: Performance: 12818.83, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:17:35,402 - INFO - Curriculum advancement check: Performance: 12818.83, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:17:35,402 - INFO - Curriculum advancement check: Performance: 12818.83, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:17:35,402 - INFO - Curriculum advancement check: Performance: 12818.83, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:17:45,108 - INFO - Curriculum advancement check: Performance: 12778.06, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:17:45,108 - INFO - Curriculum advancement check: Performance: 12778.06, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:17:45,108 - INFO - Curriculum advancement check: Performance: 12778.06, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:17:45,108 - INFO - Curriculum advancement check: Performance: 12778.06, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:17:48,260 - INFO - Curriculum advancement check: Performance: 12739.71, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:17:48,260 - INFO - Curriculum advancement check: Performance: 12739.71, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:17:48,260 - INFO - Curriculum advancement check: Performance: 12739.71, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:17:48,260 - INFO - Curriculum advancement check: Performance: 12739.71, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:17:51,517 - INFO - Curriculum advancement check: Performance: 12722.14, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:17:51,517 - INFO - Curriculum advancement check: Performance: 12722.14, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:17:51,517 - INFO - Curriculum advancement check: Performance: 12722.14, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:17:51,517 - INFO - Curriculum advancement check: Performance: 12722.14, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:17:54,346 - INFO - Curriculum advancement check: Performance: 12653.10, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:17:54,346 - INFO - Curriculum advancement check: Performance: 12653.10, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:17:54,346 - INFO - Curriculum advancement check: Performance: 12653.10, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:17:54,346 - INFO - Curriculum advancement check: Performance: 12653.10, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:18:03,703 - INFO - Curriculum advancement check: Performance: 12590.53, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:18:03,703 - INFO - Curriculum advancement check: Performance: 12590.53, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:18:03,703 - INFO - Curriculum advancement check: Performance: 12590.53, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:18:03,703 - INFO - Curriculum advancement check: Performance: 12590.53, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:18:06,569 - INFO - Curriculum advancement check: Performance: 12533.88, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:18:06,569 - INFO - Curriculum advancement check: Performance: 12533.88, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:18:06,569 - INFO - Curriculum advancement check: Performance: 12533.88, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:18:06,569 - INFO - Curriculum advancement check: Performance: 12533.88, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:18:10,420 - INFO - Curriculum advancement check: Performance: 12581.68, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:18:10,420 - INFO - Curriculum advancement check: Performance: 12581.68, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:18:10,420 - INFO - Curriculum advancement check: Performance: 12581.68, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:18:10,420 - INFO - Curriculum advancement check: Performance: 12581.68, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:18:19,844 - INFO - Curriculum advancement check: Performance: 12525.65, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:18:19,844 - INFO - Curriculum advancement check: Performance: 12525.65, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:18:19,844 - INFO - Curriculum advancement check: Performance: 12525.65, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:18:19,844 - INFO - Curriculum advancement check: Performance: 12525.65, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:18:22,662 - INFO - Curriculum advancement check: Performance: 12493.07, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:18:22,662 - INFO - Curriculum advancement check: Performance: 12493.07, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:18:22,662 - INFO - Curriculum advancement check: Performance: 12493.07, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:18:22,662 - INFO - Curriculum advancement check: Performance: 12493.07, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:18:25,396 - INFO - Curriculum advancement check: Performance: 12441.85, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:18:25,396 - INFO - Curriculum advancement check: Performance: 12441.85, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:18:25,396 - INFO - Curriculum advancement check: Performance: 12441.85, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:18:25,396 - INFO - Curriculum advancement check: Performance: 12441.85, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:18:28,229 - INFO - Curriculum advancement check: Performance: 12390.57, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:18:28,229 - INFO - Curriculum advancement check: Performance: 12390.57, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:18:28,229 - INFO - Curriculum advancement check: Performance: 12390.57, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:18:28,229 - INFO - Curriculum advancement check: Performance: 12390.57, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:18:38,854 - INFO - Curriculum advancement check: Performance: 12437.90, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:18:38,854 - INFO - Curriculum advancement check: Performance: 12437.90, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:18:38,854 - INFO - Curriculum advancement check: Performance: 12437.90, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:18:38,854 - INFO - Curriculum advancement check: Performance: 12437.90, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:18:41,914 - INFO - Curriculum advancement check: Performance: 12430.45, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:18:41,914 - INFO - Curriculum advancement check: Performance: 12430.45, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:18:41,914 - INFO - Curriculum advancement check: Performance: 12430.45, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:18:41,914 - INFO - Curriculum advancement check: Performance: 12430.45, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:18:44,874 - INFO - Curriculum advancement check: Performance: 12382.85, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:18:44,874 - INFO - Curriculum advancement check: Performance: 12382.85, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:18:44,874 - INFO - Curriculum advancement check: Performance: 12382.85, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:18:44,874 - INFO - Curriculum advancement check: Performance: 12382.85, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:18:47,617 - INFO - Curriculum advancement check: Performance: 12338.54, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:18:47,617 - INFO - Curriculum advancement check: Performance: 12338.54, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:18:47,617 - INFO - Curriculum advancement check: Performance: 12338.54, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:18:47,617 - INFO - Curriculum advancement check: Performance: 12338.54, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:18:57,001 - INFO - Curriculum advancement check: Performance: 12297.33, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:18:57,001 - INFO - Curriculum advancement check: Performance: 12297.33, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:18:57,001 - INFO - Curriculum advancement check: Performance: 12297.33, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:18:57,001 - INFO - Curriculum advancement check: Performance: 12297.33, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:19:00,924 - INFO - Curriculum advancement check: Performance: 12336.47, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:19:00,924 - INFO - Curriculum advancement check: Performance: 12336.47, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:19:00,924 - INFO - Curriculum advancement check: Performance: 12336.47, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:19:00,924 - INFO - Curriculum advancement check: Performance: 12336.47, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:19:05,116 - INFO - Curriculum advancement check: Performance: 10222.86, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:19:05,116 - INFO - Curriculum advancement check: Performance: 10222.86, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:19:05,116 - INFO - Curriculum advancement check: Performance: 10222.86, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:19:05,116 - INFO - Curriculum advancement check: Performance: 10222.86, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:19:07,233 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:19:07,233 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:19:07,233 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:19:07,233 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:19:09,361 - INFO - Curriculum advancement check: Performance: 10222.77, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:19:09,361 - INFO - Curriculum advancement check: Performance: 10222.77, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:19:09,361 - INFO - Curriculum advancement check: Performance: 10222.77, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:19:09,361 - INFO - Curriculum advancement check: Performance: 10222.77, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:19:11,531 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:19:11,531 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:19:11,531 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:19:11,531 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:19:13,705 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:19:13,705 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:19:13,705 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:19:13,705 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:19:16,753 - INFO - Curriculum advancement check: Performance: 12413.28, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:19:16,753 - INFO - Curriculum advancement check: Performance: 12413.28, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:19:16,753 - INFO - Curriculum advancement check: Performance: 12413.28, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:19:16,753 - INFO - Curriculum advancement check: Performance: 12413.28, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:19:26,257 - INFO - Curriculum advancement check: Performance: 12373.01, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:19:26,257 - INFO - Curriculum advancement check: Performance: 12373.01, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:19:26,257 - INFO - Curriculum advancement check: Performance: 12373.01, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:19:26,257 - INFO - Curriculum advancement check: Performance: 12373.01, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:19:26,260 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:19:26,260 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:19:26,260 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:19:26,260 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:19:26,261 - ERROR - An error occurred during experiment kg_completeness_1.0: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:19:26,261 - ERROR - An error occurred during experiment kg_completeness_1.0: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:19:26,261 - ERROR - An error occurred during experiment kg_completeness_1.0: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:19:26,261 - ERROR - An error occurred during experiment kg_completeness_1.0: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:19:26,265 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 251, in step
    self.simulation_manager.add_episode_performance(self.total_reward, success)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:19:26,265 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 251, in step
    self.simulation_manager.add_episode_performance(self.total_reward, success)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:19:26,265 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 251, in step
    self.simulation_manager.add_episode_performance(self.total_reward, success)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:19:26,265 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 251, in step
    self.simulation_manager.add_episode_performance(self.total_reward, success)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:19:26,283 - INFO - Ablation study results saved to results\20240812_225702\ablation_study_results.json
2024-08-12 23:19:26,283 - INFO - Ablation study results saved to results\20240812_225702\ablation_study_results.json
2024-08-12 23:19:26,283 - INFO - Ablation study results saved to results\20240812_225702\ablation_study_results.json
2024-08-12 23:19:26,283 - INFO - Ablation study results saved to results\20240812_225702\ablation_study_results.json
2024-08-12 23:19:26,297 - INFO - Base configuration saved to results\20240812_225702\base_config.json
2024-08-12 23:19:26,297 - INFO - Base configuration saved to results\20240812_225702\base_config.json
2024-08-12 23:19:26,297 - INFO - Base configuration saved to results\20240812_225702\base_config.json
2024-08-12 23:19:26,297 - INFO - Base configuration saved to results\20240812_225702\base_config.json
2024-08-12 23:19:26,299 - INFO - Ablation Study completed
2024-08-12 23:19:26,299 - INFO - Ablation Study completed
2024-08-12 23:19:26,299 - INFO - Ablation Study completed
2024-08-12 23:19:26,299 - INFO - Ablation Study completed
2024-08-12 23:31:32,358 - INFO - Created results directory: results\20240812_233132
2024-08-12 23:31:32,359 - INFO - Starting Ablation Study
2024-08-12 23:31:32,359 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 23:31:32,382 - INFO - Using device: cuda
2024-08-12 23:31:32,382 - INFO - Using device: cuda
2024-08-12 23:32:01,056 - INFO - Curriculum advancement check: Performance: 13814.53, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:32:01,056 - INFO - Curriculum advancement check: Performance: 13814.53, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:32:14,106 - INFO - Curriculum advancement check: Performance: 15238.95, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:32:14,106 - INFO - Curriculum advancement check: Performance: 15238.95, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:32:16,783 - INFO - Curriculum advancement check: Performance: 14525.43, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:32:16,783 - INFO - Curriculum advancement check: Performance: 14525.43, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:32:21,521 - INFO - Curriculum advancement check: Performance: 14693.47, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:32:21,521 - INFO - Curriculum advancement check: Performance: 14693.47, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:32:32,212 - INFO - Curriculum advancement check: Performance: 14582.94, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:32:32,212 - INFO - Curriculum advancement check: Performance: 14582.94, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:32:37,366 - INFO - Curriculum advancement check: Performance: 14930.47, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:32:37,366 - INFO - Curriculum advancement check: Performance: 14930.47, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:32:40,362 - INFO - Curriculum advancement check: Performance: 14504.14, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:32:40,362 - INFO - Curriculum advancement check: Performance: 14504.14, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:32:50,900 - INFO - Curriculum advancement check: Performance: 14309.79, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:32:50,900 - INFO - Curriculum advancement check: Performance: 14309.79, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:32:54,419 - INFO - Curriculum advancement check: Performance: 14161.98, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:32:54,419 - INFO - Curriculum advancement check: Performance: 14161.98, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:33:42,595 - INFO - Created results directory: results\20240812_233342
2024-08-12 23:33:42,595 - INFO - Starting Ablation Study
2024-08-12 23:33:42,595 - INFO - Running experiment: kg_completeness_0.3
2024-08-12 23:33:42,616 - INFO - Using device: cuda
2024-08-12 23:33:42,616 - INFO - Using device: cuda
2024-08-12 23:34:08,899 - INFO - Curriculum advancement check: Performance: 13381.67, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:34:08,899 - INFO - Curriculum advancement check: Performance: 13381.67, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:34:13,385 - INFO - Curriculum advancement check: Performance: 13841.71, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:34:13,385 - INFO - Curriculum advancement check: Performance: 13841.71, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:34:22,702 - INFO - Curriculum advancement check: Performance: 13327.49, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:34:22,702 - INFO - Curriculum advancement check: Performance: 13327.49, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:34:26,552 - INFO - Curriculum advancement check: Performance: 13541.59, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:34:26,552 - INFO - Curriculum advancement check: Performance: 13541.59, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:34:29,393 - INFO - Curriculum advancement check: Performance: 13174.74, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:34:29,393 - INFO - Curriculum advancement check: Performance: 13174.74, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:34:38,833 - INFO - Curriculum advancement check: Performance: 13035.42, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:34:38,833 - INFO - Curriculum advancement check: Performance: 13035.42, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:34:43,765 - INFO - Curriculum advancement check: Performance: 13564.81, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:34:43,765 - INFO - Curriculum advancement check: Performance: 13564.81, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:34:47,621 - INFO - Curriculum advancement check: Performance: 13664.30, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:34:47,621 - INFO - Curriculum advancement check: Performance: 13664.30, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:34:57,145 - INFO - Curriculum advancement check: Performance: 13491.75, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:34:57,145 - INFO - Curriculum advancement check: Performance: 13491.75, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:35:00,985 - INFO - Curriculum advancement check: Performance: 13507.84, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:35:00,985 - INFO - Curriculum advancement check: Performance: 13507.84, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:35:18,689 - INFO - Curriculum advancement check: Performance: 10244.52, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:35:18,689 - INFO - Curriculum advancement check: Performance: 10244.52, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:35:28,421 - INFO - Curriculum advancement check: Performance: 14255.77, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:35:28,421 - INFO - Curriculum advancement check: Performance: 14255.77, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:35:31,112 - INFO - Curriculum advancement check: Performance: 14004.97, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:35:31,112 - INFO - Curriculum advancement check: Performance: 14004.97, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:35:34,931 - INFO - Curriculum advancement check: Performance: 14008.44, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:35:34,931 - INFO - Curriculum advancement check: Performance: 14008.44, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:35:37,922 - INFO - Curriculum advancement check: Performance: 13818.26, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:35:37,922 - INFO - Curriculum advancement check: Performance: 13818.26, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:35:49,468 - INFO - Curriculum advancement check: Performance: 14019.78, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:35:49,468 - INFO - Curriculum advancement check: Performance: 14019.78, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:35:52,283 - INFO - Curriculum advancement check: Performance: 13831.71, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:35:52,283 - INFO - Curriculum advancement check: Performance: 13831.71, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:36:03,488 - INFO - Curriculum advancement check: Performance: 13968.47, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:36:03,488 - INFO - Curriculum advancement check: Performance: 13968.47, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:36:06,204 - INFO - Curriculum advancement check: Performance: 13798.86, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:36:06,204 - INFO - Curriculum advancement check: Performance: 13798.86, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:36:09,791 - INFO - Curriculum advancement check: Performance: 13803.76, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:36:09,791 - INFO - Curriculum advancement check: Performance: 13803.76, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:36:12,836 - INFO - Curriculum advancement check: Performance: 13655.19, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:36:12,836 - INFO - Curriculum advancement check: Performance: 13655.19, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:36:22,296 - INFO - Curriculum advancement check: Performance: 13523.40, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:36:22,296 - INFO - Curriculum advancement check: Performance: 13523.40, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:36:27,393 - INFO - Curriculum advancement check: Performance: 13733.20, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:36:27,393 - INFO - Curriculum advancement check: Performance: 13733.20, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:36:31,549 - INFO - Curriculum advancement check: Performance: 13731.98, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:36:31,549 - INFO - Curriculum advancement check: Performance: 13731.98, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:36:41,178 - INFO - Curriculum advancement check: Performance: 13631.11, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:36:41,178 - INFO - Curriculum advancement check: Performance: 13631.11, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:36:44,916 - INFO - Curriculum advancement check: Performance: 13631.10, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:36:44,916 - INFO - Curriculum advancement check: Performance: 13631.10, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:36:47,805 - INFO - Curriculum advancement check: Performance: 13517.93, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:36:47,805 - INFO - Curriculum advancement check: Performance: 13517.93, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:36:50,739 - INFO - Curriculum advancement check: Performance: 10240.81, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:36:50,739 - INFO - Curriculum advancement check: Performance: 10240.81, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:36:53,313 - INFO - Curriculum advancement check: Performance: 10238.46, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:36:53,313 - INFO - Curriculum advancement check: Performance: 10238.46, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:36:55,468 - INFO - Curriculum advancement check: Performance: 10236.44, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:36:55,468 - INFO - Curriculum advancement check: Performance: 10236.44, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:36:58,361 - INFO - Curriculum advancement check: Performance: 10234.87, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:36:58,361 - INFO - Curriculum advancement check: Performance: 10234.87, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:37:01,009 - INFO - Curriculum advancement check: Performance: 10233.82, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:37:01,009 - INFO - Curriculum advancement check: Performance: 10233.82, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:37:03,646 - INFO - Curriculum advancement check: Performance: 13454.97, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:37:03,646 - INFO - Curriculum advancement check: Performance: 13454.97, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:37:13,082 - INFO - Curriculum advancement check: Performance: 13356.16, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:37:13,082 - INFO - Curriculum advancement check: Performance: 13356.16, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:37:16,613 - INFO - Curriculum advancement check: Performance: 13339.38, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:37:16,613 - INFO - Curriculum advancement check: Performance: 13339.38, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:37:19,502 - INFO - Curriculum advancement check: Performance: 13248.06, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:37:19,502 - INFO - Curriculum advancement check: Performance: 13248.06, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:37:29,334 - INFO - Curriculum advancement check: Performance: 13162.15, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:37:29,334 - INFO - Curriculum advancement check: Performance: 13162.15, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:37:32,793 - INFO - Curriculum advancement check: Performance: 13141.71, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:37:32,793 - INFO - Curriculum advancement check: Performance: 13141.71, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:37:36,604 - INFO - Curriculum advancement check: Performance: 13130.82, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:37:36,604 - INFO - Curriculum advancement check: Performance: 13130.82, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:37:39,618 - INFO - Curriculum advancement check: Performance: 13057.08, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:37:39,618 - INFO - Curriculum advancement check: Performance: 13057.08, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:37:50,369 - INFO - Curriculum advancement check: Performance: 13106.00, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:37:50,369 - INFO - Curriculum advancement check: Performance: 13106.00, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:37:53,407 - INFO - Curriculum advancement check: Performance: 13039.90, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:37:53,407 - INFO - Curriculum advancement check: Performance: 13039.90, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:37:56,326 - INFO - Curriculum advancement check: Performance: 12971.29, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:37:56,326 - INFO - Curriculum advancement check: Performance: 12971.29, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:37:59,393 - INFO - Curriculum advancement check: Performance: 12905.95, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:37:59,393 - INFO - Curriculum advancement check: Performance: 12905.95, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:38:09,773 - INFO - Curriculum advancement check: Performance: 12949.25, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:38:09,773 - INFO - Curriculum advancement check: Performance: 12949.25, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:38:12,485 - INFO - Curriculum advancement check: Performance: 12889.42, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:38:12,485 - INFO - Curriculum advancement check: Performance: 12889.42, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:38:15,601 - INFO - Curriculum advancement check: Performance: 12831.33, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:38:15,601 - INFO - Curriculum advancement check: Performance: 12831.33, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:38:25,143 - INFO - Curriculum advancement check: Performance: 12774.64, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:38:25,143 - INFO - Curriculum advancement check: Performance: 12774.64, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:38:34,968 - INFO - Curriculum advancement check: Performance: 10232.96, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:38:34,968 - INFO - Curriculum advancement check: Performance: 10232.96, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:38:37,492 - INFO - Curriculum advancement check: Performance: 10232.25, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:38:37,492 - INFO - Curriculum advancement check: Performance: 10232.25, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:38:40,127 - INFO - Curriculum advancement check: Performance: 10231.48, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:38:40,127 - INFO - Curriculum advancement check: Performance: 10231.48, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:38:42,704 - INFO - Curriculum advancement check: Performance: 10230.82, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:38:42,704 - INFO - Curriculum advancement check: Performance: 10230.82, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:38:45,664 - INFO - Curriculum advancement check: Performance: 10230.26, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:38:45,664 - INFO - Curriculum advancement check: Performance: 10230.26, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:38:46,643 - INFO - Curriculum advancement check: Performance: 13060.46, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:38:46,643 - INFO - Curriculum advancement check: Performance: 13060.46, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:38:50,097 - INFO - Curriculum advancement check: Performance: 13019.83, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:38:50,097 - INFO - Curriculum advancement check: Performance: 13019.83, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:38:59,975 - INFO - Curriculum advancement check: Performance: 12962.82, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:38:59,975 - INFO - Curriculum advancement check: Performance: 12962.82, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:39:03,557 - INFO - Curriculum advancement check: Performance: 12907.87, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:39:03,557 - INFO - Curriculum advancement check: Performance: 12907.87, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:39:06,948 - INFO - Curriculum advancement check: Performance: 12867.86, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:39:06,948 - INFO - Curriculum advancement check: Performance: 12867.86, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:39:10,091 - INFO - Curriculum advancement check: Performance: 12817.25, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:39:10,091 - INFO - Curriculum advancement check: Performance: 12817.25, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:39:19,553 - INFO - Curriculum advancement check: Performance: 12768.24, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:39:19,553 - INFO - Curriculum advancement check: Performance: 12768.24, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:39:22,922 - INFO - Curriculum advancement check: Performance: 12752.59, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:39:22,922 - INFO - Curriculum advancement check: Performance: 12752.59, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:39:28,988 - INFO - Curriculum advancement check: Performance: 12877.51, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:39:28,988 - INFO - Curriculum advancement check: Performance: 12877.51, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:39:38,756 - INFO - Curriculum advancement check: Performance: 12830.05, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:39:38,756 - INFO - Curriculum advancement check: Performance: 12830.05, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:39:42,035 - INFO - Curriculum advancement check: Performance: 12789.29, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:39:42,035 - INFO - Curriculum advancement check: Performance: 12789.29, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:39:45,118 - INFO - Curriculum advancement check: Performance: 12747.67, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:39:45,118 - INFO - Curriculum advancement check: Performance: 12747.67, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:39:56,695 - INFO - Curriculum advancement check: Performance: 12842.69, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:39:56,695 - INFO - Curriculum advancement check: Performance: 12842.69, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:39:59,607 - INFO - Curriculum advancement check: Performance: 12799.05, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:39:59,607 - INFO - Curriculum advancement check: Performance: 12799.05, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:40:03,866 - INFO - Curriculum advancement check: Performance: 12780.37, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:40:03,866 - INFO - Curriculum advancement check: Performance: 12780.37, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:40:07,221 - INFO - Curriculum advancement check: Performance: 12739.16, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:40:07,221 - INFO - Curriculum advancement check: Performance: 12739.16, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:40:18,089 - INFO - Curriculum advancement check: Performance: 12761.96, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:40:18,089 - INFO - Curriculum advancement check: Performance: 12761.96, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:40:21,329 - INFO - Curriculum advancement check: Performance: 12729.78, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:40:21,329 - INFO - Curriculum advancement check: Performance: 12729.78, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:40:24,129 - INFO - Curriculum advancement check: Performance: 10233.33, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:40:24,129 - INFO - Curriculum advancement check: Performance: 10233.33, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:40:26,990 - INFO - Curriculum advancement check: Performance: 10232.82, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:40:26,990 - INFO - Curriculum advancement check: Performance: 10232.82, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:40:29,428 - INFO - Curriculum advancement check: Performance: 10232.23, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:40:29,428 - INFO - Curriculum advancement check: Performance: 10232.23, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:40:32,142 - INFO - Curriculum advancement check: Performance: 10231.71, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:40:32,142 - INFO - Curriculum advancement check: Performance: 10231.71, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:40:35,011 - INFO - Curriculum advancement check: Performance: 10231.36, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:40:35,011 - INFO - Curriculum advancement check: Performance: 10231.36, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:40:38,259 - INFO - Curriculum advancement check: Performance: 12693.72, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:40:38,259 - INFO - Curriculum advancement check: Performance: 12693.72, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:40:48,103 - INFO - Curriculum advancement check: Performance: 12656.30, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:40:48,103 - INFO - Curriculum advancement check: Performance: 12656.30, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:40:51,023 - INFO - Curriculum advancement check: Performance: 12620.00, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:40:51,023 - INFO - Curriculum advancement check: Performance: 12620.00, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:40:54,251 - INFO - Curriculum advancement check: Performance: 12591.49, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:40:54,251 - INFO - Curriculum advancement check: Performance: 12591.49, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:40:57,546 - INFO - Curriculum advancement check: Performance: 12557.11, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:40:57,546 - INFO - Curriculum advancement check: Performance: 12557.11, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:41:07,849 - INFO - Curriculum advancement check: Performance: 12549.68, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:41:07,849 - INFO - Curriculum advancement check: Performance: 12549.68, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:41:13,080 - INFO - Curriculum advancement check: Performance: 12615.56, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:41:13,080 - INFO - Curriculum advancement check: Performance: 12615.56, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:41:18,686 - INFO - Curriculum advancement check: Performance: 12703.77, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:41:18,686 - INFO - Curriculum advancement check: Performance: 12703.77, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:41:28,919 - INFO - Curriculum advancement check: Performance: 12710.69, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:41:28,919 - INFO - Curriculum advancement check: Performance: 12710.69, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:41:32,443 - INFO - Curriculum advancement check: Performance: 12699.21, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:41:32,443 - INFO - Curriculum advancement check: Performance: 12699.21, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:41:35,295 - INFO - Curriculum advancement check: Performance: 12666.18, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:41:35,295 - INFO - Curriculum advancement check: Performance: 12666.18, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:41:45,374 - INFO - Curriculum advancement check: Performance: 12634.02, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:41:45,374 - INFO - Curriculum advancement check: Performance: 12634.02, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:41:48,550 - INFO - Curriculum advancement check: Performance: 12602.70, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:41:48,550 - INFO - Curriculum advancement check: Performance: 12602.70, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:41:51,531 - INFO - Curriculum advancement check: Performance: 12572.46, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:41:51,531 - INFO - Curriculum advancement check: Performance: 12572.46, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:41:55,179 - INFO - Curriculum advancement check: Performance: 12565.32, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:41:55,179 - INFO - Curriculum advancement check: Performance: 12565.32, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:42:05,809 - INFO - Curriculum advancement check: Performance: 12564.23, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:42:05,809 - INFO - Curriculum advancement check: Performance: 12564.23, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:42:12,525 - INFO - Curriculum advancement check: Performance: 10231.08, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:42:12,525 - INFO - Curriculum advancement check: Performance: 10231.08, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:42:15,461 - INFO - Curriculum advancement check: Performance: 10230.68, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:42:15,461 - INFO - Curriculum advancement check: Performance: 10230.68, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:42:18,195 - INFO - Curriculum advancement check: Performance: 10230.31, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:42:18,195 - INFO - Curriculum advancement check: Performance: 10230.31, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:42:21,013 - INFO - Curriculum advancement check: Performance: 10229.98, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:42:21,013 - INFO - Curriculum advancement check: Performance: 10229.98, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:42:23,565 - INFO - Curriculum advancement check: Performance: 10229.67, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:42:23,565 - INFO - Curriculum advancement check: Performance: 10229.67, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:42:24,275 - INFO - Curriculum advancement check: Performance: 12599.71, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:42:24,275 - INFO - Curriculum advancement check: Performance: 12599.71, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:42:30,284 - INFO - Curriculum advancement check: Performance: 12677.39, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:42:30,284 - INFO - Curriculum advancement check: Performance: 12677.39, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:42:40,521 - INFO - Curriculum advancement check: Performance: 12678.24, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:42:40,521 - INFO - Curriculum advancement check: Performance: 12678.24, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:42:44,669 - INFO - Curriculum advancement check: Performance: 12716.79, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:42:44,669 - INFO - Curriculum advancement check: Performance: 12716.79, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:42:47,745 - INFO - Curriculum advancement check: Performance: 12687.67, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:42:47,745 - INFO - Curriculum advancement check: Performance: 12687.67, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:43:00,848 - INFO - Curriculum advancement check: Performance: 12827.66, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:43:00,848 - INFO - Curriculum advancement check: Performance: 12827.66, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:43:03,896 - INFO - Curriculum advancement check: Performance: 12797.72, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:43:03,896 - INFO - Curriculum advancement check: Performance: 12797.72, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:43:06,602 - INFO - Curriculum advancement check: Performance: 12768.46, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:43:06,602 - INFO - Curriculum advancement check: Performance: 12768.46, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:43:16,110 - INFO - Curriculum advancement check: Performance: 12756.20, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:43:16,110 - INFO - Curriculum advancement check: Performance: 12756.20, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:43:18,753 - INFO - Curriculum advancement check: Performance: 12728.06, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:43:18,753 - INFO - Curriculum advancement check: Performance: 12728.06, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:43:23,074 - INFO - Curriculum advancement check: Performance: 12736.17, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:43:23,074 - INFO - Curriculum advancement check: Performance: 12736.17, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:43:32,696 - INFO - Curriculum advancement check: Performance: 12724.89, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:43:32,696 - INFO - Curriculum advancement check: Performance: 12724.89, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:43:35,329 - INFO - Curriculum advancement check: Performance: 12698.58, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:43:35,329 - INFO - Curriculum advancement check: Performance: 12698.58, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:43:38,272 - INFO - Curriculum advancement check: Performance: 12672.24, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:43:38,272 - INFO - Curriculum advancement check: Performance: 12672.24, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:43:41,387 - INFO - Curriculum advancement check: Performance: 12646.34, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:43:41,387 - INFO - Curriculum advancement check: Performance: 12646.34, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:43:52,132 - INFO - Curriculum advancement check: Performance: 12670.13, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:43:52,132 - INFO - Curriculum advancement check: Performance: 12670.13, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:43:56,392 - INFO - Curriculum advancement check: Performance: 10229.15, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:43:56,392 - INFO - Curriculum advancement check: Performance: 10229.15, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:43:59,654 - INFO - Curriculum advancement check: Performance: 10228.97, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:43:59,654 - INFO - Curriculum advancement check: Performance: 10228.97, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:44:02,267 - INFO - Curriculum advancement check: Performance: 10228.73, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:44:02,267 - INFO - Curriculum advancement check: Performance: 10228.73, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:44:04,918 - INFO - Curriculum advancement check: Performance: 10228.51, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:44:04,918 - INFO - Curriculum advancement check: Performance: 10228.51, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:44:07,595 - INFO - Curriculum advancement check: Performance: 10228.30, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:44:07,595 - INFO - Curriculum advancement check: Performance: 10228.30, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:44:11,970 - INFO - Curriculum advancement check: Performance: 12743.85, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:44:11,970 - INFO - Curriculum advancement check: Performance: 12743.85, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:44:11,971 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:44:11,971 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:44:11,972 - ERROR - An error occurred during experiment kg_completeness_0.3: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:44:11,972 - ERROR - An error occurred during experiment kg_completeness_0.3: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:44:11,976 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 254, in step
    self.simulation_manager.advance_curriculum()
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:44:11,976 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 254, in step
    self.simulation_manager.advance_curriculum()
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:44:11,985 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 23:44:11,985 - INFO - Running experiment: kg_completeness_0.65
2024-08-12 23:44:11,987 - INFO - Using device: cuda
2024-08-12 23:44:11,987 - INFO - Using device: cuda
2024-08-12 23:44:11,987 - INFO - Using device: cuda
2024-08-12 23:44:37,117 - INFO - Curriculum advancement check: Performance: 12105.86, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:44:37,117 - INFO - Curriculum advancement check: Performance: 12105.86, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:44:37,117 - INFO - Curriculum advancement check: Performance: 12105.86, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:44:43,365 - INFO - Curriculum advancement check: Performance: 13861.88, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:44:43,365 - INFO - Curriculum advancement check: Performance: 13861.88, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:44:43,365 - INFO - Curriculum advancement check: Performance: 13861.88, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:44:53,499 - INFO - Curriculum advancement check: Performance: 13749.08, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:44:53,499 - INFO - Curriculum advancement check: Performance: 13749.08, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:44:53,499 - INFO - Curriculum advancement check: Performance: 13749.08, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:44:56,488 - INFO - Curriculum advancement check: Performance: 13363.55, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:44:56,488 - INFO - Curriculum advancement check: Performance: 13363.55, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:44:56,488 - INFO - Curriculum advancement check: Performance: 13363.55, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:44:59,423 - INFO - Curriculum advancement check: Performance: 13063.53, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:44:59,423 - INFO - Curriculum advancement check: Performance: 13063.53, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:44:59,423 - INFO - Curriculum advancement check: Performance: 13063.53, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:45:08,809 - INFO - Curriculum advancement check: Performance: 12783.52, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:45:08,809 - INFO - Curriculum advancement check: Performance: 12783.52, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:45:08,809 - INFO - Curriculum advancement check: Performance: 12783.52, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:45:11,597 - INFO - Curriculum advancement check: Performance: 12572.37, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:45:11,597 - INFO - Curriculum advancement check: Performance: 12572.37, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:45:11,597 - INFO - Curriculum advancement check: Performance: 12572.37, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:45:14,691 - INFO - Curriculum advancement check: Performance: 12506.25, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:45:14,691 - INFO - Curriculum advancement check: Performance: 12506.25, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:45:14,691 - INFO - Curriculum advancement check: Performance: 12506.25, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:45:17,767 - INFO - Curriculum advancement check: Performance: 12356.60, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:45:17,767 - INFO - Curriculum advancement check: Performance: 12356.60, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:45:17,767 - INFO - Curriculum advancement check: Performance: 12356.60, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:45:27,392 - INFO - Curriculum advancement check: Performance: 12261.79, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:45:27,392 - INFO - Curriculum advancement check: Performance: 12261.79, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:45:27,392 - INFO - Curriculum advancement check: Performance: 12261.79, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:45:30,181 - INFO - Curriculum advancement check: Performance: 12130.97, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:45:30,181 - INFO - Curriculum advancement check: Performance: 12130.97, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:45:30,181 - INFO - Curriculum advancement check: Performance: 12130.97, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:45:35,056 - INFO - Curriculum advancement check: Performance: 12485.25, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:45:35,056 - INFO - Curriculum advancement check: Performance: 12485.25, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:45:35,056 - INFO - Curriculum advancement check: Performance: 12485.25, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:45:49,548 - INFO - Curriculum advancement check: Performance: 10225.28, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:45:49,548 - INFO - Curriculum advancement check: Performance: 10225.28, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:45:49,548 - INFO - Curriculum advancement check: Performance: 10225.28, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:45:58,554 - INFO - Curriculum advancement check: Performance: 12399.68, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:45:58,554 - INFO - Curriculum advancement check: Performance: 12399.68, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:45:58,554 - INFO - Curriculum advancement check: Performance: 12399.68, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:46:01,692 - INFO - Curriculum advancement check: Performance: 12313.07, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:46:01,692 - INFO - Curriculum advancement check: Performance: 12313.07, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:46:01,692 - INFO - Curriculum advancement check: Performance: 12313.07, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:46:04,456 - INFO - Curriculum advancement check: Performance: 12216.43, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:46:04,456 - INFO - Curriculum advancement check: Performance: 12216.43, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:46:04,456 - INFO - Curriculum advancement check: Performance: 12216.43, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:46:07,393 - INFO - Curriculum advancement check: Performance: 12117.02, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:46:07,393 - INFO - Curriculum advancement check: Performance: 12117.02, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:46:07,393 - INFO - Curriculum advancement check: Performance: 12117.02, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:46:17,497 - INFO - Curriculum advancement check: Performance: 12114.92, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:46:17,497 - INFO - Curriculum advancement check: Performance: 12114.92, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:46:17,497 - INFO - Curriculum advancement check: Performance: 12114.92, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:46:20,741 - INFO - Curriculum advancement check: Performance: 12098.69, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:46:20,741 - INFO - Curriculum advancement check: Performance: 12098.69, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:46:20,741 - INFO - Curriculum advancement check: Performance: 12098.69, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:46:24,017 - INFO - Curriculum advancement check: Performance: 12101.34, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:46:24,017 - INFO - Curriculum advancement check: Performance: 12101.34, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:46:24,017 - INFO - Curriculum advancement check: Performance: 12101.34, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:46:26,917 - INFO - Curriculum advancement check: Performance: 12031.28, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:46:26,917 - INFO - Curriculum advancement check: Performance: 12031.28, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:46:26,917 - INFO - Curriculum advancement check: Performance: 12031.28, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:46:36,463 - INFO - Curriculum advancement check: Performance: 11996.75, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:46:36,463 - INFO - Curriculum advancement check: Performance: 11996.75, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:46:36,463 - INFO - Curriculum advancement check: Performance: 11996.75, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:46:39,253 - INFO - Curriculum advancement check: Performance: 11930.56, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:46:39,253 - INFO - Curriculum advancement check: Performance: 11930.56, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:46:39,253 - INFO - Curriculum advancement check: Performance: 11930.56, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:46:42,039 - INFO - Curriculum advancement check: Performance: 11874.48, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:46:42,039 - INFO - Curriculum advancement check: Performance: 11874.48, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:46:42,039 - INFO - Curriculum advancement check: Performance: 11874.48, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:46:45,095 - INFO - Curriculum advancement check: Performance: 11845.22, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:46:45,095 - INFO - Curriculum advancement check: Performance: 11845.22, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:46:45,095 - INFO - Curriculum advancement check: Performance: 11845.22, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:46:54,412 - INFO - Curriculum advancement check: Performance: 11792.42, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:46:54,412 - INFO - Curriculum advancement check: Performance: 11792.42, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:46:54,412 - INFO - Curriculum advancement check: Performance: 11792.42, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:46:57,328 - INFO - Curriculum advancement check: Performance: 11744.72, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:46:57,328 - INFO - Curriculum advancement check: Performance: 11744.72, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:46:57,328 - INFO - Curriculum advancement check: Performance: 11744.72, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:47:00,302 - INFO - Curriculum advancement check: Performance: 11696.13, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:47:00,302 - INFO - Curriculum advancement check: Performance: 11696.13, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:47:00,302 - INFO - Curriculum advancement check: Performance: 11696.13, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:47:11,317 - INFO - Curriculum advancement check: Performance: 11838.46, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:47:11,317 - INFO - Curriculum advancement check: Performance: 11838.46, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:47:11,317 - INFO - Curriculum advancement check: Performance: 11838.46, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:47:15,010 - INFO - Curriculum advancement check: Performance: 11925.78, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:47:15,010 - INFO - Curriculum advancement check: Performance: 11925.78, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:47:15,010 - INFO - Curriculum advancement check: Performance: 11925.78, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:47:21,480 - INFO - Curriculum advancement check: Performance: 10250.95, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:47:21,480 - INFO - Curriculum advancement check: Performance: 10250.95, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:47:21,480 - INFO - Curriculum advancement check: Performance: 10250.95, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:47:23,948 - INFO - Curriculum advancement check: Performance: 10246.86, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:47:23,948 - INFO - Curriculum advancement check: Performance: 10246.86, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:47:23,948 - INFO - Curriculum advancement check: Performance: 10246.86, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:47:26,761 - INFO - Curriculum advancement check: Performance: 10244.05, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:47:26,761 - INFO - Curriculum advancement check: Performance: 10244.05, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:47:26,761 - INFO - Curriculum advancement check: Performance: 10244.05, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:47:29,349 - INFO - Curriculum advancement check: Performance: 10241.63, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:47:29,349 - INFO - Curriculum advancement check: Performance: 10241.63, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:47:29,349 - INFO - Curriculum advancement check: Performance: 10241.63, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:47:31,703 - INFO - Curriculum advancement check: Performance: 10239.70, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:47:31,703 - INFO - Curriculum advancement check: Performance: 10239.70, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:47:31,703 - INFO - Curriculum advancement check: Performance: 10239.70, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:47:33,061 - INFO - Curriculum advancement check: Performance: 12089.66, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:47:33,061 - INFO - Curriculum advancement check: Performance: 12089.66, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:47:33,061 - INFO - Curriculum advancement check: Performance: 12089.66, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:47:42,692 - INFO - Curriculum advancement check: Performance: 12075.55, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:47:42,692 - INFO - Curriculum advancement check: Performance: 12075.55, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:47:42,692 - INFO - Curriculum advancement check: Performance: 12075.55, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:47:45,287 - INFO - Curriculum advancement check: Performance: 12024.57, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:47:45,287 - INFO - Curriculum advancement check: Performance: 12024.57, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:47:45,287 - INFO - Curriculum advancement check: Performance: 12024.57, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:47:48,233 - INFO - Curriculum advancement check: Performance: 11985.32, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:47:48,233 - INFO - Curriculum advancement check: Performance: 11985.32, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:47:48,233 - INFO - Curriculum advancement check: Performance: 11985.32, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:47:59,747 - INFO - Curriculum advancement check: Performance: 12165.16, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:47:59,747 - INFO - Curriculum advancement check: Performance: 12165.16, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:47:59,747 - INFO - Curriculum advancement check: Performance: 12165.16, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:48:02,655 - INFO - Curriculum advancement check: Performance: 12115.74, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:48:02,655 - INFO - Curriculum advancement check: Performance: 12115.74, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:48:02,655 - INFO - Curriculum advancement check: Performance: 12115.74, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:48:05,699 - INFO - Curriculum advancement check: Performance: 12068.70, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:48:05,699 - INFO - Curriculum advancement check: Performance: 12068.70, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:48:05,699 - INFO - Curriculum advancement check: Performance: 12068.70, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:48:18,606 - INFO - Curriculum advancement check: Performance: 12340.54, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:48:18,606 - INFO - Curriculum advancement check: Performance: 12340.54, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:48:18,606 - INFO - Curriculum advancement check: Performance: 12340.54, Success rate: 0.00, Plateau counter: 0
2024-08-12 23:48:21,737 - INFO - Curriculum advancement check: Performance: 12290.28, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:48:21,737 - INFO - Curriculum advancement check: Performance: 12290.28, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:48:21,737 - INFO - Curriculum advancement check: Performance: 12290.28, Success rate: 0.00, Plateau counter: 1
2024-08-12 23:48:24,347 - INFO - Curriculum advancement check: Performance: 12242.45, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:48:24,347 - INFO - Curriculum advancement check: Performance: 12242.45, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:48:24,347 - INFO - Curriculum advancement check: Performance: 12242.45, Success rate: 0.00, Plateau counter: 2
2024-08-12 23:48:27,710 - INFO - Curriculum advancement check: Performance: 12207.44, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:48:27,710 - INFO - Curriculum advancement check: Performance: 12207.44, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:48:27,710 - INFO - Curriculum advancement check: Performance: 12207.44, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:48:37,148 - INFO - Curriculum advancement check: Performance: 12163.42, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:48:37,148 - INFO - Curriculum advancement check: Performance: 12163.42, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:48:37,148 - INFO - Curriculum advancement check: Performance: 12163.42, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:48:42,137 - INFO - Curriculum advancement check: Performance: 12319.80, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:48:42,137 - INFO - Curriculum advancement check: Performance: 12319.80, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:48:42,137 - INFO - Curriculum advancement check: Performance: 12319.80, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:48:44,992 - INFO - Curriculum advancement check: Performance: 12275.95, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:48:44,992 - INFO - Curriculum advancement check: Performance: 12275.95, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:48:44,992 - INFO - Curriculum advancement check: Performance: 12275.95, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:48:54,598 - INFO - Curriculum advancement check: Performance: 12260.34, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:48:54,598 - INFO - Curriculum advancement check: Performance: 12260.34, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:48:54,598 - INFO - Curriculum advancement check: Performance: 12260.34, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:48:58,363 - INFO - Curriculum advancement check: Performance: 12271.58, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:48:58,363 - INFO - Curriculum advancement check: Performance: 12271.58, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:48:58,363 - INFO - Curriculum advancement check: Performance: 12271.58, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:49:03,724 - INFO - Curriculum advancement check: Performance: 10238.30, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:49:03,724 - INFO - Curriculum advancement check: Performance: 10238.30, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:49:03,724 - INFO - Curriculum advancement check: Performance: 10238.30, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:49:06,424 - INFO - Curriculum advancement check: Performance: 10236.97, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:49:06,424 - INFO - Curriculum advancement check: Performance: 10236.97, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:49:06,424 - INFO - Curriculum advancement check: Performance: 10236.97, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:49:09,381 - INFO - Curriculum advancement check: Performance: 10243.87, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:49:09,381 - INFO - Curriculum advancement check: Performance: 10243.87, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:49:09,381 - INFO - Curriculum advancement check: Performance: 10243.87, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:49:12,371 - INFO - Curriculum advancement check: Performance: 10244.80, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:49:12,371 - INFO - Curriculum advancement check: Performance: 10244.80, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:49:12,371 - INFO - Curriculum advancement check: Performance: 10244.80, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:49:15,211 - INFO - Curriculum advancement check: Performance: 10243.30, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:49:15,211 - INFO - Curriculum advancement check: Performance: 10243.30, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:49:15,211 - INFO - Curriculum advancement check: Performance: 10243.30, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:49:15,284 - INFO - Curriculum advancement check: Performance: 12232.98, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:49:15,284 - INFO - Curriculum advancement check: Performance: 12232.98, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:49:15,284 - INFO - Curriculum advancement check: Performance: 12232.98, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:49:18,242 - INFO - Curriculum advancement check: Performance: 12193.67, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:49:18,242 - INFO - Curriculum advancement check: Performance: 12193.67, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:49:18,242 - INFO - Curriculum advancement check: Performance: 12193.67, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:49:27,629 - INFO - Curriculum advancement check: Performance: 12156.27, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:49:27,629 - INFO - Curriculum advancement check: Performance: 12156.27, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:49:27,629 - INFO - Curriculum advancement check: Performance: 12156.27, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:49:30,322 - INFO - Curriculum advancement check: Performance: 12124.93, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:49:30,322 - INFO - Curriculum advancement check: Performance: 12124.93, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:49:30,322 - INFO - Curriculum advancement check: Performance: 12124.93, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:49:33,337 - INFO - Curriculum advancement check: Performance: 12090.23, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:49:33,337 - INFO - Curriculum advancement check: Performance: 12090.23, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:49:33,337 - INFO - Curriculum advancement check: Performance: 12090.23, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:49:36,319 - INFO - Curriculum advancement check: Performance: 12056.44, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:49:36,319 - INFO - Curriculum advancement check: Performance: 12056.44, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:49:36,319 - INFO - Curriculum advancement check: Performance: 12056.44, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:49:46,043 - INFO - Curriculum advancement check: Performance: 12026.47, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:49:46,043 - INFO - Curriculum advancement check: Performance: 12026.47, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:49:46,043 - INFO - Curriculum advancement check: Performance: 12026.47, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:49:48,954 - INFO - Curriculum advancement check: Performance: 11994.79, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:49:48,954 - INFO - Curriculum advancement check: Performance: 11994.79, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:49:48,954 - INFO - Curriculum advancement check: Performance: 11994.79, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:49:51,901 - INFO - Curriculum advancement check: Performance: 11964.32, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:49:51,901 - INFO - Curriculum advancement check: Performance: 11964.32, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:49:51,901 - INFO - Curriculum advancement check: Performance: 11964.32, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:49:55,234 - INFO - Curriculum advancement check: Performance: 11946.73, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:49:55,234 - INFO - Curriculum advancement check: Performance: 11946.73, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:49:55,234 - INFO - Curriculum advancement check: Performance: 11946.73, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:50:04,933 - INFO - Curriculum advancement check: Performance: 11927.79, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:50:04,933 - INFO - Curriculum advancement check: Performance: 11927.79, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:50:04,933 - INFO - Curriculum advancement check: Performance: 11927.79, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:50:07,947 - INFO - Curriculum advancement check: Performance: 11906.19, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:50:07,947 - INFO - Curriculum advancement check: Performance: 11906.19, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:50:07,947 - INFO - Curriculum advancement check: Performance: 11906.19, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:50:11,097 - INFO - Curriculum advancement check: Performance: 11879.08, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:50:11,097 - INFO - Curriculum advancement check: Performance: 11879.08, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:50:11,097 - INFO - Curriculum advancement check: Performance: 11879.08, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:50:14,289 - INFO - Curriculum advancement check: Performance: 11862.61, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:50:14,289 - INFO - Curriculum advancement check: Performance: 11862.61, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:50:14,289 - INFO - Curriculum advancement check: Performance: 11862.61, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:50:23,764 - INFO - Curriculum advancement check: Performance: 11837.04, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:50:23,764 - INFO - Curriculum advancement check: Performance: 11837.04, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:50:23,764 - INFO - Curriculum advancement check: Performance: 11837.04, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:50:26,446 - INFO - Curriculum advancement check: Performance: 11812.56, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:50:26,446 - INFO - Curriculum advancement check: Performance: 11812.56, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:50:26,446 - INFO - Curriculum advancement check: Performance: 11812.56, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:50:29,489 - INFO - Curriculum advancement check: Performance: 11788.55, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:50:29,489 - INFO - Curriculum advancement check: Performance: 11788.55, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:50:29,489 - INFO - Curriculum advancement check: Performance: 11788.55, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:50:32,656 - INFO - Curriculum advancement check: Performance: 11765.20, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:50:32,656 - INFO - Curriculum advancement check: Performance: 11765.20, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:50:32,656 - INFO - Curriculum advancement check: Performance: 11765.20, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:50:42,171 - INFO - Curriculum advancement check: Performance: 11746.84, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:50:42,171 - INFO - Curriculum advancement check: Performance: 11746.84, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:50:42,171 - INFO - Curriculum advancement check: Performance: 11746.84, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:50:45,841 - INFO - Curriculum advancement check: Performance: 11784.70, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:50:45,841 - INFO - Curriculum advancement check: Performance: 11784.70, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:50:45,841 - INFO - Curriculum advancement check: Performance: 11784.70, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:50:49,554 - INFO - Curriculum advancement check: Performance: 10241.98, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:50:49,554 - INFO - Curriculum advancement check: Performance: 10241.98, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:50:49,554 - INFO - Curriculum advancement check: Performance: 10241.98, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:50:52,797 - INFO - Curriculum advancement check: Performance: 10243.36, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:50:52,797 - INFO - Curriculum advancement check: Performance: 10243.36, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:50:52,797 - INFO - Curriculum advancement check: Performance: 10243.36, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:50:55,498 - INFO - Curriculum advancement check: Performance: 10242.19, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:50:55,498 - INFO - Curriculum advancement check: Performance: 10242.19, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:50:55,498 - INFO - Curriculum advancement check: Performance: 10242.19, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:50:58,220 - INFO - Curriculum advancement check: Performance: 10241.14, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:50:58,220 - INFO - Curriculum advancement check: Performance: 10241.14, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:50:58,220 - INFO - Curriculum advancement check: Performance: 10241.14, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:51:00,824 - INFO - Curriculum advancement check: Performance: 10244.39, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:51:00,824 - INFO - Curriculum advancement check: Performance: 10244.39, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:51:00,824 - INFO - Curriculum advancement check: Performance: 10244.39, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:51:03,346 - INFO - Curriculum advancement check: Performance: 11762.41, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:51:03,346 - INFO - Curriculum advancement check: Performance: 11762.41, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:51:03,346 - INFO - Curriculum advancement check: Performance: 11762.41, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:51:06,244 - INFO - Curriculum advancement check: Performance: 11741.30, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:51:06,244 - INFO - Curriculum advancement check: Performance: 11741.30, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:51:06,244 - INFO - Curriculum advancement check: Performance: 11741.30, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:51:15,849 - INFO - Curriculum advancement check: Performance: 11723.34, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:51:15,849 - INFO - Curriculum advancement check: Performance: 11723.34, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:51:15,849 - INFO - Curriculum advancement check: Performance: 11723.34, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:51:18,792 - INFO - Curriculum advancement check: Performance: 11706.20, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:51:18,792 - INFO - Curriculum advancement check: Performance: 11706.20, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:51:18,792 - INFO - Curriculum advancement check: Performance: 11706.20, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:51:21,961 - INFO - Curriculum advancement check: Performance: 11705.34, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:51:21,961 - INFO - Curriculum advancement check: Performance: 11705.34, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:51:21,961 - INFO - Curriculum advancement check: Performance: 11705.34, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:51:25,089 - INFO - Curriculum advancement check: Performance: 11687.27, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:51:25,089 - INFO - Curriculum advancement check: Performance: 11687.27, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:51:25,089 - INFO - Curriculum advancement check: Performance: 11687.27, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:51:34,584 - INFO - Curriculum advancement check: Performance: 11667.94, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:51:34,584 - INFO - Curriculum advancement check: Performance: 11667.94, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:51:34,584 - INFO - Curriculum advancement check: Performance: 11667.94, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:51:37,580 - INFO - Curriculum advancement check: Performance: 11650.70, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:51:37,580 - INFO - Curriculum advancement check: Performance: 11650.70, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:51:37,580 - INFO - Curriculum advancement check: Performance: 11650.70, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:51:41,658 - INFO - Curriculum advancement check: Performance: 11668.42, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:51:41,658 - INFO - Curriculum advancement check: Performance: 11668.42, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:51:41,658 - INFO - Curriculum advancement check: Performance: 11668.42, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:51:51,291 - INFO - Curriculum advancement check: Performance: 11656.27, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:51:51,291 - INFO - Curriculum advancement check: Performance: 11656.27, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:51:51,291 - INFO - Curriculum advancement check: Performance: 11656.27, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:51:55,115 - INFO - Curriculum advancement check: Performance: 11667.38, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:51:55,115 - INFO - Curriculum advancement check: Performance: 11667.38, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:51:55,115 - INFO - Curriculum advancement check: Performance: 11667.38, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:51:58,503 - INFO - Curriculum advancement check: Performance: 11659.62, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:51:58,503 - INFO - Curriculum advancement check: Performance: 11659.62, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:51:58,503 - INFO - Curriculum advancement check: Performance: 11659.62, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:52:02,286 - INFO - Curriculum advancement check: Performance: 11651.33, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:52:02,286 - INFO - Curriculum advancement check: Performance: 11651.33, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:52:02,286 - INFO - Curriculum advancement check: Performance: 11651.33, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:52:11,859 - INFO - Curriculum advancement check: Performance: 11634.08, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:52:11,859 - INFO - Curriculum advancement check: Performance: 11634.08, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:52:11,859 - INFO - Curriculum advancement check: Performance: 11634.08, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:52:14,694 - INFO - Curriculum advancement check: Performance: 11617.24, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:52:14,694 - INFO - Curriculum advancement check: Performance: 11617.24, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:52:14,694 - INFO - Curriculum advancement check: Performance: 11617.24, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:52:17,536 - INFO - Curriculum advancement check: Performance: 11602.07, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:52:17,536 - INFO - Curriculum advancement check: Performance: 11602.07, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:52:17,536 - INFO - Curriculum advancement check: Performance: 11602.07, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:52:20,502 - INFO - Curriculum advancement check: Performance: 11585.99, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:52:20,502 - INFO - Curriculum advancement check: Performance: 11585.99, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:52:20,502 - INFO - Curriculum advancement check: Performance: 11585.99, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:52:30,245 - INFO - Curriculum advancement check: Performance: 11570.37, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:52:30,245 - INFO - Curriculum advancement check: Performance: 11570.37, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:52:30,245 - INFO - Curriculum advancement check: Performance: 11570.37, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:52:33,031 - INFO - Curriculum advancement check: Performance: 11556.68, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:52:33,031 - INFO - Curriculum advancement check: Performance: 11556.68, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:52:33,031 - INFO - Curriculum advancement check: Performance: 11556.68, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:52:36,500 - INFO - Curriculum advancement check: Performance: 10243.44, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:52:36,500 - INFO - Curriculum advancement check: Performance: 10243.44, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:52:36,500 - INFO - Curriculum advancement check: Performance: 10243.44, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:52:39,285 - INFO - Curriculum advancement check: Performance: 10242.48, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:52:39,285 - INFO - Curriculum advancement check: Performance: 10242.48, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:52:39,285 - INFO - Curriculum advancement check: Performance: 10242.48, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:52:41,619 - INFO - Curriculum advancement check: Performance: 10241.60, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:52:41,619 - INFO - Curriculum advancement check: Performance: 10241.60, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:52:41,619 - INFO - Curriculum advancement check: Performance: 10241.60, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:52:44,047 - INFO - Curriculum advancement check: Performance: 10240.55, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:52:44,047 - INFO - Curriculum advancement check: Performance: 10240.55, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:52:44,047 - INFO - Curriculum advancement check: Performance: 10240.55, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:52:46,895 - INFO - Curriculum advancement check: Performance: 10239.82, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:52:46,895 - INFO - Curriculum advancement check: Performance: 10239.82, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:52:46,895 - INFO - Curriculum advancement check: Performance: 10239.82, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:52:49,196 - INFO - Curriculum advancement check: Performance: 11541.58, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:52:49,196 - INFO - Curriculum advancement check: Performance: 11541.58, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:52:49,196 - INFO - Curriculum advancement check: Performance: 11541.58, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:52:52,428 - INFO - Curriculum advancement check: Performance: 11533.87, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:52:52,428 - INFO - Curriculum advancement check: Performance: 11533.87, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:52:52,428 - INFO - Curriculum advancement check: Performance: 11533.87, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:53:03,515 - INFO - Curriculum advancement check: Performance: 11569.39, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:53:03,515 - INFO - Curriculum advancement check: Performance: 11569.39, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:53:03,515 - INFO - Curriculum advancement check: Performance: 11569.39, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:53:03,518 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:53:03,518 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:53:03,518 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:53:03,519 - ERROR - An error occurred during experiment kg_completeness_0.65: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:53:03,519 - ERROR - An error occurred during experiment kg_completeness_0.65: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:53:03,519 - ERROR - An error occurred during experiment kg_completeness_0.65: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:53:03,523 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 254, in step
    self.simulation_manager.advance_curriculum()
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:53:03,523 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 254, in step
    self.simulation_manager.advance_curriculum()
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:53:03,523 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 254, in step
    self.simulation_manager.advance_curriculum()
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:53:03,539 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 23:53:03,539 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 23:53:03,539 - INFO - Running experiment: kg_completeness_1.0
2024-08-12 23:53:03,541 - INFO - Using device: cuda
2024-08-12 23:53:03,541 - INFO - Using device: cuda
2024-08-12 23:53:03,541 - INFO - Using device: cuda
2024-08-12 23:53:03,541 - INFO - Using device: cuda
2024-08-12 23:53:31,982 - INFO - Curriculum advancement check: Performance: 14385.36, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:53:31,982 - INFO - Curriculum advancement check: Performance: 14385.36, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:53:31,982 - INFO - Curriculum advancement check: Performance: 14385.36, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:53:31,982 - INFO - Curriculum advancement check: Performance: 14385.36, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:53:41,918 - INFO - Curriculum advancement check: Performance: 14048.12, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:53:41,918 - INFO - Curriculum advancement check: Performance: 14048.12, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:53:41,918 - INFO - Curriculum advancement check: Performance: 14048.12, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:53:41,918 - INFO - Curriculum advancement check: Performance: 14048.12, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:53:46,111 - INFO - Curriculum advancement check: Performance: 14466.97, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:53:46,111 - INFO - Curriculum advancement check: Performance: 14466.97, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:53:46,111 - INFO - Curriculum advancement check: Performance: 14466.97, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:53:46,111 - INFO - Curriculum advancement check: Performance: 14466.97, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:53:49,127 - INFO - Curriculum advancement check: Performance: 13938.41, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:53:49,127 - INFO - Curriculum advancement check: Performance: 13938.41, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:53:49,127 - INFO - Curriculum advancement check: Performance: 13938.41, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:53:49,127 - INFO - Curriculum advancement check: Performance: 13938.41, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:53:52,229 - INFO - Curriculum advancement check: Performance: 13596.80, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:53:52,229 - INFO - Curriculum advancement check: Performance: 13596.80, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:53:52,229 - INFO - Curriculum advancement check: Performance: 13596.80, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:53:52,229 - INFO - Curriculum advancement check: Performance: 13596.80, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:54:01,729 - INFO - Curriculum advancement check: Performance: 13350.33, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:54:01,729 - INFO - Curriculum advancement check: Performance: 13350.33, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:54:01,729 - INFO - Curriculum advancement check: Performance: 13350.33, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:54:01,729 - INFO - Curriculum advancement check: Performance: 13350.33, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:54:05,675 - INFO - Curriculum advancement check: Performance: 13496.63, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:54:05,675 - INFO - Curriculum advancement check: Performance: 13496.63, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:54:05,675 - INFO - Curriculum advancement check: Performance: 13496.63, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:54:05,675 - INFO - Curriculum advancement check: Performance: 13496.63, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:54:08,414 - INFO - Curriculum advancement check: Performance: 13225.45, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:54:08,414 - INFO - Curriculum advancement check: Performance: 13225.45, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:54:08,414 - INFO - Curriculum advancement check: Performance: 13225.45, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:54:08,414 - INFO - Curriculum advancement check: Performance: 13225.45, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:54:19,761 - INFO - Curriculum advancement check: Performance: 13600.34, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:54:19,761 - INFO - Curriculum advancement check: Performance: 13600.34, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:54:19,761 - INFO - Curriculum advancement check: Performance: 13600.34, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:54:19,761 - INFO - Curriculum advancement check: Performance: 13600.34, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:54:23,091 - INFO - Curriculum advancement check: Performance: 13485.18, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:54:23,091 - INFO - Curriculum advancement check: Performance: 13485.18, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:54:23,091 - INFO - Curriculum advancement check: Performance: 13485.18, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:54:23,091 - INFO - Curriculum advancement check: Performance: 13485.18, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:54:26,016 - INFO - Curriculum advancement check: Performance: 13268.60, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:54:26,016 - INFO - Curriculum advancement check: Performance: 13268.60, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:54:26,016 - INFO - Curriculum advancement check: Performance: 13268.60, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:54:26,016 - INFO - Curriculum advancement check: Performance: 13268.60, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:54:37,488 - INFO - Curriculum advancement check: Performance: 10223.12, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:54:37,488 - INFO - Curriculum advancement check: Performance: 10223.12, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:54:37,488 - INFO - Curriculum advancement check: Performance: 10223.12, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:54:37,488 - INFO - Curriculum advancement check: Performance: 10223.12, Success rate: 0.00, Plateau counter: 3
2024-08-12 23:54:46,061 - INFO - Curriculum advancement check: Performance: 13100.15, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:54:46,061 - INFO - Curriculum advancement check: Performance: 13100.15, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:54:46,061 - INFO - Curriculum advancement check: Performance: 13100.15, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:54:46,061 - INFO - Curriculum advancement check: Performance: 13100.15, Success rate: 0.00, Plateau counter: 14
2024-08-12 23:54:49,286 - INFO - Curriculum advancement check: Performance: 13067.58, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:54:49,286 - INFO - Curriculum advancement check: Performance: 13067.58, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:54:49,286 - INFO - Curriculum advancement check: Performance: 13067.58, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:54:49,286 - INFO - Curriculum advancement check: Performance: 13067.58, Success rate: 0.00, Plateau counter: 15
2024-08-12 23:54:52,061 - INFO - Curriculum advancement check: Performance: 12910.45, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:54:52,061 - INFO - Curriculum advancement check: Performance: 12910.45, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:54:52,061 - INFO - Curriculum advancement check: Performance: 12910.45, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:54:52,061 - INFO - Curriculum advancement check: Performance: 12910.45, Success rate: 0.00, Plateau counter: 16
2024-08-12 23:55:03,866 - INFO - Curriculum advancement check: Performance: 13193.12, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:55:03,866 - INFO - Curriculum advancement check: Performance: 13193.12, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:55:03,866 - INFO - Curriculum advancement check: Performance: 13193.12, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:55:03,866 - INFO - Curriculum advancement check: Performance: 13193.12, Success rate: 0.00, Plateau counter: 17
2024-08-12 23:55:06,842 - INFO - Curriculum advancement check: Performance: 13111.17, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:55:06,842 - INFO - Curriculum advancement check: Performance: 13111.17, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:55:06,842 - INFO - Curriculum advancement check: Performance: 13111.17, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:55:06,842 - INFO - Curriculum advancement check: Performance: 13111.17, Success rate: 0.00, Plateau counter: 18
2024-08-12 23:55:09,659 - INFO - Curriculum advancement check: Performance: 12974.32, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:55:09,659 - INFO - Curriculum advancement check: Performance: 12974.32, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:55:09,659 - INFO - Curriculum advancement check: Performance: 12974.32, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:55:09,659 - INFO - Curriculum advancement check: Performance: 12974.32, Success rate: 0.00, Plateau counter: 19
2024-08-12 23:55:13,664 - INFO - Curriculum advancement check: Performance: 13032.41, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:55:13,664 - INFO - Curriculum advancement check: Performance: 13032.41, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:55:13,664 - INFO - Curriculum advancement check: Performance: 13032.41, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:55:13,664 - INFO - Curriculum advancement check: Performance: 13032.41, Success rate: 0.00, Plateau counter: 20
2024-08-12 23:55:23,403 - INFO - Curriculum advancement check: Performance: 12977.10, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:55:23,403 - INFO - Curriculum advancement check: Performance: 12977.10, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:55:23,403 - INFO - Curriculum advancement check: Performance: 12977.10, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:55:23,403 - INFO - Curriculum advancement check: Performance: 12977.10, Success rate: 0.00, Plateau counter: 21
2024-08-12 23:55:26,641 - INFO - Curriculum advancement check: Performance: 12923.76, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:55:26,641 - INFO - Curriculum advancement check: Performance: 12923.76, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:55:26,641 - INFO - Curriculum advancement check: Performance: 12923.76, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:55:26,641 - INFO - Curriculum advancement check: Performance: 12923.76, Success rate: 0.00, Plateau counter: 22
2024-08-12 23:55:29,409 - INFO - Curriculum advancement check: Performance: 12817.11, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:55:29,409 - INFO - Curriculum advancement check: Performance: 12817.11, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:55:29,409 - INFO - Curriculum advancement check: Performance: 12817.11, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:55:29,409 - INFO - Curriculum advancement check: Performance: 12817.11, Success rate: 0.00, Plateau counter: 23
2024-08-12 23:55:41,454 - INFO - Curriculum advancement check: Performance: 13127.18, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:55:41,454 - INFO - Curriculum advancement check: Performance: 13127.18, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:55:41,454 - INFO - Curriculum advancement check: Performance: 13127.18, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:55:41,454 - INFO - Curriculum advancement check: Performance: 13127.18, Success rate: 0.00, Plateau counter: 24
2024-08-12 23:55:44,228 - INFO - Curriculum advancement check: Performance: 13038.11, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:55:44,228 - INFO - Curriculum advancement check: Performance: 13038.11, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:55:44,228 - INFO - Curriculum advancement check: Performance: 13038.11, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:55:44,228 - INFO - Curriculum advancement check: Performance: 13038.11, Success rate: 0.00, Plateau counter: 25
2024-08-12 23:55:47,799 - INFO - Curriculum advancement check: Performance: 13052.03, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:55:47,799 - INFO - Curriculum advancement check: Performance: 13052.03, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:55:47,799 - INFO - Curriculum advancement check: Performance: 13052.03, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:55:47,799 - INFO - Curriculum advancement check: Performance: 13052.03, Success rate: 0.00, Plateau counter: 26
2024-08-12 23:55:57,216 - INFO - Curriculum advancement check: Performance: 12954.93, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:55:57,216 - INFO - Curriculum advancement check: Performance: 12954.93, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:55:57,216 - INFO - Curriculum advancement check: Performance: 12954.93, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:55:57,216 - INFO - Curriculum advancement check: Performance: 12954.93, Success rate: 0.00, Plateau counter: 27
2024-08-12 23:55:59,871 - INFO - Curriculum advancement check: Performance: 12868.43, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:55:59,871 - INFO - Curriculum advancement check: Performance: 12868.43, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:55:59,871 - INFO - Curriculum advancement check: Performance: 12868.43, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:55:59,871 - INFO - Curriculum advancement check: Performance: 12868.43, Success rate: 0.00, Plateau counter: 28
2024-08-12 23:56:03,059 - INFO - Curriculum advancement check: Performance: 12833.19, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:56:03,059 - INFO - Curriculum advancement check: Performance: 12833.19, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:56:03,059 - INFO - Curriculum advancement check: Performance: 12833.19, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:56:03,059 - INFO - Curriculum advancement check: Performance: 12833.19, Success rate: 0.00, Plateau counter: 29
2024-08-12 23:56:07,813 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:56:07,813 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:56:07,813 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:56:07,813 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 4
2024-08-12 23:56:09,823 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:56:09,823 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:56:09,823 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:56:09,823 - INFO - Curriculum advancement check: Performance: 10222.89, Success rate: 0.00, Plateau counter: 5
2024-08-12 23:56:11,991 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:56:11,991 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:56:11,991 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:56:11,991 - INFO - Curriculum advancement check: Performance: 10222.81, Success rate: 0.00, Plateau counter: 6
2024-08-12 23:56:14,028 - INFO - Curriculum advancement check: Performance: 10222.75, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:56:14,028 - INFO - Curriculum advancement check: Performance: 10222.75, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:56:14,028 - INFO - Curriculum advancement check: Performance: 10222.75, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:56:14,028 - INFO - Curriculum advancement check: Performance: 10222.75, Success rate: 0.00, Plateau counter: 7
2024-08-12 23:56:16,098 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:56:16,098 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:56:16,098 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:56:16,098 - INFO - Curriculum advancement check: Performance: 10222.71, Success rate: 0.00, Plateau counter: 8
2024-08-12 23:56:16,995 - INFO - Curriculum advancement check: Performance: 12825.33, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:56:16,995 - INFO - Curriculum advancement check: Performance: 12825.33, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:56:16,995 - INFO - Curriculum advancement check: Performance: 12825.33, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:56:16,995 - INFO - Curriculum advancement check: Performance: 12825.33, Success rate: 0.00, Plateau counter: 30
2024-08-12 23:56:26,448 - INFO - Curriculum advancement check: Performance: 12774.50, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:56:26,448 - INFO - Curriculum advancement check: Performance: 12774.50, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:56:26,448 - INFO - Curriculum advancement check: Performance: 12774.50, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:56:26,448 - INFO - Curriculum advancement check: Performance: 12774.50, Success rate: 0.00, Plateau counter: 31
2024-08-12 23:56:29,291 - INFO - Curriculum advancement check: Performance: 12714.09, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:56:29,291 - INFO - Curriculum advancement check: Performance: 12714.09, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:56:29,291 - INFO - Curriculum advancement check: Performance: 12714.09, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:56:29,291 - INFO - Curriculum advancement check: Performance: 12714.09, Success rate: 0.00, Plateau counter: 32
2024-08-12 23:56:32,038 - INFO - Curriculum advancement check: Performance: 12653.47, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:56:32,038 - INFO - Curriculum advancement check: Performance: 12653.47, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:56:32,038 - INFO - Curriculum advancement check: Performance: 12653.47, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:56:32,038 - INFO - Curriculum advancement check: Performance: 12653.47, Success rate: 0.00, Plateau counter: 33
2024-08-12 23:56:35,868 - INFO - Curriculum advancement check: Performance: 12688.23, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:56:35,868 - INFO - Curriculum advancement check: Performance: 12688.23, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:56:35,868 - INFO - Curriculum advancement check: Performance: 12688.23, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:56:35,868 - INFO - Curriculum advancement check: Performance: 12688.23, Success rate: 0.00, Plateau counter: 34
2024-08-12 23:56:45,102 - INFO - Curriculum advancement check: Performance: 12621.88, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:56:45,102 - INFO - Curriculum advancement check: Performance: 12621.88, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:56:45,102 - INFO - Curriculum advancement check: Performance: 12621.88, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:56:45,102 - INFO - Curriculum advancement check: Performance: 12621.88, Success rate: 0.00, Plateau counter: 35
2024-08-12 23:56:48,389 - INFO - Curriculum advancement check: Performance: 12600.06, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:56:48,389 - INFO - Curriculum advancement check: Performance: 12600.06, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:56:48,389 - INFO - Curriculum advancement check: Performance: 12600.06, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:56:48,389 - INFO - Curriculum advancement check: Performance: 12600.06, Success rate: 0.00, Plateau counter: 36
2024-08-12 23:56:51,313 - INFO - Curriculum advancement check: Performance: 12545.66, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:56:51,313 - INFO - Curriculum advancement check: Performance: 12545.66, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:56:51,313 - INFO - Curriculum advancement check: Performance: 12545.66, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:56:51,313 - INFO - Curriculum advancement check: Performance: 12545.66, Success rate: 0.00, Plateau counter: 37
2024-08-12 23:56:54,453 - INFO - Curriculum advancement check: Performance: 12509.65, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:56:54,453 - INFO - Curriculum advancement check: Performance: 12509.65, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:56:54,453 - INFO - Curriculum advancement check: Performance: 12509.65, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:56:54,453 - INFO - Curriculum advancement check: Performance: 12509.65, Success rate: 0.00, Plateau counter: 38
2024-08-12 23:57:04,524 - INFO - Curriculum advancement check: Performance: 12538.41, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:57:04,524 - INFO - Curriculum advancement check: Performance: 12538.41, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:57:04,524 - INFO - Curriculum advancement check: Performance: 12538.41, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:57:04,524 - INFO - Curriculum advancement check: Performance: 12538.41, Success rate: 0.00, Plateau counter: 39
2024-08-12 23:57:07,466 - INFO - Curriculum advancement check: Performance: 12504.19, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:57:07,466 - INFO - Curriculum advancement check: Performance: 12504.19, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:57:07,466 - INFO - Curriculum advancement check: Performance: 12504.19, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:57:07,466 - INFO - Curriculum advancement check: Performance: 12504.19, Success rate: 0.00, Plateau counter: 40
2024-08-12 23:57:10,977 - INFO - Curriculum advancement check: Performance: 12526.59, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:57:10,977 - INFO - Curriculum advancement check: Performance: 12526.59, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:57:10,977 - INFO - Curriculum advancement check: Performance: 12526.59, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:57:10,977 - INFO - Curriculum advancement check: Performance: 12526.59, Success rate: 0.00, Plateau counter: 41
2024-08-12 23:57:20,862 - INFO - Curriculum advancement check: Performance: 12526.90, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:57:20,862 - INFO - Curriculum advancement check: Performance: 12526.90, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:57:20,862 - INFO - Curriculum advancement check: Performance: 12526.90, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:57:20,862 - INFO - Curriculum advancement check: Performance: 12526.90, Success rate: 0.00, Plateau counter: 42
2024-08-12 23:57:23,755 - INFO - Curriculum advancement check: Performance: 12507.75, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:57:23,755 - INFO - Curriculum advancement check: Performance: 12507.75, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:57:23,755 - INFO - Curriculum advancement check: Performance: 12507.75, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:57:23,755 - INFO - Curriculum advancement check: Performance: 12507.75, Success rate: 0.00, Plateau counter: 43
2024-08-12 23:57:27,120 - INFO - Curriculum advancement check: Performance: 12495.28, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:57:27,120 - INFO - Curriculum advancement check: Performance: 12495.28, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:57:27,120 - INFO - Curriculum advancement check: Performance: 12495.28, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:57:27,120 - INFO - Curriculum advancement check: Performance: 12495.28, Success rate: 0.00, Plateau counter: 44
2024-08-12 23:57:36,637 - INFO - Curriculum advancement check: Performance: 12460.44, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:57:36,637 - INFO - Curriculum advancement check: Performance: 12460.44, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:57:36,637 - INFO - Curriculum advancement check: Performance: 12460.44, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:57:36,637 - INFO - Curriculum advancement check: Performance: 12460.44, Success rate: 0.00, Plateau counter: 45
2024-08-12 23:57:39,354 - INFO - Curriculum advancement check: Performance: 12430.88, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:57:39,354 - INFO - Curriculum advancement check: Performance: 12430.88, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:57:39,354 - INFO - Curriculum advancement check: Performance: 12430.88, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:57:39,354 - INFO - Curriculum advancement check: Performance: 12430.88, Success rate: 0.00, Plateau counter: 46
2024-08-12 23:57:42,636 - INFO - Curriculum advancement check: Performance: 12424.50, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:57:42,636 - INFO - Curriculum advancement check: Performance: 12424.50, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:57:42,636 - INFO - Curriculum advancement check: Performance: 12424.50, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:57:42,636 - INFO - Curriculum advancement check: Performance: 12424.50, Success rate: 0.00, Plateau counter: 47
2024-08-12 23:57:45,458 - INFO - Curriculum advancement check: Performance: 10222.86, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:57:45,458 - INFO - Curriculum advancement check: Performance: 10222.86, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:57:45,458 - INFO - Curriculum advancement check: Performance: 10222.86, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:57:45,458 - INFO - Curriculum advancement check: Performance: 10222.86, Success rate: 0.00, Plateau counter: 9
2024-08-12 23:57:47,524 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:57:47,524 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:57:47,524 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:57:47,524 - INFO - Curriculum advancement check: Performance: 10222.99, Success rate: 0.00, Plateau counter: 10
2024-08-12 23:57:49,479 - INFO - Curriculum advancement check: Performance: 10223.09, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:57:49,479 - INFO - Curriculum advancement check: Performance: 10223.09, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:57:49,479 - INFO - Curriculum advancement check: Performance: 10223.09, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:57:49,479 - INFO - Curriculum advancement check: Performance: 10223.09, Success rate: 0.00, Plateau counter: 11
2024-08-12 23:57:51,433 - INFO - Curriculum advancement check: Performance: 10223.18, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:57:51,433 - INFO - Curriculum advancement check: Performance: 10223.18, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:57:51,433 - INFO - Curriculum advancement check: Performance: 10223.18, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:57:51,433 - INFO - Curriculum advancement check: Performance: 10223.18, Success rate: 0.00, Plateau counter: 12
2024-08-12 23:57:53,415 - INFO - Curriculum advancement check: Performance: 10223.26, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:57:53,415 - INFO - Curriculum advancement check: Performance: 10223.26, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:57:53,415 - INFO - Curriculum advancement check: Performance: 10223.26, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:57:53,415 - INFO - Curriculum advancement check: Performance: 10223.26, Success rate: 0.00, Plateau counter: 13
2024-08-12 23:57:55,835 - INFO - Curriculum advancement check: Performance: 12387.92, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:57:55,835 - INFO - Curriculum advancement check: Performance: 12387.92, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:57:55,835 - INFO - Curriculum advancement check: Performance: 12387.92, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:57:55,835 - INFO - Curriculum advancement check: Performance: 12387.92, Success rate: 0.00, Plateau counter: 48
2024-08-12 23:58:05,553 - INFO - Curriculum advancement check: Performance: 12372.55, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:58:05,553 - INFO - Curriculum advancement check: Performance: 12372.55, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:58:05,553 - INFO - Curriculum advancement check: Performance: 12372.55, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:58:05,553 - INFO - Curriculum advancement check: Performance: 12372.55, Success rate: 0.00, Plateau counter: 49
2024-08-12 23:58:08,098 - INFO - Curriculum advancement check: Performance: 12334.13, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:58:08,098 - INFO - Curriculum advancement check: Performance: 12334.13, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:58:08,098 - INFO - Curriculum advancement check: Performance: 12334.13, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:58:08,098 - INFO - Curriculum advancement check: Performance: 12334.13, Success rate: 0.00, Plateau counter: 50
2024-08-12 23:58:08,101 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:58:08,101 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:58:08,101 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:58:08,101 - INFO - Advancing curriculum due to performance plateau.
2024-08-12 23:58:08,103 - ERROR - An error occurred during experiment kg_completeness_1.0: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:58:08,103 - ERROR - An error occurred during experiment kg_completeness_1.0: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:58:08,103 - ERROR - An error occurred during experiment kg_completeness_1.0: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:58:08,103 - ERROR - An error occurred during experiment kg_completeness_1.0: 'SimulationManager' object has no attribute 'logger'
2024-08-12 23:58:08,107 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 254, in step
    self.simulation_manager.advance_curriculum()
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:58:08,107 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 254, in step
    self.simulation_manager.advance_curriculum()
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:58:08,107 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 254, in step
    self.simulation_manager.advance_curriculum()
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:58:08,107 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 254, in step
    self.simulation_manager.advance_curriculum()
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 116, in advance_curriculum
    self.logger.info(f"Advanced to curriculum level {self.current_curriculum_index}. "
    ^^^^^^^^^^^
AttributeError: 'SimulationManager' object has no attribute 'logger'

2024-08-12 23:58:08,135 - INFO - Ablation study results saved to results\20240812_233342\ablation_study_results.json
2024-08-12 23:58:08,135 - INFO - Ablation study results saved to results\20240812_233342\ablation_study_results.json
2024-08-12 23:58:08,135 - INFO - Ablation study results saved to results\20240812_233342\ablation_study_results.json
2024-08-12 23:58:08,135 - INFO - Ablation study results saved to results\20240812_233342\ablation_study_results.json
2024-08-12 23:58:08,138 - INFO - Base configuration saved to results\20240812_233342\base_config.json
2024-08-12 23:58:08,138 - INFO - Base configuration saved to results\20240812_233342\base_config.json
2024-08-12 23:58:08,138 - INFO - Base configuration saved to results\20240812_233342\base_config.json
2024-08-12 23:58:08,138 - INFO - Base configuration saved to results\20240812_233342\base_config.json
2024-08-12 23:58:08,140 - INFO - Ablation Study completed
2024-08-12 23:58:08,140 - INFO - Ablation Study completed
2024-08-12 23:58:08,140 - INFO - Ablation Study completed
2024-08-12 23:58:08,140 - INFO - Ablation Study completed
2024-08-13 07:38:41,872 - INFO - Created results directory: results\20240813_073841
2024-08-13 07:38:41,872 - INFO - Starting Ablation Study
2024-08-13 07:38:41,873 - INFO - Running experiment: kg_completeness_0.3
2024-08-13 07:38:41,901 - INFO - Using device: cuda
2024-08-13 07:38:41,901 - INFO - Using device: cuda
2024-08-13 07:44:39,975 - ERROR - An error occurred during experiment kg_completeness_0.3: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-13 07:44:39,975 - ERROR - An error occurred during experiment kg_completeness_0.3: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-13 07:44:39,992 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 256, in step
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-13 07:44:39,992 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 256, in step
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-13 07:44:39,999 - INFO - Running experiment: kg_completeness_0.65
2024-08-13 07:44:39,999 - INFO - Running experiment: kg_completeness_0.65
2024-08-13 07:44:40,000 - INFO - Using device: cuda
2024-08-13 07:44:40,000 - INFO - Using device: cuda
2024-08-13 07:44:40,000 - INFO - Using device: cuda
2024-08-13 07:51:01,370 - ERROR - An error occurred during experiment kg_completeness_0.65: Tried to step environment that needs reset
2024-08-13 07:51:01,370 - ERROR - An error occurred during experiment kg_completeness_0.65: Tried to step environment that needs reset
2024-08-13 07:51:01,370 - ERROR - An error occurred during experiment kg_completeness_0.65: Tried to step environment that needs reset
2024-08-13 07:51:01,373 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-13 07:51:01,373 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-13 07:51:01,373 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-13 07:51:01,378 - INFO - Running experiment: kg_completeness_1.0
2024-08-13 07:51:01,378 - INFO - Running experiment: kg_completeness_1.0
2024-08-13 07:51:01,378 - INFO - Running experiment: kg_completeness_1.0
2024-08-13 07:51:01,381 - INFO - Using device: cuda
2024-08-13 07:51:01,381 - INFO - Using device: cuda
2024-08-13 07:51:01,381 - INFO - Using device: cuda
2024-08-13 07:51:01,381 - INFO - Using device: cuda
2024-08-13 07:52:58,755 - ERROR - An error occurred during experiment kg_completeness_1.0: Tried to step environment that needs reset
2024-08-13 07:52:58,755 - ERROR - An error occurred during experiment kg_completeness_1.0: Tried to step environment that needs reset
2024-08-13 07:52:58,755 - ERROR - An error occurred during experiment kg_completeness_1.0: Tried to step environment that needs reset
2024-08-13 07:52:58,755 - ERROR - An error occurred during experiment kg_completeness_1.0: Tried to step environment that needs reset
2024-08-13 07:52:58,758 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-13 07:52:58,758 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-13 07:52:58,758 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-13 07:52:58,758 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 80, in train
    self.rl_model.learn(total_timesteps=1, callback=eval_callback, reset_num_timesteps=False)
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 93, in step
    raise RuntimeError("Tried to step environment that needs reset")
RuntimeError: Tried to step environment that needs reset

2024-08-13 07:52:58,797 - INFO - Ablation study results saved to results\20240813_073841\ablation_study_results.json
2024-08-13 07:52:58,797 - INFO - Ablation study results saved to results\20240813_073841\ablation_study_results.json
2024-08-13 07:52:58,797 - INFO - Ablation study results saved to results\20240813_073841\ablation_study_results.json
2024-08-13 07:52:58,797 - INFO - Ablation study results saved to results\20240813_073841\ablation_study_results.json
2024-08-13 07:52:58,799 - INFO - Base configuration saved to results\20240813_073841\base_config.json
2024-08-13 07:52:58,799 - INFO - Base configuration saved to results\20240813_073841\base_config.json
2024-08-13 07:52:58,799 - INFO - Base configuration saved to results\20240813_073841\base_config.json
2024-08-13 07:52:58,799 - INFO - Base configuration saved to results\20240813_073841\base_config.json
2024-08-13 07:52:58,800 - INFO - Ablation Study completed
2024-08-13 07:52:58,800 - INFO - Ablation Study completed
2024-08-13 07:52:58,800 - INFO - Ablation Study completed
2024-08-13 07:52:58,800 - INFO - Ablation Study completed
2024-08-13 22:07:29,645 - INFO - Created results directory: results\20240813_220729
2024-08-13 22:07:29,646 - INFO - Starting Ablation Study
2024-08-13 22:07:29,646 - INFO - Running experiment: kg_completeness_1
2024-08-13 22:07:29,719 - INFO - Using device: cuda
2024-08-13 22:07:29,719 - INFO - Using device: cuda
2024-08-13 22:07:53,768 - ERROR - An error occurred during experiment kg_completeness_1: property 'logger' of 'CurriculumCallback' object has no setter
2024-08-13 22:07:53,768 - ERROR - An error occurred during experiment kg_completeness_1: property 'logger' of 'CurriculumCallback' object has no setter
2024-08-13 22:07:53,769 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 82, in train
    curriculum_callback = CurriculumCallback(self.eval_env, self.logger)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 40, in __init__
    self.logger = logger
    ^^^^^^^^^^^
AttributeError: property 'logger' of 'CurriculumCallback' object has no setter

2024-08-13 22:07:53,769 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 235, in run
    self.model_trainer.train(
  File "c:\Users\anton\Dev\ABM\training.py", line 82, in train
    curriculum_callback = CurriculumCallback(self.eval_env, self.logger)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 40, in __init__
    self.logger = logger
    ^^^^^^^^^^^
AttributeError: property 'logger' of 'CurriculumCallback' object has no setter

2024-08-13 22:07:53,772 - INFO - Ablation study results saved to results\20240813_220729\ablation_study_results.json
2024-08-13 22:07:53,772 - INFO - Ablation study results saved to results\20240813_220729\ablation_study_results.json
2024-08-13 22:07:53,773 - INFO - Base configuration saved to results\20240813_220729\base_config.json
2024-08-13 22:07:53,773 - INFO - Base configuration saved to results\20240813_220729\base_config.json
2024-08-13 22:07:53,773 - INFO - Ablation Study completed
2024-08-13 22:07:53,773 - INFO - Ablation Study completed
2024-08-13 22:09:34,552 - INFO - Created results directory: results\20240813_220934
2024-08-13 22:09:34,552 - INFO - Starting Ablation Study
2024-08-13 22:09:34,552 - INFO - Running experiment: kg_completeness_1
2024-08-13 22:09:34,574 - INFO - Using device: cuda
2024-08-13 22:09:34,574 - INFO - Using device: cuda
2024-08-13 22:09:56,664 - ERROR - An error occurred during training: cannot unpack non-iterable NoneType object
2024-08-13 22:09:56,664 - ERROR - An error occurred during training: cannot unpack non-iterable NoneType object
2024-08-13 22:09:56,677 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 85, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 287, in learn
    total_timesteps, callback = self._setup_learn(
                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 423, in _setup_learn
    self._last_obs = self.env.reset()  # type: ignore[assignment]
                     ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 77, in reset
    obs, self.reset_infos[env_idx] = self.envs[env_idx].reset(seed=self._seeds[env_idx], **maybe_options)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cannot unpack non-iterable NoneType object

2024-08-13 22:09:56,677 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 85, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 287, in learn
    total_timesteps, callback = self._setup_learn(
                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 423, in _setup_learn
    self._last_obs = self.env.reset()  # type: ignore[assignment]
                     ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 77, in reset
    obs, self.reset_infos[env_idx] = self.envs[env_idx].reset(seed=self._seeds[env_idx], **maybe_options)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cannot unpack non-iterable NoneType object

2024-08-13 22:09:56,682 - INFO - Profiling stats saved to results\20240813_220934\kg_completeness_1\profile_stats.txt
2024-08-13 22:09:56,682 - INFO - Profiling stats saved to results\20240813_220934\kg_completeness_1\profile_stats.txt
2024-08-13 22:09:56,841 - ERROR - An error occurred during experiment kg_completeness_1: cannot unpack non-iterable NoneType object
2024-08-13 22:09:56,841 - ERROR - An error occurred during experiment kg_completeness_1: cannot unpack non-iterable NoneType object
2024-08-13 22:09:56,843 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 248, in run
    mean_reward, std_reward = self.model_trainer.evaluate_model(self.eval_env)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 126, in evaluate_model
    mean_reward, std_reward = evaluate_policy(self.rl_model, eval_env, n_eval_episodes=n_eval_episodes)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\evaluation.py", line 84, in evaluate_policy
    observations = env.reset()
                   ^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 77, in reset
    obs, self.reset_infos[env_idx] = self.envs[env_idx].reset(seed=self._seeds[env_idx], **maybe_options)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cannot unpack non-iterable NoneType object

2024-08-13 22:09:56,843 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 163, in run
    result = trainer.run(experiment_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 248, in run
    mean_reward, std_reward = self.model_trainer.evaluate_model(self.eval_env)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 126, in evaluate_model
    mean_reward, std_reward = evaluate_policy(self.rl_model, eval_env, n_eval_episodes=n_eval_episodes)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\evaluation.py", line 84, in evaluate_policy
    observations = env.reset()
                   ^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 77, in reset
    obs, self.reset_infos[env_idx] = self.envs[env_idx].reset(seed=self._seeds[env_idx], **maybe_options)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cannot unpack non-iterable NoneType object

2024-08-13 22:09:56,847 - INFO - Ablation study results saved to results\20240813_220934\ablation_study_results.json
2024-08-13 22:09:56,847 - INFO - Ablation study results saved to results\20240813_220934\ablation_study_results.json
2024-08-13 22:09:56,847 - INFO - Base configuration saved to results\20240813_220934\base_config.json
2024-08-13 22:09:56,847 - INFO - Base configuration saved to results\20240813_220934\base_config.json
2024-08-13 22:09:56,847 - INFO - Ablation Study completed
2024-08-13 22:09:56,847 - INFO - Ablation Study completed
2024-08-13 22:16:27,924 - INFO - Created results directory: results\20240813_221627
2024-08-13 22:16:27,925 - INFO - Starting Ablation Study
2024-08-13 22:16:27,925 - INFO - Running experiment: kg_completeness_1
2024-08-13 22:16:27,947 - INFO - Using device: cuda
2024-08-13 22:16:27,947 - INFO - Using device: cuda
2024-08-13 22:16:51,481 - ERROR - An error occurred during training: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`
2024-08-13 22:16:51,481 - ERROR - An error occurred during training: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`
2024-08-13 22:16:51,484 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 85, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 287, in learn
    total_timesteps, callback = self._setup_learn(
                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 434, in _setup_learn
    callback = self._init_callback(callback, progress_bar)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 378, in _init_callback
    callback = CallbackList([callback, ProgressBarCallback()])
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\callbacks.py", line 690, in __init__
    raise ImportError(
ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`

2024-08-13 22:16:51,484 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 85, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 287, in learn
    total_timesteps, callback = self._setup_learn(
                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 434, in _setup_learn
    callback = self._init_callback(callback, progress_bar)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 378, in _init_callback
    callback = CallbackList([callback, ProgressBarCallback()])
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\callbacks.py", line 690, in __init__
    raise ImportError(
ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`

2024-08-13 22:16:51,493 - INFO - Profiling stats saved to results\20240813_221627\kg_completeness_1\profile_stats.txt
2024-08-13 22:16:51,493 - INFO - Profiling stats saved to results\20240813_221627\kg_completeness_1\profile_stats.txt
2024-08-13 22:17:12,565 - INFO - Training and evaluation completed.
2024-08-13 22:17:12,565 - INFO - Training and evaluation completed.
2024-08-13 22:17:12,565 - INFO - Experiment kg_completeness_1 completed
2024-08-13 22:17:12,565 - INFO - Experiment kg_completeness_1 completed
2024-08-13 22:17:12,566 - INFO - Ablation study results saved to results\20240813_221627\ablation_study_results.json
2024-08-13 22:17:12,566 - INFO - Ablation study results saved to results\20240813_221627\ablation_study_results.json
2024-08-13 22:17:12,568 - INFO - Individual experiment results saved to results\20240813_221627\kg_completeness_1_results.json
2024-08-13 22:17:12,568 - INFO - Individual experiment results saved to results\20240813_221627\kg_completeness_1_results.json
2024-08-13 22:17:12,568 - INFO - Base configuration saved to results\20240813_221627\base_config.json
2024-08-13 22:17:12,568 - INFO - Base configuration saved to results\20240813_221627\base_config.json
2024-08-13 22:17:12,569 - INFO - Ablation Study completed
2024-08-13 22:17:12,569 - INFO - Ablation Study completed
2024-08-13 22:19:24,147 - INFO - Created results directory: results\20240813_221924
2024-08-13 22:19:24,148 - INFO - Starting Ablation Study
2024-08-13 22:19:24,148 - INFO - Running experiment: kg_completeness_1
2024-08-13 22:19:24,170 - INFO - Using device: cuda
2024-08-13 22:19:24,170 - INFO - Using device: cuda
2024-08-13 22:19:45,507 - ERROR - An error occurred during training: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`
2024-08-13 22:19:45,507 - ERROR - An error occurred during training: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`
2024-08-13 22:19:45,511 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 85, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 287, in learn
    total_timesteps, callback = self._setup_learn(
                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 434, in _setup_learn
    callback = self._init_callback(callback, progress_bar)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 378, in _init_callback
    callback = CallbackList([callback, ProgressBarCallback()])
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\callbacks.py", line 690, in __init__
    raise ImportError(
ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`

2024-08-13 22:19:45,511 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 85, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 287, in learn
    total_timesteps, callback = self._setup_learn(
                                ^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 434, in _setup_learn
    callback = self._init_callback(callback, progress_bar)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\base_class.py", line 378, in _init_callback
    callback = CallbackList([callback, ProgressBarCallback()])
                                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\callbacks.py", line 690, in __init__
    raise ImportError(
ImportError: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`

2024-08-13 22:19:45,521 - INFO - Profiling stats saved to results\20240813_221924\kg_completeness_1\profile_stats.txt
2024-08-13 22:19:45,521 - INFO - Profiling stats saved to results\20240813_221924\kg_completeness_1\profile_stats.txt
2024-08-13 22:20:03,260 - INFO - Training and evaluation completed.
2024-08-13 22:20:03,260 - INFO - Training and evaluation completed.
2024-08-13 22:20:03,261 - INFO - Experiment kg_completeness_1 completed
2024-08-13 22:20:03,261 - INFO - Experiment kg_completeness_1 completed
2024-08-13 22:20:03,262 - INFO - Ablation study results saved to results\20240813_221924\ablation_study_results.json
2024-08-13 22:20:03,262 - INFO - Ablation study results saved to results\20240813_221924\ablation_study_results.json
2024-08-13 22:20:03,263 - INFO - Individual experiment results saved to results\20240813_221924\kg_completeness_1_results.json
2024-08-13 22:20:03,263 - INFO - Individual experiment results saved to results\20240813_221924\kg_completeness_1_results.json
2024-08-13 22:20:03,264 - INFO - Base configuration saved to results\20240813_221924\base_config.json
2024-08-13 22:20:03,264 - INFO - Base configuration saved to results\20240813_221924\base_config.json
2024-08-13 22:20:03,264 - INFO - Ablation Study completed
2024-08-13 22:20:03,264 - INFO - Ablation Study completed
2024-08-13 22:27:58,216 - INFO - Created results directory: results\20240813_222758
2024-08-13 22:27:58,216 - INFO - Starting Ablation Study
2024-08-13 22:27:58,216 - INFO - Running experiment: kg_completeness_1
2024-08-13 22:27:58,234 - INFO - Using device: cuda
2024-08-13 22:27:58,234 - INFO - Using device: cuda
2024-08-13 22:28:37,070 - INFO - Profiling stats saved to results\20240813_222758\kg_completeness_1\profile_stats.txt
2024-08-13 22:28:37,070 - INFO - Profiling stats saved to results\20240813_222758\kg_completeness_1\profile_stats.txt
2024-08-13 22:28:53,799 - INFO - Training and evaluation completed.
2024-08-13 22:28:53,799 - INFO - Training and evaluation completed.
2024-08-13 22:28:53,801 - INFO - Experiment kg_completeness_1 completed
2024-08-13 22:28:53,801 - INFO - Experiment kg_completeness_1 completed
2024-08-13 22:28:53,802 - INFO - Ablation study results saved to results\20240813_222758\ablation_study_results.json
2024-08-13 22:28:53,802 - INFO - Ablation study results saved to results\20240813_222758\ablation_study_results.json
2024-08-13 22:28:53,803 - INFO - Individual experiment results saved to results\20240813_222758\kg_completeness_1_results.json
2024-08-13 22:28:53,803 - INFO - Individual experiment results saved to results\20240813_222758\kg_completeness_1_results.json
2024-08-13 22:28:53,804 - INFO - Base configuration saved to results\20240813_222758\base_config.json
2024-08-13 22:28:53,804 - INFO - Base configuration saved to results\20240813_222758\base_config.json
2024-08-13 22:28:53,804 - INFO - Ablation Study completed
2024-08-13 22:28:53,804 - INFO - Ablation Study completed
2024-08-13 22:32:54,350 - INFO - Created results directory: results\20240813_223254
2024-08-13 22:32:54,350 - INFO - Starting Ablation Study
2024-08-13 22:32:54,350 - INFO - Running experiment: kg_completeness_0.3
2024-08-13 22:32:54,375 - INFO - Using device: cuda
2024-08-13 22:32:54,375 - INFO - Using device: cuda
2024-08-13 22:37:40,042 - INFO - Created results directory: results\20240813_223740
2024-08-13 22:37:40,042 - INFO - Starting Ablation Study
2024-08-13 22:37:40,043 - INFO - Running experiment: kg_completeness_0.3
2024-08-13 22:37:40,065 - INFO - Using device: cuda
2024-08-13 22:37:40,065 - INFO - Using device: cuda
2024-08-13 22:42:13,676 - INFO - Created results directory: results\20240813_224213
2024-08-13 22:42:13,676 - INFO - Starting Ablation Study
2024-08-13 22:42:13,677 - INFO - Running experiment: kg_completeness_0.3
2024-08-13 22:42:13,698 - INFO - Using device: cuda
2024-08-13 22:42:13,698 - INFO - Using device: cuda
2024-08-13 22:55:51,851 - ERROR - An error occurred during training: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-13 22:55:51,851 - ERROR - An error occurred during training: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given
2024-08-13 22:55:51,854 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 85, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 255, in step
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-13 22:55:51,854 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 85, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 255, in step
    self.set_current_game_manager(self.current_game_index)
TypeError: CustomEnv.set_current_game_manager() takes 1 positional argument but 2 were given

2024-08-13 22:55:51,875 - INFO - Profiling stats saved to results\20240813_224213\kg_completeness_0.3\profile_stats.txt
2024-08-13 22:55:51,875 - INFO - Profiling stats saved to results\20240813_224213\kg_completeness_0.3\profile_stats.txt
2024-08-13 22:56:12,186 - INFO - Training and evaluation completed.
2024-08-13 22:56:12,186 - INFO - Training and evaluation completed.
2024-08-13 22:56:12,187 - INFO - Experiment kg_completeness_0.3 completed
2024-08-13 22:56:12,187 - INFO - Experiment kg_completeness_0.3 completed
2024-08-13 22:56:12,189 - INFO - Running experiment: kg_completeness_0.65
2024-08-13 22:56:12,189 - INFO - Running experiment: kg_completeness_0.65
2024-08-13 22:56:12,190 - INFO - Using device: cuda
2024-08-13 22:56:12,190 - INFO - Using device: cuda
2024-08-13 22:56:12,190 - INFO - Using device: cuda
2024-08-13 23:14:51,905 - INFO - Created results directory: results\20240813_231451
2024-08-13 23:14:51,906 - INFO - Starting Ablation Study
2024-08-13 23:14:51,906 - INFO - Running experiment: kg_completeness_0.3
2024-08-13 23:14:51,930 - INFO - Using device: cuda
2024-08-13 23:14:51,930 - INFO - Using device: cuda
2024-08-14 02:22:28,516 - INFO - Profiling stats saved to results\20240813_231451\kg_completeness_0.3\profile_stats.txt
2024-08-14 02:22:28,516 - INFO - Profiling stats saved to results\20240813_231451\kg_completeness_0.3\profile_stats.txt
2024-08-14 02:22:44,716 - INFO - Training and evaluation completed.
2024-08-14 02:22:44,716 - INFO - Training and evaluation completed.
2024-08-14 02:22:44,717 - INFO - Experiment kg_completeness_0.3 completed
2024-08-14 02:22:44,717 - INFO - Experiment kg_completeness_0.3 completed
2024-08-14 02:22:44,718 - INFO - Running experiment: kg_completeness_0.65
2024-08-14 02:22:44,718 - INFO - Running experiment: kg_completeness_0.65
2024-08-14 02:22:44,719 - INFO - Using device: cuda
2024-08-14 02:22:44,719 - INFO - Using device: cuda
2024-08-14 02:22:44,719 - INFO - Using device: cuda
2024-08-14 05:24:17,047 - INFO - Profiling stats saved to results\20240813_231451\kg_completeness_0.65\profile_stats.txt
2024-08-14 05:24:17,047 - INFO - Profiling stats saved to results\20240813_231451\kg_completeness_0.65\profile_stats.txt
2024-08-14 05:24:17,047 - INFO - Profiling stats saved to results\20240813_231451\kg_completeness_0.65\profile_stats.txt
2024-08-14 05:24:33,204 - INFO - Training and evaluation completed.
2024-08-14 05:24:33,204 - INFO - Training and evaluation completed.
2024-08-14 05:24:33,204 - INFO - Training and evaluation completed.
2024-08-14 05:24:33,206 - INFO - Experiment kg_completeness_0.65 completed
2024-08-14 05:24:33,206 - INFO - Experiment kg_completeness_0.65 completed
2024-08-14 05:24:33,206 - INFO - Experiment kg_completeness_0.65 completed
2024-08-14 05:24:33,207 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 05:24:33,207 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 05:24:33,207 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 05:24:33,209 - INFO - Using device: cuda
2024-08-14 05:24:33,209 - INFO - Using device: cuda
2024-08-14 05:24:33,209 - INFO - Using device: cuda
2024-08-14 05:24:33,209 - INFO - Using device: cuda
2024-08-14 08:26:04,189 - INFO - Profiling stats saved to results\20240813_231451\kg_completeness_1.0\profile_stats.txt
2024-08-14 08:26:04,189 - INFO - Profiling stats saved to results\20240813_231451\kg_completeness_1.0\profile_stats.txt
2024-08-14 08:26:04,189 - INFO - Profiling stats saved to results\20240813_231451\kg_completeness_1.0\profile_stats.txt
2024-08-14 08:26:04,189 - INFO - Profiling stats saved to results\20240813_231451\kg_completeness_1.0\profile_stats.txt
2024-08-14 08:26:20,550 - INFO - Training and evaluation completed.
2024-08-14 08:26:20,550 - INFO - Training and evaluation completed.
2024-08-14 08:26:20,550 - INFO - Training and evaluation completed.
2024-08-14 08:26:20,550 - INFO - Training and evaluation completed.
2024-08-14 08:26:20,552 - INFO - Experiment kg_completeness_1.0 completed
2024-08-14 08:26:20,552 - INFO - Experiment kg_completeness_1.0 completed
2024-08-14 08:26:20,552 - INFO - Experiment kg_completeness_1.0 completed
2024-08-14 08:26:20,552 - INFO - Experiment kg_completeness_1.0 completed
2024-08-14 08:26:20,555 - INFO - Ablation study results saved to results\20240813_231451\ablation_study_results.json
2024-08-14 08:26:20,555 - INFO - Ablation study results saved to results\20240813_231451\ablation_study_results.json
2024-08-14 08:26:20,555 - INFO - Ablation study results saved to results\20240813_231451\ablation_study_results.json
2024-08-14 08:26:20,555 - INFO - Ablation study results saved to results\20240813_231451\ablation_study_results.json
2024-08-14 08:26:20,556 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_0.3_results.json
2024-08-14 08:26:20,556 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_0.3_results.json
2024-08-14 08:26:20,556 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_0.3_results.json
2024-08-14 08:26:20,556 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_0.3_results.json
2024-08-14 08:26:20,556 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_0.65_results.json
2024-08-14 08:26:20,556 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_0.65_results.json
2024-08-14 08:26:20,556 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_0.65_results.json
2024-08-14 08:26:20,556 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_0.65_results.json
2024-08-14 08:26:20,559 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_1.0_results.json
2024-08-14 08:26:20,559 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_1.0_results.json
2024-08-14 08:26:20,559 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_1.0_results.json
2024-08-14 08:26:20,559 - INFO - Individual experiment results saved to results\20240813_231451\kg_completeness_1.0_results.json
2024-08-14 08:26:20,560 - INFO - Base configuration saved to results\20240813_231451\base_config.json
2024-08-14 08:26:20,560 - INFO - Base configuration saved to results\20240813_231451\base_config.json
2024-08-14 08:26:20,560 - INFO - Base configuration saved to results\20240813_231451\base_config.json
2024-08-14 08:26:20,560 - INFO - Base configuration saved to results\20240813_231451\base_config.json
2024-08-14 08:26:20,560 - INFO - Ablation Study completed
2024-08-14 08:26:20,560 - INFO - Ablation Study completed
2024-08-14 08:26:20,560 - INFO - Ablation Study completed
2024-08-14 08:26:20,560 - INFO - Ablation Study completed
2024-08-14 22:23:18,957 - INFO - Created results directory: results\20240814_222318
2024-08-14 22:23:18,958 - INFO - Starting Ablation Study
2024-08-14 22:23:18,958 - INFO - Running experiment: kg_completeness_0.3
2024-08-14 22:23:19,026 - INFO - Using device: cuda
2024-08-14 22:23:19,026 - INFO - Using device: cuda
2024-08-14 22:23:19,147 - ERROR - An error occurred during experiment kg_completeness_0.3: Cannot choose from an empty sequence
2024-08-14 22:23:19,147 - ERROR - An error occurred during experiment kg_completeness_0.3: Cannot choose from an empty sequence
2024-08-14 22:23:19,152 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:23:19,152 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:23:19,155 - INFO - Running experiment: kg_completeness_0.65
2024-08-14 22:23:19,155 - INFO - Running experiment: kg_completeness_0.65
2024-08-14 22:23:19,156 - INFO - Using device: cuda
2024-08-14 22:23:19,156 - INFO - Using device: cuda
2024-08-14 22:23:19,156 - INFO - Using device: cuda
2024-08-14 22:23:19,207 - ERROR - An error occurred during experiment kg_completeness_0.65: Cannot choose from an empty sequence
2024-08-14 22:23:19,207 - ERROR - An error occurred during experiment kg_completeness_0.65: Cannot choose from an empty sequence
2024-08-14 22:23:19,207 - ERROR - An error occurred during experiment kg_completeness_0.65: Cannot choose from an empty sequence
2024-08-14 22:23:19,209 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:23:19,209 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:23:19,209 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:23:19,213 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 22:23:19,213 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 22:23:19,213 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 22:23:19,214 - INFO - Using device: cuda
2024-08-14 22:23:19,214 - INFO - Using device: cuda
2024-08-14 22:23:19,214 - INFO - Using device: cuda
2024-08-14 22:23:19,214 - INFO - Using device: cuda
2024-08-14 22:23:19,222 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-08-14 22:23:19,222 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-08-14 22:23:19,222 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-08-14 22:23:19,222 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-08-14 22:23:19,224 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:23:19,224 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:23:19,224 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:23:19,224 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:23:19,230 - INFO - Ablation study results saved to results\20240814_222318\ablation_study_results.json
2024-08-14 22:23:19,230 - INFO - Ablation study results saved to results\20240814_222318\ablation_study_results.json
2024-08-14 22:23:19,230 - INFO - Ablation study results saved to results\20240814_222318\ablation_study_results.json
2024-08-14 22:23:19,230 - INFO - Ablation study results saved to results\20240814_222318\ablation_study_results.json
2024-08-14 22:23:19,231 - INFO - Base configuration saved to results\20240814_222318\base_config.json
2024-08-14 22:23:19,231 - INFO - Base configuration saved to results\20240814_222318\base_config.json
2024-08-14 22:23:19,231 - INFO - Base configuration saved to results\20240814_222318\base_config.json
2024-08-14 22:23:19,231 - INFO - Base configuration saved to results\20240814_222318\base_config.json
2024-08-14 22:23:19,231 - INFO - Ablation Study completed
2024-08-14 22:23:19,231 - INFO - Ablation Study completed
2024-08-14 22:23:19,231 - INFO - Ablation Study completed
2024-08-14 22:23:19,231 - INFO - Ablation Study completed
2024-08-14 22:24:39,541 - INFO - Created results directory: results\20240814_222439
2024-08-14 22:24:39,542 - INFO - Starting Ablation Study
2024-08-14 22:24:39,542 - INFO - Running experiment: kg_completeness_0.3
2024-08-14 22:24:39,587 - INFO - Using device: cuda
2024-08-14 22:24:39,587 - INFO - Using device: cuda
2024-08-14 22:24:39,618 - ERROR - An error occurred during experiment kg_completeness_0.3: 0
2024-08-14 22:24:39,618 - ERROR - An error occurred during experiment kg_completeness_0.3: 0
2024-08-14 22:24:39,623 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-08-14 22:24:39,623 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-08-14 22:24:39,626 - INFO - Running experiment: kg_completeness_0.65
2024-08-14 22:24:39,626 - INFO - Running experiment: kg_completeness_0.65
2024-08-14 22:24:39,627 - INFO - Using device: cuda
2024-08-14 22:24:39,627 - INFO - Using device: cuda
2024-08-14 22:24:39,627 - INFO - Using device: cuda
2024-08-14 22:24:39,630 - ERROR - An error occurred during experiment kg_completeness_0.65: 1
2024-08-14 22:24:39,630 - ERROR - An error occurred during experiment kg_completeness_0.65: 1
2024-08-14 22:24:39,630 - ERROR - An error occurred during experiment kg_completeness_0.65: 1
2024-08-14 22:24:39,631 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 1

2024-08-14 22:24:39,631 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 1

2024-08-14 22:24:39,631 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 1

2024-08-14 22:24:39,636 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 22:24:39,636 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 22:24:39,636 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 22:24:39,639 - INFO - Using device: cuda
2024-08-14 22:24:39,639 - INFO - Using device: cuda
2024-08-14 22:24:39,639 - INFO - Using device: cuda
2024-08-14 22:24:39,639 - INFO - Using device: cuda
2024-08-14 22:24:39,641 - ERROR - An error occurred during experiment kg_completeness_1.0: 2
2024-08-14 22:24:39,641 - ERROR - An error occurred during experiment kg_completeness_1.0: 2
2024-08-14 22:24:39,641 - ERROR - An error occurred during experiment kg_completeness_1.0: 2
2024-08-14 22:24:39,641 - ERROR - An error occurred during experiment kg_completeness_1.0: 2
2024-08-14 22:24:39,643 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-08-14 22:24:39,643 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-08-14 22:24:39,643 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-08-14 22:24:39,643 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 35, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 111, in init_player
    location = random.choice(self.suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-08-14 22:24:39,650 - INFO - Ablation study results saved to results\20240814_222439\ablation_study_results.json
2024-08-14 22:24:39,650 - INFO - Ablation study results saved to results\20240814_222439\ablation_study_results.json
2024-08-14 22:24:39,650 - INFO - Ablation study results saved to results\20240814_222439\ablation_study_results.json
2024-08-14 22:24:39,650 - INFO - Ablation study results saved to results\20240814_222439\ablation_study_results.json
2024-08-14 22:24:39,652 - INFO - Base configuration saved to results\20240814_222439\base_config.json
2024-08-14 22:24:39,652 - INFO - Base configuration saved to results\20240814_222439\base_config.json
2024-08-14 22:24:39,652 - INFO - Base configuration saved to results\20240814_222439\base_config.json
2024-08-14 22:24:39,652 - INFO - Base configuration saved to results\20240814_222439\base_config.json
2024-08-14 22:24:39,652 - INFO - Ablation Study completed
2024-08-14 22:24:39,652 - INFO - Ablation Study completed
2024-08-14 22:24:39,652 - INFO - Ablation Study completed
2024-08-14 22:24:39,652 - INFO - Ablation Study completed
2024-08-14 22:37:42,872 - INFO - Created results directory: results\20240814_223742
2024-08-14 22:37:42,872 - INFO - Starting Ablation Study
2024-08-14 22:37:42,872 - INFO - Running experiment: kg_completeness_0.3
2024-08-14 22:37:42,918 - INFO - Using device: cuda
2024-08-14 22:37:42,918 - INFO - Using device: cuda
2024-08-14 22:37:46,878 - ERROR - An error occurred during experiment kg_completeness_0.3: Cannot choose from an empty sequence
2024-08-14 22:37:46,878 - ERROR - An error occurred during experiment kg_completeness_0.3: Cannot choose from an empty sequence
2024-08-14 22:37:46,882 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 124, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:37:46,882 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 268, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 124, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:37:46,888 - INFO - Running experiment: kg_completeness_0.65
2024-08-14 22:37:46,888 - INFO - Running experiment: kg_completeness_0.65
2024-08-14 22:37:46,890 - INFO - Using device: cuda
2024-08-14 22:37:46,890 - INFO - Using device: cuda
2024-08-14 22:37:46,890 - INFO - Using device: cuda
2024-08-14 22:37:56,637 - ERROR - An error occurred during experiment kg_completeness_0.65: Cannot choose from an empty sequence
2024-08-14 22:37:56,637 - ERROR - An error occurred during experiment kg_completeness_0.65: Cannot choose from an empty sequence
2024-08-14 22:37:56,637 - ERROR - An error occurred during experiment kg_completeness_0.65: Cannot choose from an empty sequence
2024-08-14 22:37:56,639 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 274, in setup
    self.eval_env: CustomEnv = self.env_manager.make_env()
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 124, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:37:56,639 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 274, in setup
    self.eval_env: CustomEnv = self.env_manager.make_env()
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 124, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:37:56,639 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 218, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 274, in setup
    self.eval_env: CustomEnv = self.env_manager.make_env()
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 27, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 59, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 15, in __init__
    self.create_games(number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 47, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 124, in init_player
    location = random.choice(self.suitable_terrain_locations['Plains'] + self.suitable_terrain_locations['Hills'])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-08-14 22:37:56,645 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 22:37:56,645 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 22:37:56,645 - INFO - Running experiment: kg_completeness_1.0
2024-08-14 22:37:56,646 - INFO - Using device: cuda
2024-08-14 22:37:56,646 - INFO - Using device: cuda
2024-08-14 22:37:56,646 - INFO - Using device: cuda
2024-08-14 22:37:56,646 - INFO - Using device: cuda
2024-08-14 22:38:42,936 - INFO - Created results directory: results\20240814_223842
2024-08-14 22:38:42,937 - INFO - Starting Ablation Study
2024-08-14 22:38:42,937 - INFO - Running experiment: kg_completeness_0.3
2024-08-14 22:38:42,961 - INFO - Using device: cuda
2024-08-14 22:38:42,961 - INFO - Using device: cuda
2024-08-15 03:22:25,873 - INFO - Profiling stats saved to results\20240814_223842\kg_completeness_0.3\profile_stats.txt
2024-08-15 03:22:25,873 - INFO - Profiling stats saved to results\20240814_223842\kg_completeness_0.3\profile_stats.txt
2024-08-15 03:22:43,747 - INFO - Training and evaluation completed.
2024-08-15 03:22:43,747 - INFO - Training and evaluation completed.
2024-08-15 03:22:43,751 - INFO - Experiment kg_completeness_0.3 completed
2024-08-15 03:22:43,751 - INFO - Experiment kg_completeness_0.3 completed
2024-08-15 03:22:43,752 - INFO - Running experiment: kg_completeness_0.65
2024-08-15 03:22:43,752 - INFO - Running experiment: kg_completeness_0.65
2024-08-15 03:22:43,786 - INFO - Using device: cuda
2024-08-15 03:22:43,786 - INFO - Using device: cuda
2024-08-15 03:22:43,786 - INFO - Using device: cuda
2024-08-15 07:50:11,814 - INFO - Profiling stats saved to results\20240814_223842\kg_completeness_0.65\profile_stats.txt
2024-08-15 07:50:11,814 - INFO - Profiling stats saved to results\20240814_223842\kg_completeness_0.65\profile_stats.txt
2024-08-15 07:50:11,814 - INFO - Profiling stats saved to results\20240814_223842\kg_completeness_0.65\profile_stats.txt
2024-08-15 07:50:31,231 - INFO - Training and evaluation completed.
2024-08-15 07:50:31,231 - INFO - Training and evaluation completed.
2024-08-15 07:50:31,231 - INFO - Training and evaluation completed.
2024-08-15 07:50:31,233 - INFO - Experiment kg_completeness_0.65 completed
2024-08-15 07:50:31,233 - INFO - Experiment kg_completeness_0.65 completed
2024-08-15 07:50:31,233 - INFO - Experiment kg_completeness_0.65 completed
2024-08-15 07:50:31,234 - INFO - Running experiment: kg_completeness_1.0
2024-08-15 07:50:31,234 - INFO - Running experiment: kg_completeness_1.0
2024-08-15 07:50:31,234 - INFO - Running experiment: kg_completeness_1.0
2024-08-15 07:50:31,235 - INFO - Using device: cuda
2024-08-15 07:50:31,235 - INFO - Using device: cuda
2024-08-15 07:50:31,235 - INFO - Using device: cuda
2024-08-15 07:50:31,235 - INFO - Using device: cuda
2024-08-15 12:21:47,681 - INFO - Profiling stats saved to results\20240814_223842\kg_completeness_1.0\profile_stats.txt
2024-08-15 12:21:47,681 - INFO - Profiling stats saved to results\20240814_223842\kg_completeness_1.0\profile_stats.txt
2024-08-15 12:21:47,681 - INFO - Profiling stats saved to results\20240814_223842\kg_completeness_1.0\profile_stats.txt
2024-08-15 12:21:47,681 - INFO - Profiling stats saved to results\20240814_223842\kg_completeness_1.0\profile_stats.txt
2024-08-15 12:22:06,187 - INFO - Training and evaluation completed.
2024-08-15 12:22:06,187 - INFO - Training and evaluation completed.
2024-08-15 12:22:06,187 - INFO - Training and evaluation completed.
2024-08-15 12:22:06,187 - INFO - Training and evaluation completed.
2024-08-15 12:22:06,189 - INFO - Experiment kg_completeness_1.0 completed
2024-08-15 12:22:06,189 - INFO - Experiment kg_completeness_1.0 completed
2024-08-15 12:22:06,189 - INFO - Experiment kg_completeness_1.0 completed
2024-08-15 12:22:06,189 - INFO - Experiment kg_completeness_1.0 completed
2024-08-15 12:22:06,191 - INFO - Ablation study results saved to results\20240814_223842\ablation_study_results.json
2024-08-15 12:22:06,191 - INFO - Ablation study results saved to results\20240814_223842\ablation_study_results.json
2024-08-15 12:22:06,191 - INFO - Ablation study results saved to results\20240814_223842\ablation_study_results.json
2024-08-15 12:22:06,191 - INFO - Ablation study results saved to results\20240814_223842\ablation_study_results.json
2024-08-15 12:22:06,192 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_0.3_results.json
2024-08-15 12:22:06,192 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_0.3_results.json
2024-08-15 12:22:06,192 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_0.3_results.json
2024-08-15 12:22:06,192 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_0.3_results.json
2024-08-15 12:22:06,203 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_0.65_results.json
2024-08-15 12:22:06,203 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_0.65_results.json
2024-08-15 12:22:06,203 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_0.65_results.json
2024-08-15 12:22:06,203 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_0.65_results.json
2024-08-15 12:22:06,204 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_1.0_results.json
2024-08-15 12:22:06,204 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_1.0_results.json
2024-08-15 12:22:06,204 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_1.0_results.json
2024-08-15 12:22:06,204 - INFO - Individual experiment results saved to results\20240814_223842\kg_completeness_1.0_results.json
2024-08-15 12:22:06,206 - INFO - Base configuration saved to results\20240814_223842\base_config.json
2024-08-15 12:22:06,206 - INFO - Base configuration saved to results\20240814_223842\base_config.json
2024-08-15 12:22:06,206 - INFO - Base configuration saved to results\20240814_223842\base_config.json
2024-08-15 12:22:06,206 - INFO - Base configuration saved to results\20240814_223842\base_config.json
2024-08-15 12:22:06,207 - INFO - Ablation Study completed
2024-08-15 12:22:06,207 - INFO - Ablation Study completed
2024-08-15 12:22:06,207 - INFO - Ablation Study completed
2024-08-15 12:22:06,207 - INFO - Ablation Study completed
2024-09-01 09:37:24,548 - INFO - Created results directory: results\20240901_093724
2024-09-01 09:37:24,548 - INFO - Starting Ablation Study
2024-09-01 09:37:24,550 - INFO - Running experiment: kg_completeness_0.25
2024-09-01 09:37:24,569 - INFO - Using device: cuda
2024-09-01 09:37:24,569 - INFO - Using device: cuda
2024-09-01 09:50:17,883 - INFO - Created results directory: results\20240901_095017
2024-09-01 09:50:17,883 - INFO - Starting Ablation Study
2024-09-01 09:50:17,884 - INFO - Running experiment: kg_completeness_0.25
2024-09-01 09:50:17,907 - INFO - Using device: cuda
2024-09-01 09:50:17,907 - INFO - Using device: cuda
2024-09-01 09:59:03,766 - INFO - Created results directory: results\20240901_095903
2024-09-01 09:59:03,766 - INFO - Starting Ablation Study
2024-09-01 09:59:03,766 - INFO - Running experiment: kg_completeness_0.25
2024-09-01 09:59:03,788 - INFO - Using device: cuda
2024-09-01 09:59:03,788 - INFO - Using device: cuda
2024-09-01 10:04:30,179 - INFO - Created results directory: results\20240901_100430
2024-09-01 10:04:30,179 - INFO - Starting Ablation Study
2024-09-01 10:04:30,179 - INFO - Running experiment: kg_completeness_0.25
2024-09-01 10:04:30,199 - INFO - Using device: cuda
2024-09-01 10:04:30,199 - INFO - Using device: cuda
2024-09-01 10:21:43,329 - INFO - Created results directory: results\20240901_102143
2024-09-01 10:21:43,329 - INFO - Starting Ablation Study
2024-09-01 10:21:43,329 - INFO - Running experiment: kg_completeness_0.25
2024-09-01 10:21:43,348 - INFO - Using device: cuda
2024-09-01 10:21:43,348 - INFO - Using device: cuda
2024-09-01 11:47:44,678 - INFO - Created results directory: results\20240901_114744
2024-09-01 11:47:44,678 - INFO - Starting Ablation Study
2024-09-01 11:47:44,678 - INFO - Running experiment: kg_completeness_0.25
2024-09-01 11:47:44,708 - INFO - Using device: cuda
2024-09-01 11:47:44,708 - INFO - Using device: cuda
2024-09-01 11:52:05,982 - INFO - Created results directory: results\20240901_115205
2024-09-01 11:52:05,982 - INFO - Starting Ablation Study
2024-09-01 11:52:05,982 - INFO - Running experiment: kg_completeness_0.25
2024-09-01 11:52:06,003 - INFO - Using device: cuda
2024-09-01 11:52:06,003 - INFO - Using device: cuda
2024-09-02 04:02:05,892 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_0.25\profile_stats.txt
2024-09-02 04:02:05,892 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_0.25\profile_stats.txt
2024-09-02 04:12:23,372 - INFO - Training and evaluation completed.
2024-09-02 04:12:23,372 - INFO - Training and evaluation completed.
2024-09-02 04:12:23,375 - INFO - Experiment kg_completeness_0.25 completed
2024-09-02 04:12:23,375 - INFO - Experiment kg_completeness_0.25 completed
2024-09-02 04:12:23,376 - INFO - Running experiment: kg_completeness_0.5
2024-09-02 04:12:23,376 - INFO - Running experiment: kg_completeness_0.5
2024-09-02 04:12:23,380 - INFO - Using device: cuda
2024-09-02 04:12:23,380 - INFO - Using device: cuda
2024-09-02 04:12:23,380 - INFO - Using device: cuda
2024-09-02 19:37:51,816 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_0.5\profile_stats.txt
2024-09-02 19:37:51,816 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_0.5\profile_stats.txt
2024-09-02 19:37:51,816 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_0.5\profile_stats.txt
2024-09-02 19:48:55,978 - INFO - Training and evaluation completed.
2024-09-02 19:48:55,978 - INFO - Training and evaluation completed.
2024-09-02 19:48:55,978 - INFO - Training and evaluation completed.
2024-09-02 19:48:55,980 - INFO - Experiment kg_completeness_0.5 completed
2024-09-02 19:48:55,980 - INFO - Experiment kg_completeness_0.5 completed
2024-09-02 19:48:55,980 - INFO - Experiment kg_completeness_0.5 completed
2024-09-02 19:48:55,980 - INFO - Running experiment: kg_completeness_0.75
2024-09-02 19:48:55,980 - INFO - Running experiment: kg_completeness_0.75
2024-09-02 19:48:55,980 - INFO - Running experiment: kg_completeness_0.75
2024-09-02 19:48:55,983 - INFO - Using device: cuda
2024-09-02 19:48:55,983 - INFO - Using device: cuda
2024-09-02 19:48:55,983 - INFO - Using device: cuda
2024-09-02 19:48:55,983 - INFO - Using device: cuda
2024-09-03 11:36:26,025 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_0.75\profile_stats.txt
2024-09-03 11:36:26,025 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_0.75\profile_stats.txt
2024-09-03 11:36:26,025 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_0.75\profile_stats.txt
2024-09-03 11:36:26,025 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_0.75\profile_stats.txt
2024-09-03 11:47:23,697 - INFO - Training and evaluation completed.
2024-09-03 11:47:23,697 - INFO - Training and evaluation completed.
2024-09-03 11:47:23,697 - INFO - Training and evaluation completed.
2024-09-03 11:47:23,697 - INFO - Training and evaluation completed.
2024-09-03 11:47:23,699 - INFO - Experiment kg_completeness_0.75 completed
2024-09-03 11:47:23,699 - INFO - Experiment kg_completeness_0.75 completed
2024-09-03 11:47:23,699 - INFO - Experiment kg_completeness_0.75 completed
2024-09-03 11:47:23,699 - INFO - Experiment kg_completeness_0.75 completed
2024-09-03 11:47:23,699 - INFO - Running experiment: kg_completeness_1.0
2024-09-03 11:47:23,699 - INFO - Running experiment: kg_completeness_1.0
2024-09-03 11:47:23,699 - INFO - Running experiment: kg_completeness_1.0
2024-09-03 11:47:23,699 - INFO - Running experiment: kg_completeness_1.0
2024-09-03 11:47:23,701 - INFO - Using device: cuda
2024-09-03 11:47:23,701 - INFO - Using device: cuda
2024-09-03 11:47:23,701 - INFO - Using device: cuda
2024-09-03 11:47:23,701 - INFO - Using device: cuda
2024-09-03 11:47:23,701 - INFO - Using device: cuda
2024-09-04 03:40:30,389 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_1.0\profile_stats.txt
2024-09-04 03:40:30,389 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_1.0\profile_stats.txt
2024-09-04 03:40:30,389 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_1.0\profile_stats.txt
2024-09-04 03:40:30,389 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_1.0\profile_stats.txt
2024-09-04 03:40:30,389 - INFO - Profiling stats saved to results\20240901_115205\kg_completeness_1.0\profile_stats.txt
2024-09-04 03:51:46,560 - INFO - Training and evaluation completed.
2024-09-04 03:51:46,560 - INFO - Training and evaluation completed.
2024-09-04 03:51:46,560 - INFO - Training and evaluation completed.
2024-09-04 03:51:46,560 - INFO - Training and evaluation completed.
2024-09-04 03:51:46,560 - INFO - Training and evaluation completed.
2024-09-04 03:51:46,570 - INFO - Experiment kg_completeness_1.0 completed
2024-09-04 03:51:46,570 - INFO - Experiment kg_completeness_1.0 completed
2024-09-04 03:51:46,570 - INFO - Experiment kg_completeness_1.0 completed
2024-09-04 03:51:46,570 - INFO - Experiment kg_completeness_1.0 completed
2024-09-04 03:51:46,570 - INFO - Experiment kg_completeness_1.0 completed
2024-09-04 03:51:46,572 - INFO - Ablation study results saved to results\20240901_115205\ablation_study_results.json
2024-09-04 03:51:46,572 - INFO - Ablation study results saved to results\20240901_115205\ablation_study_results.json
2024-09-04 03:51:46,572 - INFO - Ablation study results saved to results\20240901_115205\ablation_study_results.json
2024-09-04 03:51:46,572 - INFO - Ablation study results saved to results\20240901_115205\ablation_study_results.json
2024-09-04 03:51:46,572 - INFO - Ablation study results saved to results\20240901_115205\ablation_study_results.json
2024-09-04 03:51:46,574 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.25_results.json
2024-09-04 03:51:46,574 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.25_results.json
2024-09-04 03:51:46,574 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.25_results.json
2024-09-04 03:51:46,574 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.25_results.json
2024-09-04 03:51:46,574 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.25_results.json
2024-09-04 03:51:46,576 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.5_results.json
2024-09-04 03:51:46,576 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.5_results.json
2024-09-04 03:51:46,576 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.5_results.json
2024-09-04 03:51:46,576 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.5_results.json
2024-09-04 03:51:46,576 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.5_results.json
2024-09-04 03:51:46,577 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.75_results.json
2024-09-04 03:51:46,577 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.75_results.json
2024-09-04 03:51:46,577 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.75_results.json
2024-09-04 03:51:46,577 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.75_results.json
2024-09-04 03:51:46,577 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_0.75_results.json
2024-09-04 03:51:46,579 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_1.0_results.json
2024-09-04 03:51:46,579 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_1.0_results.json
2024-09-04 03:51:46,579 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_1.0_results.json
2024-09-04 03:51:46,579 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_1.0_results.json
2024-09-04 03:51:46,579 - INFO - Individual experiment results saved to results\20240901_115205\kg_completeness_1.0_results.json
2024-09-04 03:51:46,580 - INFO - Base configuration saved to results\20240901_115205\base_config.json
2024-09-04 03:51:46,580 - INFO - Base configuration saved to results\20240901_115205\base_config.json
2024-09-04 03:51:46,580 - INFO - Base configuration saved to results\20240901_115205\base_config.json
2024-09-04 03:51:46,580 - INFO - Base configuration saved to results\20240901_115205\base_config.json
2024-09-04 03:51:46,580 - INFO - Base configuration saved to results\20240901_115205\base_config.json
2024-09-04 03:51:46,581 - INFO - Ablation Study completed
2024-09-04 03:51:46,581 - INFO - Ablation Study completed
2024-09-04 03:51:46,581 - INFO - Ablation Study completed
2024-09-04 03:51:46,581 - INFO - Ablation Study completed
2024-09-04 03:51:46,581 - INFO - Ablation Study completed
2024-09-04 23:20:05,741 - INFO - Created results directory: results\20240904_232005
2024-09-04 23:20:05,741 - INFO - Starting Ablation Study
2024-09-04 23:20:05,741 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:20:05,808 - INFO - Using device: cuda
2024-09-04 23:20:05,808 - INFO - Using device: cuda
2024-09-04 23:23:23,932 - INFO - Created results directory: results\20240904_232323
2024-09-04 23:23:23,933 - INFO - Starting Ablation Study
2024-09-04 23:23:23,933 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:23:23,960 - INFO - Using device: cuda
2024-09-04 23:23:23,960 - INFO - Using device: cuda
2024-09-04 23:32:38,825 - INFO - Created results directory: results\20240904_233238
2024-09-04 23:32:38,826 - INFO - Starting Ablation Study
2024-09-04 23:32:38,826 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:32:38,872 - INFO - Using device: cuda
2024-09-04 23:32:38,872 - INFO - Using device: cuda
2024-09-04 23:32:57,161 - ERROR - An error occurred during training: Algorithmic best energy cannot be zero
2024-09-04 23:32:57,161 - ERROR - An error occurred during training: Algorithmic best energy cannot be zero
2024-09-04 23:32:57,167 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 268, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 193, in _calculate_reward
    self.current_efficiency = self.calculate_route_efficiency(agent_route_energy, algorithmic_best_energy)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 379, in calculate_route_efficiency
    raise ValueError("Algorithmic best energy cannot be zero")
ValueError: Algorithmic best energy cannot be zero

2024-09-04 23:32:57,167 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 268, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 193, in _calculate_reward
    self.current_efficiency = self.calculate_route_efficiency(agent_route_energy, algorithmic_best_energy)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 379, in calculate_route_efficiency
    raise ValueError("Algorithmic best energy cannot be zero")
ValueError: Algorithmic best energy cannot be zero

2024-09-04 23:32:57,202 - INFO - Profiling stats saved to results\20240904_233238\kg_completeness_0.25\profile_stats.txt
2024-09-04 23:32:57,202 - INFO - Profiling stats saved to results\20240904_233238\kg_completeness_0.25\profile_stats.txt
2024-09-04 23:35:04,841 - INFO - Created results directory: results\20240904_233504
2024-09-04 23:35:04,842 - INFO - Starting Ablation Study
2024-09-04 23:35:04,842 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:35:04,864 - INFO - Using device: cuda
2024-09-04 23:35:04,864 - INFO - Using device: cuda
2024-09-04 23:35:22,583 - ERROR - An error occurred during training: Algorithmic best energy cannot be zero
2024-09-04 23:35:22,583 - ERROR - An error occurred during training: Algorithmic best energy cannot be zero
2024-09-04 23:35:22,628 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 269, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 193, in _calculate_reward
    raise ValueError("Algorithmic best energy cannot be zero")
ValueError: Algorithmic best energy cannot be zero

2024-09-04 23:35:22,628 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 269, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 193, in _calculate_reward
    raise ValueError("Algorithmic best energy cannot be zero")
ValueError: Algorithmic best energy cannot be zero

2024-09-04 23:35:22,658 - INFO - Profiling stats saved to results\20240904_233504\kg_completeness_0.25\profile_stats.txt
2024-09-04 23:35:22,658 - INFO - Profiling stats saved to results\20240904_233504\kg_completeness_0.25\profile_stats.txt
2024-09-04 23:37:47,528 - INFO - Created results directory: results\20240904_233747
2024-09-04 23:37:47,528 - INFO - Starting Ablation Study
2024-09-04 23:37:47,528 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:37:47,548 - INFO - Using device: cuda
2024-09-04 23:37:47,548 - INFO - Using device: cuda
2024-09-04 23:37:59,460 - ERROR - An error occurred during training: Algorithmic best energy cannot be zero
2024-09-04 23:37:59,460 - ERROR - An error occurred during training: Algorithmic best energy cannot be zero
2024-09-04 23:37:59,466 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 271, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 196, in _calculate_reward
    self.current_efficiency = self.calculate_route_efficiency(agent_route_energy, algorithmic_best_energy)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 382, in calculate_route_efficiency
    raise ValueError("Algorithmic best energy cannot be zero")
ValueError: Algorithmic best energy cannot be zero

2024-09-04 23:37:59,466 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 271, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 196, in _calculate_reward
    self.current_efficiency = self.calculate_route_efficiency(agent_route_energy, algorithmic_best_energy)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 382, in calculate_route_efficiency
    raise ValueError("Algorithmic best energy cannot be zero")
ValueError: Algorithmic best energy cannot be zero

2024-09-04 23:37:59,497 - INFO - Profiling stats saved to results\20240904_233747\kg_completeness_0.25\profile_stats.txt
2024-09-04 23:37:59,497 - INFO - Profiling stats saved to results\20240904_233747\kg_completeness_0.25\profile_stats.txt
2024-09-04 23:39:47,904 - INFO - Created results directory: results\20240904_233947
2024-09-04 23:39:47,905 - INFO - Starting Ablation Study
2024-09-04 23:39:47,905 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:39:47,927 - INFO - Using device: cuda
2024-09-04 23:39:47,927 - INFO - Using device: cuda
2024-09-04 23:40:04,212 - ERROR - An error occurred during training: Algorithmic best energy cannot be zero
2024-09-04 23:40:04,212 - ERROR - An error occurred during training: Algorithmic best energy cannot be zero
2024-09-04 23:40:04,229 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 269, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 194, in _calculate_reward
    self.current_efficiency = self.calculate_route_efficiency(agent_route_energy, algorithmic_best_energy)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 380, in calculate_route_efficiency
    raise ValueError("Algorithmic best energy cannot be zero")
ValueError: Algorithmic best energy cannot be zero

2024-09-04 23:40:04,229 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 269, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 194, in _calculate_reward
    self.current_efficiency = self.calculate_route_efficiency(agent_route_energy, algorithmic_best_energy)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 380, in calculate_route_efficiency
    raise ValueError("Algorithmic best energy cannot be zero")
ValueError: Algorithmic best energy cannot be zero

2024-09-04 23:40:04,259 - INFO - Profiling stats saved to results\20240904_233947\kg_completeness_0.25\profile_stats.txt
2024-09-04 23:40:04,259 - INFO - Profiling stats saved to results\20240904_233947\kg_completeness_0.25\profile_stats.txt
2024-09-04 23:48:19,727 - INFO - Created results directory: results\20240904_234819
2024-09-04 23:48:19,727 - INFO - Starting Ablation Study
2024-09-04 23:48:19,727 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:48:19,770 - INFO - Using device: cuda
2024-09-04 23:48:19,770 - INFO - Using device: cuda
2024-09-04 23:50:43,045 - INFO - Created results directory: results\20240904_235043
2024-09-04 23:50:43,045 - INFO - Starting Ablation Study
2024-09-04 23:50:43,045 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:50:43,065 - INFO - Using device: cuda
2024-09-04 23:50:43,065 - INFO - Using device: cuda
2024-09-04 23:53:36,003 - INFO - Created results directory: results\20240904_235336
2024-09-04 23:53:36,003 - INFO - Starting Ablation Study
2024-09-04 23:53:36,003 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:53:36,026 - INFO - Using device: cuda
2024-09-04 23:53:36,026 - INFO - Using device: cuda
2024-09-04 23:57:19,787 - INFO - Created results directory: results\20240904_235719
2024-09-04 23:57:19,787 - INFO - Starting Ablation Study
2024-09-04 23:57:19,788 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:57:19,811 - INFO - Using device: cuda
2024-09-04 23:57:19,811 - INFO - Using device: cuda
2024-09-04 23:58:55,106 - INFO - Created results directory: results\20240904_235855
2024-09-04 23:58:55,106 - INFO - Starting Ablation Study
2024-09-04 23:58:55,106 - INFO - Running experiment: kg_completeness_0.25
2024-09-04 23:58:55,129 - INFO - Using device: cuda
2024-09-04 23:58:55,129 - INFO - Using device: cuda
2024-09-05 00:04:37,867 - INFO - Created results directory: results\20240905_000437
2024-09-05 00:04:37,868 - INFO - Starting Ablation Study
2024-09-05 00:04:37,868 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 00:04:37,887 - INFO - Using device: cuda
2024-09-05 00:04:37,887 - INFO - Using device: cuda
2024-09-05 00:06:19,862 - INFO - Created results directory: results\20240905_000619
2024-09-05 00:06:19,863 - INFO - Starting Ablation Study
2024-09-05 00:06:19,863 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 00:06:19,883 - INFO - Using device: cuda
2024-09-05 00:06:19,883 - INFO - Using device: cuda
2024-09-05 00:09:08,770 - INFO - Created results directory: results\20240905_000908
2024-09-05 00:09:08,770 - INFO - Starting Ablation Study
2024-09-05 00:09:08,770 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 00:09:08,791 - INFO - Using device: cuda
2024-09-05 00:09:08,791 - INFO - Using device: cuda
2024-09-05 00:09:54,372 - INFO - Created results directory: results\20240905_000954
2024-09-05 00:09:54,372 - INFO - Starting Ablation Study
2024-09-05 00:09:54,372 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 00:09:54,394 - INFO - Using device: cuda
2024-09-05 00:09:54,394 - INFO - Using device: cuda
2024-09-05 00:16:34,751 - INFO - Created results directory: results\20240905_001634
2024-09-05 00:16:34,752 - INFO - Starting Ablation Study
2024-09-05 00:16:34,752 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 00:16:34,772 - INFO - Using device: cuda
2024-09-05 00:16:34,772 - INFO - Using device: cuda
2024-09-05 00:16:48,993 - ERROR - An error occurred during training: CustomEnv.calculate_relative_improvement() takes 2 positional arguments but 3 were given
2024-09-05 00:16:48,993 - ERROR - An error occurred during training: CustomEnv.calculate_relative_improvement() takes 2 positional arguments but 3 were given
2024-09-05 00:16:49,008 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 270, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 200, in _calculate_reward
    self.improvement = self.calculate_relative_improvement(agent_route_energy, algorithmic_best_energy)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: CustomEnv.calculate_relative_improvement() takes 2 positional arguments but 3 were given

2024-09-05 00:16:49,008 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 230, in train
    self.rl_model.learn(
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\ppo\ppo.py", line 315, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 300, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py", line 195, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 206, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 270, in step
    reward = self._calculate_reward()
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 200, in _calculate_reward
    self.improvement = self.calculate_relative_improvement(agent_route_energy, algorithmic_best_energy)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: CustomEnv.calculate_relative_improvement() takes 2 positional arguments but 3 were given

2024-09-05 00:16:49,040 - INFO - Profiling stats saved to results\20240905_001634\kg_completeness_0.25\profile_stats.txt
2024-09-05 00:16:49,040 - INFO - Profiling stats saved to results\20240905_001634\kg_completeness_0.25\profile_stats.txt
2024-09-05 00:17:43,591 - INFO - Created results directory: results\20240905_001743
2024-09-05 00:17:43,591 - INFO - Starting Ablation Study
2024-09-05 00:17:43,591 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 00:17:43,609 - INFO - Using device: cuda
2024-09-05 00:17:43,609 - INFO - Using device: cuda
2024-09-05 00:22:31,534 - INFO - Created results directory: results\20240905_002231
2024-09-05 00:22:31,534 - INFO - Starting Ablation Study
2024-09-05 00:22:31,534 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 00:22:31,556 - INFO - Using device: cuda
2024-09-05 00:22:31,556 - INFO - Using device: cuda
2024-09-05 02:06:32,928 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_0.25\profile_stats.txt
2024-09-05 02:06:32,928 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_0.25\profile_stats.txt
2024-09-05 02:18:37,826 - INFO - Training and evaluation completed.
2024-09-05 02:18:37,826 - INFO - Training and evaluation completed.
2024-09-05 02:18:37,830 - INFO - Experiment kg_completeness_0.25 completed
2024-09-05 02:18:37,830 - INFO - Experiment kg_completeness_0.25 completed
2024-09-05 02:18:37,831 - INFO - Running experiment: kg_completeness_0.5
2024-09-05 02:18:37,831 - INFO - Running experiment: kg_completeness_0.5
2024-09-05 02:18:37,840 - INFO - Using device: cuda
2024-09-05 02:18:37,840 - INFO - Using device: cuda
2024-09-05 02:18:37,840 - INFO - Using device: cuda
2024-09-05 04:00:44,137 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_0.5\profile_stats.txt
2024-09-05 04:00:44,137 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_0.5\profile_stats.txt
2024-09-05 04:00:44,137 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_0.5\profile_stats.txt
2024-09-05 04:12:45,649 - INFO - Training and evaluation completed.
2024-09-05 04:12:45,649 - INFO - Training and evaluation completed.
2024-09-05 04:12:45,649 - INFO - Training and evaluation completed.
2024-09-05 04:12:45,651 - INFO - Experiment kg_completeness_0.5 completed
2024-09-05 04:12:45,651 - INFO - Experiment kg_completeness_0.5 completed
2024-09-05 04:12:45,651 - INFO - Experiment kg_completeness_0.5 completed
2024-09-05 04:12:45,652 - INFO - Running experiment: kg_completeness_0.75
2024-09-05 04:12:45,652 - INFO - Running experiment: kg_completeness_0.75
2024-09-05 04:12:45,652 - INFO - Running experiment: kg_completeness_0.75
2024-09-05 04:12:45,652 - INFO - Using device: cuda
2024-09-05 04:12:45,652 - INFO - Using device: cuda
2024-09-05 04:12:45,652 - INFO - Using device: cuda
2024-09-05 04:12:45,652 - INFO - Using device: cuda
2024-09-05 05:57:50,680 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_0.75\profile_stats.txt
2024-09-05 05:57:50,680 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_0.75\profile_stats.txt
2024-09-05 05:57:50,680 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_0.75\profile_stats.txt
2024-09-05 05:57:50,680 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_0.75\profile_stats.txt
2024-09-05 06:10:46,954 - INFO - Training and evaluation completed.
2024-09-05 06:10:46,954 - INFO - Training and evaluation completed.
2024-09-05 06:10:46,954 - INFO - Training and evaluation completed.
2024-09-05 06:10:46,954 - INFO - Training and evaluation completed.
2024-09-05 06:10:46,956 - INFO - Experiment kg_completeness_0.75 completed
2024-09-05 06:10:46,956 - INFO - Experiment kg_completeness_0.75 completed
2024-09-05 06:10:46,956 - INFO - Experiment kg_completeness_0.75 completed
2024-09-05 06:10:46,956 - INFO - Experiment kg_completeness_0.75 completed
2024-09-05 06:10:46,957 - INFO - Running experiment: kg_completeness_1.0
2024-09-05 06:10:46,957 - INFO - Running experiment: kg_completeness_1.0
2024-09-05 06:10:46,957 - INFO - Running experiment: kg_completeness_1.0
2024-09-05 06:10:46,957 - INFO - Running experiment: kg_completeness_1.0
2024-09-05 06:10:46,959 - INFO - Using device: cuda
2024-09-05 06:10:46,959 - INFO - Using device: cuda
2024-09-05 06:10:46,959 - INFO - Using device: cuda
2024-09-05 06:10:46,959 - INFO - Using device: cuda
2024-09-05 06:10:46,959 - INFO - Using device: cuda
2024-09-05 07:53:01,071 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_1.0\profile_stats.txt
2024-09-05 07:53:01,071 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_1.0\profile_stats.txt
2024-09-05 07:53:01,071 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_1.0\profile_stats.txt
2024-09-05 07:53:01,071 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_1.0\profile_stats.txt
2024-09-05 07:53:01,071 - INFO - Profiling stats saved to results\20240905_002231\kg_completeness_1.0\profile_stats.txt
2024-09-05 08:04:57,558 - INFO - Training and evaluation completed.
2024-09-05 08:04:57,558 - INFO - Training and evaluation completed.
2024-09-05 08:04:57,558 - INFO - Training and evaluation completed.
2024-09-05 08:04:57,558 - INFO - Training and evaluation completed.
2024-09-05 08:04:57,558 - INFO - Training and evaluation completed.
2024-09-05 08:04:57,560 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 08:04:57,560 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 08:04:57,560 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 08:04:57,560 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 08:04:57,560 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 08:04:57,562 - INFO - Ablation study results saved to results\20240905_002231\ablation_study_results.json
2024-09-05 08:04:57,562 - INFO - Ablation study results saved to results\20240905_002231\ablation_study_results.json
2024-09-05 08:04:57,562 - INFO - Ablation study results saved to results\20240905_002231\ablation_study_results.json
2024-09-05 08:04:57,562 - INFO - Ablation study results saved to results\20240905_002231\ablation_study_results.json
2024-09-05 08:04:57,562 - INFO - Ablation study results saved to results\20240905_002231\ablation_study_results.json
2024-09-05 08:04:57,564 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.25_results.json
2024-09-05 08:04:57,564 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.25_results.json
2024-09-05 08:04:57,564 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.25_results.json
2024-09-05 08:04:57,564 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.25_results.json
2024-09-05 08:04:57,564 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.25_results.json
2024-09-05 08:04:57,566 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.5_results.json
2024-09-05 08:04:57,566 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.5_results.json
2024-09-05 08:04:57,566 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.5_results.json
2024-09-05 08:04:57,566 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.5_results.json
2024-09-05 08:04:57,566 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.5_results.json
2024-09-05 08:04:57,568 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.75_results.json
2024-09-05 08:04:57,568 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.75_results.json
2024-09-05 08:04:57,568 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.75_results.json
2024-09-05 08:04:57,568 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.75_results.json
2024-09-05 08:04:57,568 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_0.75_results.json
2024-09-05 08:04:57,570 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_1.0_results.json
2024-09-05 08:04:57,570 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_1.0_results.json
2024-09-05 08:04:57,570 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_1.0_results.json
2024-09-05 08:04:57,570 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_1.0_results.json
2024-09-05 08:04:57,570 - INFO - Individual experiment results saved to results\20240905_002231\kg_completeness_1.0_results.json
2024-09-05 08:04:57,571 - INFO - Base configuration saved to results\20240905_002231\base_config.json
2024-09-05 08:04:57,571 - INFO - Base configuration saved to results\20240905_002231\base_config.json
2024-09-05 08:04:57,571 - INFO - Base configuration saved to results\20240905_002231\base_config.json
2024-09-05 08:04:57,571 - INFO - Base configuration saved to results\20240905_002231\base_config.json
2024-09-05 08:04:57,571 - INFO - Base configuration saved to results\20240905_002231\base_config.json
2024-09-05 08:04:57,573 - INFO - Ablation Study completed
2024-09-05 08:04:57,573 - INFO - Ablation Study completed
2024-09-05 08:04:57,573 - INFO - Ablation Study completed
2024-09-05 08:04:57,573 - INFO - Ablation Study completed
2024-09-05 08:04:57,573 - INFO - Ablation Study completed
2024-09-05 08:29:17,211 - INFO - Created results directory: results\20240905_082917
2024-09-05 08:29:17,211 - INFO - Starting Ablation Study
2024-09-05 08:29:17,211 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 08:29:17,242 - INFO - Using device: cuda
2024-09-05 08:29:17,242 - INFO - Using device: cuda
2024-09-05 08:32:25,124 - INFO - Created results directory: results\20240905_083225
2024-09-05 08:32:25,125 - INFO - Starting Ablation Study
2024-09-05 08:32:25,125 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 08:32:25,148 - INFO - Using device: cuda
2024-09-05 08:32:25,148 - INFO - Using device: cuda
2024-09-05 08:47:33,776 - INFO - Created results directory: results\20240905_084733
2024-09-05 08:47:33,776 - INFO - Starting Ablation Study
2024-09-05 08:47:33,776 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 08:47:33,807 - INFO - Using device: cuda
2024-09-05 08:47:33,807 - INFO - Using device: cuda
2024-09-05 10:31:44,065 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_0.25\profile_stats.txt
2024-09-05 10:31:44,065 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_0.25\profile_stats.txt
2024-09-05 10:44:28,993 - INFO - Training and evaluation completed.
2024-09-05 10:44:28,993 - INFO - Training and evaluation completed.
2024-09-05 10:44:28,994 - INFO - Experiment kg_completeness_0.25 completed
2024-09-05 10:44:28,994 - INFO - Experiment kg_completeness_0.25 completed
2024-09-05 10:44:28,995 - INFO - Running experiment: kg_completeness_0.5
2024-09-05 10:44:28,995 - INFO - Running experiment: kg_completeness_0.5
2024-09-05 10:44:28,996 - INFO - Using device: cuda
2024-09-05 10:44:28,996 - INFO - Using device: cuda
2024-09-05 10:44:28,996 - INFO - Using device: cuda
2024-09-05 12:27:25,014 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_0.5\profile_stats.txt
2024-09-05 12:27:25,014 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_0.5\profile_stats.txt
2024-09-05 12:27:25,014 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_0.5\profile_stats.txt
2024-09-05 12:39:33,153 - INFO - Training and evaluation completed.
2024-09-05 12:39:33,153 - INFO - Training and evaluation completed.
2024-09-05 12:39:33,153 - INFO - Training and evaluation completed.
2024-09-05 12:39:33,155 - INFO - Experiment kg_completeness_0.5 completed
2024-09-05 12:39:33,155 - INFO - Experiment kg_completeness_0.5 completed
2024-09-05 12:39:33,155 - INFO - Experiment kg_completeness_0.5 completed
2024-09-05 12:39:33,155 - INFO - Running experiment: kg_completeness_0.75
2024-09-05 12:39:33,155 - INFO - Running experiment: kg_completeness_0.75
2024-09-05 12:39:33,155 - INFO - Running experiment: kg_completeness_0.75
2024-09-05 12:39:33,157 - INFO - Using device: cuda
2024-09-05 12:39:33,157 - INFO - Using device: cuda
2024-09-05 12:39:33,157 - INFO - Using device: cuda
2024-09-05 12:39:33,157 - INFO - Using device: cuda
2024-09-05 14:21:47,660 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_0.75\profile_stats.txt
2024-09-05 14:21:47,660 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_0.75\profile_stats.txt
2024-09-05 14:21:47,660 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_0.75\profile_stats.txt
2024-09-05 14:21:47,660 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_0.75\profile_stats.txt
2024-09-05 14:34:01,821 - INFO - Training and evaluation completed.
2024-09-05 14:34:01,821 - INFO - Training and evaluation completed.
2024-09-05 14:34:01,821 - INFO - Training and evaluation completed.
2024-09-05 14:34:01,821 - INFO - Training and evaluation completed.
2024-09-05 14:34:01,823 - INFO - Experiment kg_completeness_0.75 completed
2024-09-05 14:34:01,823 - INFO - Experiment kg_completeness_0.75 completed
2024-09-05 14:34:01,823 - INFO - Experiment kg_completeness_0.75 completed
2024-09-05 14:34:01,823 - INFO - Experiment kg_completeness_0.75 completed
2024-09-05 14:34:01,823 - INFO - Running experiment: kg_completeness_1.0
2024-09-05 14:34:01,823 - INFO - Running experiment: kg_completeness_1.0
2024-09-05 14:34:01,823 - INFO - Running experiment: kg_completeness_1.0
2024-09-05 14:34:01,823 - INFO - Running experiment: kg_completeness_1.0
2024-09-05 14:34:01,826 - INFO - Using device: cuda
2024-09-05 14:34:01,826 - INFO - Using device: cuda
2024-09-05 14:34:01,826 - INFO - Using device: cuda
2024-09-05 14:34:01,826 - INFO - Using device: cuda
2024-09-05 14:34:01,826 - INFO - Using device: cuda
2024-09-05 16:15:59,398 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_1.0\profile_stats.txt
2024-09-05 16:15:59,398 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_1.0\profile_stats.txt
2024-09-05 16:15:59,398 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_1.0\profile_stats.txt
2024-09-05 16:15:59,398 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_1.0\profile_stats.txt
2024-09-05 16:15:59,398 - INFO - Profiling stats saved to results\20240905_084733\kg_completeness_1.0\profile_stats.txt
2024-09-05 16:28:27,744 - INFO - Training and evaluation completed.
2024-09-05 16:28:27,744 - INFO - Training and evaluation completed.
2024-09-05 16:28:27,744 - INFO - Training and evaluation completed.
2024-09-05 16:28:27,744 - INFO - Training and evaluation completed.
2024-09-05 16:28:27,744 - INFO - Training and evaluation completed.
2024-09-05 16:28:27,746 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 16:28:27,746 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 16:28:27,746 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 16:28:27,746 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 16:28:27,746 - INFO - Experiment kg_completeness_1.0 completed
2024-09-05 16:28:27,749 - INFO - Ablation study results saved to results\20240905_084733\ablation_study_results.json
2024-09-05 16:28:27,749 - INFO - Ablation study results saved to results\20240905_084733\ablation_study_results.json
2024-09-05 16:28:27,749 - INFO - Ablation study results saved to results\20240905_084733\ablation_study_results.json
2024-09-05 16:28:27,749 - INFO - Ablation study results saved to results\20240905_084733\ablation_study_results.json
2024-09-05 16:28:27,749 - INFO - Ablation study results saved to results\20240905_084733\ablation_study_results.json
2024-09-05 16:28:27,750 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.25_results.json
2024-09-05 16:28:27,750 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.25_results.json
2024-09-05 16:28:27,750 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.25_results.json
2024-09-05 16:28:27,750 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.25_results.json
2024-09-05 16:28:27,750 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.25_results.json
2024-09-05 16:28:27,753 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.5_results.json
2024-09-05 16:28:27,753 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.5_results.json
2024-09-05 16:28:27,753 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.5_results.json
2024-09-05 16:28:27,753 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.5_results.json
2024-09-05 16:28:27,753 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.5_results.json
2024-09-05 16:28:27,754 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.75_results.json
2024-09-05 16:28:27,754 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.75_results.json
2024-09-05 16:28:27,754 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.75_results.json
2024-09-05 16:28:27,754 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.75_results.json
2024-09-05 16:28:27,754 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_0.75_results.json
2024-09-05 16:28:27,756 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_1.0_results.json
2024-09-05 16:28:27,756 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_1.0_results.json
2024-09-05 16:28:27,756 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_1.0_results.json
2024-09-05 16:28:27,756 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_1.0_results.json
2024-09-05 16:28:27,756 - INFO - Individual experiment results saved to results\20240905_084733\kg_completeness_1.0_results.json
2024-09-05 16:28:27,757 - INFO - Base configuration saved to results\20240905_084733\base_config.json
2024-09-05 16:28:27,757 - INFO - Base configuration saved to results\20240905_084733\base_config.json
2024-09-05 16:28:27,757 - INFO - Base configuration saved to results\20240905_084733\base_config.json
2024-09-05 16:28:27,757 - INFO - Base configuration saved to results\20240905_084733\base_config.json
2024-09-05 16:28:27,757 - INFO - Base configuration saved to results\20240905_084733\base_config.json
2024-09-05 16:28:27,758 - INFO - Ablation Study completed
2024-09-05 16:28:27,758 - INFO - Ablation Study completed
2024-09-05 16:28:27,758 - INFO - Ablation Study completed
2024-09-05 16:28:27,758 - INFO - Ablation Study completed
2024-09-05 16:28:27,758 - INFO - Ablation Study completed
2024-09-05 17:07:16,488 - INFO - Created results directory: results\20240905_170716
2024-09-05 17:07:16,488 - INFO - Starting Ablation Study
2024-09-05 17:07:16,488 - INFO - Running experiment: kg_completeness_0.25
2024-09-05 17:07:16,555 - INFO - Using device: cuda
2024-09-05 17:07:16,555 - INFO - Using device: cuda
2024-09-05 19:25:41,349 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_0.25\profile_stats.txt
2024-09-05 19:25:41,349 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_0.25\profile_stats.txt
2024-09-05 19:38:21,536 - INFO - Training and evaluation completed.
2024-09-05 19:38:21,536 - INFO - Training and evaluation completed.
2024-09-05 19:38:21,541 - INFO - Experiment kg_completeness_0.25 completed
2024-09-05 19:38:21,541 - INFO - Experiment kg_completeness_0.25 completed
2024-09-05 19:38:21,542 - INFO - Running experiment: kg_completeness_0.5
2024-09-05 19:38:21,542 - INFO - Running experiment: kg_completeness_0.5
2024-09-05 19:38:21,551 - INFO - Using device: cuda
2024-09-05 19:38:21,551 - INFO - Using device: cuda
2024-09-05 19:38:21,551 - INFO - Using device: cuda
2024-09-05 21:54:56,740 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_0.5\profile_stats.txt
2024-09-05 21:54:56,740 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_0.5\profile_stats.txt
2024-09-05 21:54:56,740 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_0.5\profile_stats.txt
2024-09-05 22:07:57,983 - INFO - Training and evaluation completed.
2024-09-05 22:07:57,983 - INFO - Training and evaluation completed.
2024-09-05 22:07:57,983 - INFO - Training and evaluation completed.
2024-09-05 22:07:57,986 - INFO - Experiment kg_completeness_0.5 completed
2024-09-05 22:07:57,986 - INFO - Experiment kg_completeness_0.5 completed
2024-09-05 22:07:57,986 - INFO - Experiment kg_completeness_0.5 completed
2024-09-05 22:07:57,986 - INFO - Running experiment: kg_completeness_0.75
2024-09-05 22:07:57,986 - INFO - Running experiment: kg_completeness_0.75
2024-09-05 22:07:57,986 - INFO - Running experiment: kg_completeness_0.75
2024-09-05 22:07:57,995 - INFO - Using device: cuda
2024-09-05 22:07:57,995 - INFO - Using device: cuda
2024-09-05 22:07:57,995 - INFO - Using device: cuda
2024-09-05 22:07:57,995 - INFO - Using device: cuda
2024-09-06 00:19:31,861 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_0.75\profile_stats.txt
2024-09-06 00:19:31,861 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_0.75\profile_stats.txt
2024-09-06 00:19:31,861 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_0.75\profile_stats.txt
2024-09-06 00:19:31,861 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_0.75\profile_stats.txt
2024-09-06 00:31:46,295 - INFO - Training and evaluation completed.
2024-09-06 00:31:46,295 - INFO - Training and evaluation completed.
2024-09-06 00:31:46,295 - INFO - Training and evaluation completed.
2024-09-06 00:31:46,295 - INFO - Training and evaluation completed.
2024-09-06 00:31:46,298 - INFO - Experiment kg_completeness_0.75 completed
2024-09-06 00:31:46,298 - INFO - Experiment kg_completeness_0.75 completed
2024-09-06 00:31:46,298 - INFO - Experiment kg_completeness_0.75 completed
2024-09-06 00:31:46,298 - INFO - Experiment kg_completeness_0.75 completed
2024-09-06 00:31:46,298 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 00:31:46,298 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 00:31:46,298 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 00:31:46,298 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 00:31:46,299 - INFO - Using device: cuda
2024-09-06 00:31:46,299 - INFO - Using device: cuda
2024-09-06 00:31:46,299 - INFO - Using device: cuda
2024-09-06 00:31:46,299 - INFO - Using device: cuda
2024-09-06 00:31:46,299 - INFO - Using device: cuda
2024-09-06 02:42:31,378 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_1.0\profile_stats.txt
2024-09-06 02:42:31,378 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_1.0\profile_stats.txt
2024-09-06 02:42:31,378 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_1.0\profile_stats.txt
2024-09-06 02:42:31,378 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_1.0\profile_stats.txt
2024-09-06 02:42:31,378 - INFO - Profiling stats saved to results\20240905_170716\kg_completeness_1.0\profile_stats.txt
2024-09-06 02:54:48,796 - INFO - Training and evaluation completed.
2024-09-06 02:54:48,796 - INFO - Training and evaluation completed.
2024-09-06 02:54:48,796 - INFO - Training and evaluation completed.
2024-09-06 02:54:48,796 - INFO - Training and evaluation completed.
2024-09-06 02:54:48,796 - INFO - Training and evaluation completed.
2024-09-06 02:54:48,798 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 02:54:48,798 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 02:54:48,798 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 02:54:48,798 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 02:54:48,798 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 02:54:48,800 - INFO - Ablation study results saved to results\20240905_170716\ablation_study_results.json
2024-09-06 02:54:48,800 - INFO - Ablation study results saved to results\20240905_170716\ablation_study_results.json
2024-09-06 02:54:48,800 - INFO - Ablation study results saved to results\20240905_170716\ablation_study_results.json
2024-09-06 02:54:48,800 - INFO - Ablation study results saved to results\20240905_170716\ablation_study_results.json
2024-09-06 02:54:48,800 - INFO - Ablation study results saved to results\20240905_170716\ablation_study_results.json
2024-09-06 02:54:48,801 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.25_results.json
2024-09-06 02:54:48,801 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.25_results.json
2024-09-06 02:54:48,801 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.25_results.json
2024-09-06 02:54:48,801 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.25_results.json
2024-09-06 02:54:48,801 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.25_results.json
2024-09-06 02:54:48,802 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.5_results.json
2024-09-06 02:54:48,802 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.5_results.json
2024-09-06 02:54:48,802 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.5_results.json
2024-09-06 02:54:48,802 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.5_results.json
2024-09-06 02:54:48,802 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.5_results.json
2024-09-06 02:54:48,804 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.75_results.json
2024-09-06 02:54:48,804 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.75_results.json
2024-09-06 02:54:48,804 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.75_results.json
2024-09-06 02:54:48,804 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.75_results.json
2024-09-06 02:54:48,804 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_0.75_results.json
2024-09-06 02:54:48,805 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_1.0_results.json
2024-09-06 02:54:48,805 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_1.0_results.json
2024-09-06 02:54:48,805 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_1.0_results.json
2024-09-06 02:54:48,805 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_1.0_results.json
2024-09-06 02:54:48,805 - INFO - Individual experiment results saved to results\20240905_170716\kg_completeness_1.0_results.json
2024-09-06 02:54:48,807 - INFO - Base configuration saved to results\20240905_170716\base_config.json
2024-09-06 02:54:48,807 - INFO - Base configuration saved to results\20240905_170716\base_config.json
2024-09-06 02:54:48,807 - INFO - Base configuration saved to results\20240905_170716\base_config.json
2024-09-06 02:54:48,807 - INFO - Base configuration saved to results\20240905_170716\base_config.json
2024-09-06 02:54:48,807 - INFO - Base configuration saved to results\20240905_170716\base_config.json
2024-09-06 02:54:48,807 - INFO - Ablation Study completed
2024-09-06 02:54:48,807 - INFO - Ablation Study completed
2024-09-06 02:54:48,807 - INFO - Ablation Study completed
2024-09-06 02:54:48,807 - INFO - Ablation Study completed
2024-09-06 02:54:48,807 - INFO - Ablation Study completed
2024-09-06 03:05:51,359 - INFO - Created results directory: results\20240906_030551
2024-09-06 03:05:51,359 - INFO - Starting Ablation Study
2024-09-06 03:05:51,359 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:05:51,427 - INFO - Using device: cuda
2024-09-06 03:05:51,427 - INFO - Using device: cuda
2024-09-06 03:05:51,566 - ERROR - An error occurred during experiment kg_completeness_0.25: 0
2024-09-06 03:05:51,566 - ERROR - An error occurred during experiment kg_completeness_0.25: 0
2024-09-06 03:05:51,570 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:05:51,570 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:05:51,574 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:05:51,574 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:05:51,575 - INFO - Using device: cuda
2024-09-06 03:05:51,575 - INFO - Using device: cuda
2024-09-06 03:05:51,575 - INFO - Using device: cuda
2024-09-06 03:05:51,601 - ERROR - An error occurred during experiment kg_completeness_0.5: 2
2024-09-06 03:05:51,601 - ERROR - An error occurred during experiment kg_completeness_0.5: 2
2024-09-06 03:05:51,601 - ERROR - An error occurred during experiment kg_completeness_0.5: 2
2024-09-06 03:05:51,603 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,603 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,603 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,607 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:05:51,607 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:05:51,607 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:05:51,609 - INFO - Using device: cuda
2024-09-06 03:05:51,609 - INFO - Using device: cuda
2024-09-06 03:05:51,609 - INFO - Using device: cuda
2024-09-06 03:05:51,609 - INFO - Using device: cuda
2024-09-06 03:05:51,630 - ERROR - An error occurred during experiment kg_completeness_0.75: 2
2024-09-06 03:05:51,630 - ERROR - An error occurred during experiment kg_completeness_0.75: 2
2024-09-06 03:05:51,630 - ERROR - An error occurred during experiment kg_completeness_0.75: 2
2024-09-06 03:05:51,630 - ERROR - An error occurred during experiment kg_completeness_0.75: 2
2024-09-06 03:05:51,633 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,633 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,633 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,633 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,640 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:05:51,640 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:05:51,640 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:05:51,640 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:05:51,641 - INFO - Using device: cuda
2024-09-06 03:05:51,641 - INFO - Using device: cuda
2024-09-06 03:05:51,641 - INFO - Using device: cuda
2024-09-06 03:05:51,641 - INFO - Using device: cuda
2024-09-06 03:05:51,641 - INFO - Using device: cuda
2024-09-06 03:05:51,665 - ERROR - An error occurred during experiment kg_completeness_1.0: 2
2024-09-06 03:05:51,665 - ERROR - An error occurred during experiment kg_completeness_1.0: 2
2024-09-06 03:05:51,665 - ERROR - An error occurred during experiment kg_completeness_1.0: 2
2024-09-06 03:05:51,665 - ERROR - An error occurred during experiment kg_completeness_1.0: 2
2024-09-06 03:05:51,665 - ERROR - An error occurred during experiment kg_completeness_1.0: 2
2024-09-06 03:05:51,669 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,669 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,669 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,669 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,669 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:05:51,677 - INFO - Ablation study results saved to results\20240906_030551\ablation_study_results.json
2024-09-06 03:05:51,677 - INFO - Ablation study results saved to results\20240906_030551\ablation_study_results.json
2024-09-06 03:05:51,677 - INFO - Ablation study results saved to results\20240906_030551\ablation_study_results.json
2024-09-06 03:05:51,677 - INFO - Ablation study results saved to results\20240906_030551\ablation_study_results.json
2024-09-06 03:05:51,677 - INFO - Ablation study results saved to results\20240906_030551\ablation_study_results.json
2024-09-06 03:05:51,677 - INFO - Base configuration saved to results\20240906_030551\base_config.json
2024-09-06 03:05:51,677 - INFO - Base configuration saved to results\20240906_030551\base_config.json
2024-09-06 03:05:51,677 - INFO - Base configuration saved to results\20240906_030551\base_config.json
2024-09-06 03:05:51,677 - INFO - Base configuration saved to results\20240906_030551\base_config.json
2024-09-06 03:05:51,677 - INFO - Base configuration saved to results\20240906_030551\base_config.json
2024-09-06 03:05:51,677 - INFO - Ablation Study completed
2024-09-06 03:05:51,677 - INFO - Ablation Study completed
2024-09-06 03:05:51,677 - INFO - Ablation Study completed
2024-09-06 03:05:51,677 - INFO - Ablation Study completed
2024-09-06 03:05:51,677 - INFO - Ablation Study completed
2024-09-06 03:06:29,718 - INFO - Created results directory: results\20240906_030629
2024-09-06 03:06:29,718 - INFO - Starting Ablation Study
2024-09-06 03:06:29,718 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:06:29,746 - INFO - Using device: cuda
2024-09-06 03:06:29,746 - INFO - Using device: cuda
2024-09-06 03:06:29,806 - ERROR - An error occurred during experiment kg_completeness_0.25: 3
2024-09-06 03:06:29,806 - ERROR - An error occurred during experiment kg_completeness_0.25: 3
2024-09-06 03:06:29,806 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 3

2024-09-06 03:06:29,806 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 3

2024-09-06 03:06:29,816 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:06:29,816 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:06:29,817 - INFO - Using device: cuda
2024-09-06 03:06:29,817 - INFO - Using device: cuda
2024-09-06 03:06:29,817 - INFO - Using device: cuda
2024-09-06 03:06:29,856 - ERROR - An error occurred during experiment kg_completeness_0.5: 2
2024-09-06 03:06:29,856 - ERROR - An error occurred during experiment kg_completeness_0.5: 2
2024-09-06 03:06:29,856 - ERROR - An error occurred during experiment kg_completeness_0.5: 2
2024-09-06 03:06:29,858 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:06:29,858 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:06:29,858 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:06:29,862 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:06:29,862 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:06:29,862 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:06:29,863 - INFO - Using device: cuda
2024-09-06 03:06:29,863 - INFO - Using device: cuda
2024-09-06 03:06:29,863 - INFO - Using device: cuda
2024-09-06 03:06:29,863 - INFO - Using device: cuda
2024-09-06 03:06:29,876 - ERROR - An error occurred during experiment kg_completeness_0.75: 3
2024-09-06 03:06:29,876 - ERROR - An error occurred during experiment kg_completeness_0.75: 3
2024-09-06 03:06:29,876 - ERROR - An error occurred during experiment kg_completeness_0.75: 3
2024-09-06 03:06:29,876 - ERROR - An error occurred during experiment kg_completeness_0.75: 3
2024-09-06 03:06:29,878 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 3

2024-09-06 03:06:29,878 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 3

2024-09-06 03:06:29,878 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 3

2024-09-06 03:06:29,878 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 3

2024-09-06 03:06:29,885 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:06:29,885 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:06:29,885 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:06:29,885 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:06:29,886 - INFO - Using device: cuda
2024-09-06 03:06:29,886 - INFO - Using device: cuda
2024-09-06 03:06:29,886 - INFO - Using device: cuda
2024-09-06 03:06:29,886 - INFO - Using device: cuda
2024-09-06 03:06:29,886 - INFO - Using device: cuda
2024-09-06 03:06:29,915 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:06:29,915 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:06:29,915 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:06:29,915 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:06:29,915 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:06:29,915 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:06:29,915 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:06:29,915 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:06:29,915 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:06:29,915 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:06:29,926 - INFO - Ablation study results saved to results\20240906_030629\ablation_study_results.json
2024-09-06 03:06:29,926 - INFO - Ablation study results saved to results\20240906_030629\ablation_study_results.json
2024-09-06 03:06:29,926 - INFO - Ablation study results saved to results\20240906_030629\ablation_study_results.json
2024-09-06 03:06:29,926 - INFO - Ablation study results saved to results\20240906_030629\ablation_study_results.json
2024-09-06 03:06:29,926 - INFO - Ablation study results saved to results\20240906_030629\ablation_study_results.json
2024-09-06 03:06:29,926 - INFO - Base configuration saved to results\20240906_030629\base_config.json
2024-09-06 03:06:29,926 - INFO - Base configuration saved to results\20240906_030629\base_config.json
2024-09-06 03:06:29,926 - INFO - Base configuration saved to results\20240906_030629\base_config.json
2024-09-06 03:06:29,926 - INFO - Base configuration saved to results\20240906_030629\base_config.json
2024-09-06 03:06:29,926 - INFO - Base configuration saved to results\20240906_030629\base_config.json
2024-09-06 03:06:29,927 - INFO - Ablation Study completed
2024-09-06 03:06:29,927 - INFO - Ablation Study completed
2024-09-06 03:06:29,927 - INFO - Ablation Study completed
2024-09-06 03:06:29,927 - INFO - Ablation Study completed
2024-09-06 03:06:29,927 - INFO - Ablation Study completed
2024-09-06 03:08:43,377 - INFO - Created results directory: results\20240906_030843
2024-09-06 03:08:43,378 - INFO - Starting Ablation Study
2024-09-06 03:08:43,378 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:08:43,398 - INFO - Using device: cuda
2024-09-06 03:08:43,398 - INFO - Using device: cuda
2024-09-06 03:08:43,518 - ERROR - An error occurred during experiment kg_completeness_0.25: 0
2024-09-06 03:08:43,518 - ERROR - An error occurred during experiment kg_completeness_0.25: 0
2024-09-06 03:08:43,519 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,519 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,524 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:08:43,524 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:08:43,526 - INFO - Using device: cuda
2024-09-06 03:08:43,526 - INFO - Using device: cuda
2024-09-06 03:08:43,526 - INFO - Using device: cuda
2024-09-06 03:08:43,629 - ERROR - An error occurred during experiment kg_completeness_0.5: 0
2024-09-06 03:08:43,629 - ERROR - An error occurred during experiment kg_completeness_0.5: 0
2024-09-06 03:08:43,629 - ERROR - An error occurred during experiment kg_completeness_0.5: 0
2024-09-06 03:08:43,632 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,632 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,632 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,637 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:08:43,637 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:08:43,637 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:08:43,639 - INFO - Using device: cuda
2024-09-06 03:08:43,639 - INFO - Using device: cuda
2024-09-06 03:08:43,639 - INFO - Using device: cuda
2024-09-06 03:08:43,639 - INFO - Using device: cuda
2024-09-06 03:08:43,702 - ERROR - An error occurred during experiment kg_completeness_0.75: 2
2024-09-06 03:08:43,702 - ERROR - An error occurred during experiment kg_completeness_0.75: 2
2024-09-06 03:08:43,702 - ERROR - An error occurred during experiment kg_completeness_0.75: 2
2024-09-06 03:08:43,702 - ERROR - An error occurred during experiment kg_completeness_0.75: 2
2024-09-06 03:08:43,711 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:08:43,711 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:08:43,711 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:08:43,711 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 2

2024-09-06 03:08:43,726 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:08:43,726 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:08:43,726 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:08:43,726 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:08:43,729 - INFO - Using device: cuda
2024-09-06 03:08:43,729 - INFO - Using device: cuda
2024-09-06 03:08:43,729 - INFO - Using device: cuda
2024-09-06 03:08:43,729 - INFO - Using device: cuda
2024-09-06 03:08:43,729 - INFO - Using device: cuda
2024-09-06 03:08:43,896 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:08:43,896 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:08:43,896 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:08:43,896 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:08:43,896 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:08:43,900 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,900 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,900 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,900 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,900 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=2)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:08:43,908 - INFO - Ablation study results saved to results\20240906_030843\ablation_study_results.json
2024-09-06 03:08:43,908 - INFO - Ablation study results saved to results\20240906_030843\ablation_study_results.json
2024-09-06 03:08:43,908 - INFO - Ablation study results saved to results\20240906_030843\ablation_study_results.json
2024-09-06 03:08:43,908 - INFO - Ablation study results saved to results\20240906_030843\ablation_study_results.json
2024-09-06 03:08:43,908 - INFO - Ablation study results saved to results\20240906_030843\ablation_study_results.json
2024-09-06 03:08:43,908 - INFO - Base configuration saved to results\20240906_030843\base_config.json
2024-09-06 03:08:43,908 - INFO - Base configuration saved to results\20240906_030843\base_config.json
2024-09-06 03:08:43,908 - INFO - Base configuration saved to results\20240906_030843\base_config.json
2024-09-06 03:08:43,908 - INFO - Base configuration saved to results\20240906_030843\base_config.json
2024-09-06 03:08:43,908 - INFO - Base configuration saved to results\20240906_030843\base_config.json
2024-09-06 03:08:43,911 - INFO - Ablation Study completed
2024-09-06 03:08:43,911 - INFO - Ablation Study completed
2024-09-06 03:08:43,911 - INFO - Ablation Study completed
2024-09-06 03:08:43,911 - INFO - Ablation Study completed
2024-09-06 03:08:43,911 - INFO - Ablation Study completed
2024-09-06 03:09:20,551 - INFO - Created results directory: results\20240906_030920
2024-09-06 03:09:20,551 - INFO - Starting Ablation Study
2024-09-06 03:09:20,551 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:09:20,574 - INFO - Using device: cuda
2024-09-06 03:09:20,574 - INFO - Using device: cuda
2024-09-06 03:09:22,367 - ERROR - An error occurred during experiment kg_completeness_0.25: min() arg is an empty sequence
2024-09-06 03:09:22,367 - ERROR - An error occurred during experiment kg_completeness_0.25: min() arg is an empty sequence
2024-09-06 03:09:22,374 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:22,374 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:22,376 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:09:22,376 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:09:22,377 - INFO - Using device: cuda
2024-09-06 03:09:22,377 - INFO - Using device: cuda
2024-09-06 03:09:22,377 - INFO - Using device: cuda
2024-09-06 03:09:24,157 - ERROR - An error occurred during experiment kg_completeness_0.5: min() arg is an empty sequence
2024-09-06 03:09:24,157 - ERROR - An error occurred during experiment kg_completeness_0.5: min() arg is an empty sequence
2024-09-06 03:09:24,157 - ERROR - An error occurred during experiment kg_completeness_0.5: min() arg is an empty sequence
2024-09-06 03:09:24,157 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:24,157 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:24,157 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:24,161 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:09:24,161 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:09:24,161 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:09:24,163 - INFO - Using device: cuda
2024-09-06 03:09:24,163 - INFO - Using device: cuda
2024-09-06 03:09:24,163 - INFO - Using device: cuda
2024-09-06 03:09:24,163 - INFO - Using device: cuda
2024-09-06 03:09:25,932 - ERROR - An error occurred during experiment kg_completeness_0.75: min() arg is an empty sequence
2024-09-06 03:09:25,932 - ERROR - An error occurred during experiment kg_completeness_0.75: min() arg is an empty sequence
2024-09-06 03:09:25,932 - ERROR - An error occurred during experiment kg_completeness_0.75: min() arg is an empty sequence
2024-09-06 03:09:25,932 - ERROR - An error occurred during experiment kg_completeness_0.75: min() arg is an empty sequence
2024-09-06 03:09:25,934 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:25,934 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:25,934 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:25,934 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:25,937 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:09:25,937 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:09:25,937 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:09:25,937 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:09:25,938 - INFO - Using device: cuda
2024-09-06 03:09:25,938 - INFO - Using device: cuda
2024-09-06 03:09:25,938 - INFO - Using device: cuda
2024-09-06 03:09:25,938 - INFO - Using device: cuda
2024-09-06 03:09:25,938 - INFO - Using device: cuda
2024-09-06 03:09:27,672 - ERROR - An error occurred during experiment kg_completeness_1.0: min() arg is an empty sequence
2024-09-06 03:09:27,672 - ERROR - An error occurred during experiment kg_completeness_1.0: min() arg is an empty sequence
2024-09-06 03:09:27,672 - ERROR - An error occurred during experiment kg_completeness_1.0: min() arg is an empty sequence
2024-09-06 03:09:27,672 - ERROR - An error occurred during experiment kg_completeness_1.0: min() arg is an empty sequence
2024-09-06 03:09:27,672 - ERROR - An error occurred during experiment kg_completeness_1.0: min() arg is an empty sequence
2024-09-06 03:09:27,676 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:27,676 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:27,676 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:27,676 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:27,676 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 18, in __init__
    self.curriculum_indices, step_size = self.get_curriculum(number_of_curricula + 1)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 72, in get_curriculum
    min_energy, max_energy = min(energy_values), max(energy_values)
                             ^^^^^^^^^^^^^^^^^^
ValueError: min() arg is an empty sequence

2024-09-06 03:09:27,681 - INFO - Ablation study results saved to results\20240906_030920\ablation_study_results.json
2024-09-06 03:09:27,681 - INFO - Ablation study results saved to results\20240906_030920\ablation_study_results.json
2024-09-06 03:09:27,681 - INFO - Ablation study results saved to results\20240906_030920\ablation_study_results.json
2024-09-06 03:09:27,681 - INFO - Ablation study results saved to results\20240906_030920\ablation_study_results.json
2024-09-06 03:09:27,681 - INFO - Ablation study results saved to results\20240906_030920\ablation_study_results.json
2024-09-06 03:09:27,683 - INFO - Base configuration saved to results\20240906_030920\base_config.json
2024-09-06 03:09:27,683 - INFO - Base configuration saved to results\20240906_030920\base_config.json
2024-09-06 03:09:27,683 - INFO - Base configuration saved to results\20240906_030920\base_config.json
2024-09-06 03:09:27,683 - INFO - Base configuration saved to results\20240906_030920\base_config.json
2024-09-06 03:09:27,683 - INFO - Base configuration saved to results\20240906_030920\base_config.json
2024-09-06 03:09:27,684 - INFO - Ablation Study completed
2024-09-06 03:09:27,684 - INFO - Ablation Study completed
2024-09-06 03:09:27,684 - INFO - Ablation Study completed
2024-09-06 03:09:27,684 - INFO - Ablation Study completed
2024-09-06 03:09:27,684 - INFO - Ablation Study completed
2024-09-06 03:10:14,904 - INFO - Created results directory: results\20240906_031014
2024-09-06 03:10:14,909 - INFO - Starting Ablation Study
2024-09-06 03:10:14,909 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:10:14,935 - INFO - Using device: cuda
2024-09-06 03:10:14,935 - INFO - Using device: cuda
2024-09-06 03:10:14,993 - ERROR - An error occurred during experiment kg_completeness_0.25: 0
2024-09-06 03:10:14,993 - ERROR - An error occurred during experiment kg_completeness_0.25: 0
2024-09-06 03:10:15,000 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,000 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,005 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:10:15,005 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:10:15,007 - INFO - Using device: cuda
2024-09-06 03:10:15,007 - INFO - Using device: cuda
2024-09-06 03:10:15,007 - INFO - Using device: cuda
2024-09-06 03:10:15,018 - ERROR - An error occurred during experiment kg_completeness_0.5: 0
2024-09-06 03:10:15,018 - ERROR - An error occurred during experiment kg_completeness_0.5: 0
2024-09-06 03:10:15,018 - ERROR - An error occurred during experiment kg_completeness_0.5: 0
2024-09-06 03:10:15,020 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,020 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,020 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,025 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:10:15,025 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:10:15,025 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:10:15,026 - INFO - Using device: cuda
2024-09-06 03:10:15,026 - INFO - Using device: cuda
2024-09-06 03:10:15,026 - INFO - Using device: cuda
2024-09-06 03:10:15,026 - INFO - Using device: cuda
2024-09-06 03:10:15,121 - ERROR - An error occurred during experiment kg_completeness_0.75: 1
2024-09-06 03:10:15,121 - ERROR - An error occurred during experiment kg_completeness_0.75: 1
2024-09-06 03:10:15,121 - ERROR - An error occurred during experiment kg_completeness_0.75: 1
2024-09-06 03:10:15,121 - ERROR - An error occurred during experiment kg_completeness_0.75: 1
2024-09-06 03:10:15,126 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 1

2024-09-06 03:10:15,126 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 1

2024-09-06 03:10:15,126 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 1

2024-09-06 03:10:15,126 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 1

2024-09-06 03:10:15,133 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:10:15,133 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:10:15,133 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:10:15,133 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:10:15,135 - INFO - Using device: cuda
2024-09-06 03:10:15,135 - INFO - Using device: cuda
2024-09-06 03:10:15,135 - INFO - Using device: cuda
2024-09-06 03:10:15,135 - INFO - Using device: cuda
2024-09-06 03:10:15,135 - INFO - Using device: cuda
2024-09-06 03:10:15,142 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:10:15,142 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:10:15,142 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:10:15,142 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:10:15,142 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-06 03:10:15,144 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,144 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,144 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,144 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,144 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 0

2024-09-06 03:10:15,153 - INFO - Ablation study results saved to results\20240906_031014\ablation_study_results.json
2024-09-06 03:10:15,153 - INFO - Ablation study results saved to results\20240906_031014\ablation_study_results.json
2024-09-06 03:10:15,153 - INFO - Ablation study results saved to results\20240906_031014\ablation_study_results.json
2024-09-06 03:10:15,153 - INFO - Ablation study results saved to results\20240906_031014\ablation_study_results.json
2024-09-06 03:10:15,153 - INFO - Ablation study results saved to results\20240906_031014\ablation_study_results.json
2024-09-06 03:10:15,154 - INFO - Base configuration saved to results\20240906_031014\base_config.json
2024-09-06 03:10:15,154 - INFO - Base configuration saved to results\20240906_031014\base_config.json
2024-09-06 03:10:15,154 - INFO - Base configuration saved to results\20240906_031014\base_config.json
2024-09-06 03:10:15,154 - INFO - Base configuration saved to results\20240906_031014\base_config.json
2024-09-06 03:10:15,154 - INFO - Base configuration saved to results\20240906_031014\base_config.json
2024-09-06 03:10:15,155 - INFO - Ablation Study completed
2024-09-06 03:10:15,155 - INFO - Ablation Study completed
2024-09-06 03:10:15,155 - INFO - Ablation Study completed
2024-09-06 03:10:15,155 - INFO - Ablation Study completed
2024-09-06 03:10:15,155 - INFO - Ablation Study completed
2024-09-06 03:10:33,675 - INFO - Created results directory: results\20240906_031033
2024-09-06 03:10:33,675 - INFO - Starting Ablation Study
2024-09-06 03:10:33,675 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:10:33,707 - INFO - Using device: cuda
2024-09-06 03:10:33,707 - INFO - Using device: cuda
2024-09-06 03:10:38,833 - ERROR - An error occurred during experiment kg_completeness_0.25: 1
2024-09-06 03:10:38,833 - ERROR - An error occurred during experiment kg_completeness_0.25: 1
2024-09-06 03:10:38,836 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 384, in setup
    self.eval_env: CustomEnv = self.env_manager.make_env()
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 1

2024-09-06 03:10:38,836 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 384, in setup
    self.eval_env: CustomEnv = self.env_manager.make_env()
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 130, in init_player
    location = random.choice(self.less_suitable_terrain_locations)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 374, in choice
    return seq[self._randbelow(len(seq))]
           ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 1

2024-09-06 03:10:38,842 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:10:38,842 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:10:38,843 - INFO - Using device: cuda
2024-09-06 03:10:38,843 - INFO - Using device: cuda
2024-09-06 03:10:38,843 - INFO - Using device: cuda
2024-09-06 03:18:41,881 - INFO - Created results directory: results\20240906_031841
2024-09-06 03:18:41,881 - INFO - Starting Ablation Study
2024-09-06 03:18:41,881 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:18:41,905 - INFO - Using device: cuda
2024-09-06 03:18:41,905 - INFO - Using device: cuda
2024-09-06 03:19:14,901 - INFO - Created results directory: results\20240906_031914
2024-09-06 03:19:14,901 - INFO - Starting Ablation Study
2024-09-06 03:19:14,901 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:19:14,926 - INFO - Using device: cuda
2024-09-06 03:19:14,926 - INFO - Using device: cuda
2024-09-06 03:19:14,988 - ERROR - An error occurred during experiment kg_completeness_0.25: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:14,988 - ERROR - An error occurred during experiment kg_completeness_0.25: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:14,991 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:14,991 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:14,994 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:19:14,994 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:19:14,995 - INFO - Using device: cuda
2024-09-06 03:19:14,995 - INFO - Using device: cuda
2024-09-06 03:19:14,995 - INFO - Using device: cuda
2024-09-06 03:19:15,024 - ERROR - An error occurred during experiment kg_completeness_0.5: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,024 - ERROR - An error occurred during experiment kg_completeness_0.5: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,024 - ERROR - An error occurred during experiment kg_completeness_0.5: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,027 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,027 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,027 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,031 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:19:15,031 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:19:15,031 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:19:15,032 - INFO - Using device: cuda
2024-09-06 03:19:15,032 - INFO - Using device: cuda
2024-09-06 03:19:15,032 - INFO - Using device: cuda
2024-09-06 03:19:15,032 - INFO - Using device: cuda
2024-09-06 03:19:15,102 - ERROR - An error occurred during experiment kg_completeness_0.75: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,102 - ERROR - An error occurred during experiment kg_completeness_0.75: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,102 - ERROR - An error occurred during experiment kg_completeness_0.75: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,102 - ERROR - An error occurred during experiment kg_completeness_0.75: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,104 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,104 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,104 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,104 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,110 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:19:15,110 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:19:15,110 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:19:15,110 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:19:15,111 - INFO - Using device: cuda
2024-09-06 03:19:15,111 - INFO - Using device: cuda
2024-09-06 03:19:15,111 - INFO - Using device: cuda
2024-09-06 03:19:15,111 - INFO - Using device: cuda
2024-09-06 03:19:15,111 - INFO - Using device: cuda
2024-09-06 03:19:15,162 - ERROR - An error occurred during experiment kg_completeness_1.0: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,162 - ERROR - An error occurred during experiment kg_completeness_1.0: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,162 - ERROR - An error occurred during experiment kg_completeness_1.0: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,162 - ERROR - An error occurred during experiment kg_completeness_1.0: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,162 - ERROR - An error occurred during experiment kg_completeness_1.0: 'Environment' object has no attribute 'remove_entity'
2024-09-06 03:19:15,162 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,162 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,162 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,162 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,162 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 146, in init_player
    self.remove_entity(location[0], location[1])
    ^^^^^^^^^^^^^^^^^^
AttributeError: 'Environment' object has no attribute 'remove_entity'

2024-09-06 03:19:15,175 - INFO - Ablation study results saved to results\20240906_031914\ablation_study_results.json
2024-09-06 03:19:15,175 - INFO - Ablation study results saved to results\20240906_031914\ablation_study_results.json
2024-09-06 03:19:15,175 - INFO - Ablation study results saved to results\20240906_031914\ablation_study_results.json
2024-09-06 03:19:15,175 - INFO - Ablation study results saved to results\20240906_031914\ablation_study_results.json
2024-09-06 03:19:15,175 - INFO - Ablation study results saved to results\20240906_031914\ablation_study_results.json
2024-09-06 03:19:15,177 - INFO - Base configuration saved to results\20240906_031914\base_config.json
2024-09-06 03:19:15,177 - INFO - Base configuration saved to results\20240906_031914\base_config.json
2024-09-06 03:19:15,177 - INFO - Base configuration saved to results\20240906_031914\base_config.json
2024-09-06 03:19:15,177 - INFO - Base configuration saved to results\20240906_031914\base_config.json
2024-09-06 03:19:15,177 - INFO - Base configuration saved to results\20240906_031914\base_config.json
2024-09-06 03:19:15,177 - INFO - Ablation Study completed
2024-09-06 03:19:15,177 - INFO - Ablation Study completed
2024-09-06 03:19:15,177 - INFO - Ablation Study completed
2024-09-06 03:19:15,177 - INFO - Ablation Study completed
2024-09-06 03:19:15,177 - INFO - Ablation Study completed
2024-09-06 03:21:19,320 - INFO - Created results directory: results\20240906_032119
2024-09-06 03:21:19,320 - INFO - Starting Ablation Study
2024-09-06 03:21:19,320 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:21:19,343 - INFO - Using device: cuda
2024-09-06 03:21:19,343 - INFO - Using device: cuda
2024-09-06 03:21:19,830 - ERROR - An error occurred during experiment kg_completeness_0.25: Cannot choose from an empty sequence
2024-09-06 03:21:19,830 - ERROR - An error occurred during experiment kg_completeness_0.25: Cannot choose from an empty sequence
2024-09-06 03:21:19,833 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:19,833 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:19,838 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:21:19,838 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 03:21:19,840 - INFO - Using device: cuda
2024-09-06 03:21:19,840 - INFO - Using device: cuda
2024-09-06 03:21:19,840 - INFO - Using device: cuda
2024-09-06 03:21:19,901 - ERROR - An error occurred during experiment kg_completeness_0.5: Cannot choose from an empty sequence
2024-09-06 03:21:19,901 - ERROR - An error occurred during experiment kg_completeness_0.5: Cannot choose from an empty sequence
2024-09-06 03:21:19,901 - ERROR - An error occurred during experiment kg_completeness_0.5: Cannot choose from an empty sequence
2024-09-06 03:21:19,901 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:19,901 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:19,901 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:19,910 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:21:19,910 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:21:19,910 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 03:21:19,911 - INFO - Using device: cuda
2024-09-06 03:21:19,911 - INFO - Using device: cuda
2024-09-06 03:21:19,911 - INFO - Using device: cuda
2024-09-06 03:21:19,911 - INFO - Using device: cuda
2024-09-06 03:21:20,030 - ERROR - An error occurred during experiment kg_completeness_0.75: Cannot choose from an empty sequence
2024-09-06 03:21:20,030 - ERROR - An error occurred during experiment kg_completeness_0.75: Cannot choose from an empty sequence
2024-09-06 03:21:20,030 - ERROR - An error occurred during experiment kg_completeness_0.75: Cannot choose from an empty sequence
2024-09-06 03:21:20,030 - ERROR - An error occurred during experiment kg_completeness_0.75: Cannot choose from an empty sequence
2024-09-06 03:21:20,030 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:20,030 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:20,030 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:20,030 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:20,051 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:21:20,051 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:21:20,051 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:21:20,051 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 03:21:20,052 - INFO - Using device: cuda
2024-09-06 03:21:20,052 - INFO - Using device: cuda
2024-09-06 03:21:20,052 - INFO - Using device: cuda
2024-09-06 03:21:20,052 - INFO - Using device: cuda
2024-09-06 03:21:20,052 - INFO - Using device: cuda
2024-09-06 03:21:20,214 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-06 03:21:20,214 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-06 03:21:20,214 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-06 03:21:20,214 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-06 03:21:20,214 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-06 03:21:20,217 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:20,217 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:20,217 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:20,217 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:20,217 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 145, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 46, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-06 03:21:20,226 - INFO - Ablation study results saved to results\20240906_032119\ablation_study_results.json
2024-09-06 03:21:20,226 - INFO - Ablation study results saved to results\20240906_032119\ablation_study_results.json
2024-09-06 03:21:20,226 - INFO - Ablation study results saved to results\20240906_032119\ablation_study_results.json
2024-09-06 03:21:20,226 - INFO - Ablation study results saved to results\20240906_032119\ablation_study_results.json
2024-09-06 03:21:20,226 - INFO - Ablation study results saved to results\20240906_032119\ablation_study_results.json
2024-09-06 03:21:20,229 - INFO - Base configuration saved to results\20240906_032119\base_config.json
2024-09-06 03:21:20,229 - INFO - Base configuration saved to results\20240906_032119\base_config.json
2024-09-06 03:21:20,229 - INFO - Base configuration saved to results\20240906_032119\base_config.json
2024-09-06 03:21:20,229 - INFO - Base configuration saved to results\20240906_032119\base_config.json
2024-09-06 03:21:20,229 - INFO - Base configuration saved to results\20240906_032119\base_config.json
2024-09-06 03:21:20,229 - INFO - Ablation Study completed
2024-09-06 03:21:20,229 - INFO - Ablation Study completed
2024-09-06 03:21:20,229 - INFO - Ablation Study completed
2024-09-06 03:21:20,229 - INFO - Ablation Study completed
2024-09-06 03:21:20,229 - INFO - Ablation Study completed
2024-09-06 03:21:53,037 - INFO - Created results directory: results\20240906_032153
2024-09-06 03:21:53,037 - INFO - Starting Ablation Study
2024-09-06 03:21:53,037 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 03:21:53,056 - INFO - Using device: cuda
2024-09-06 03:21:53,056 - INFO - Using device: cuda
2024-09-06 05:03:40,697 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_0.25\profile_stats.txt
2024-09-06 05:03:40,697 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_0.25\profile_stats.txt
2024-09-06 05:14:33,745 - INFO - Training and evaluation completed.
2024-09-06 05:14:33,745 - INFO - Training and evaluation completed.
2024-09-06 05:14:33,750 - INFO - Experiment kg_completeness_0.25 completed
2024-09-06 05:14:33,750 - INFO - Experiment kg_completeness_0.25 completed
2024-09-06 05:14:33,751 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 05:14:33,751 - INFO - Running experiment: kg_completeness_0.5
2024-09-06 05:14:33,753 - INFO - Using device: cuda
2024-09-06 05:14:33,753 - INFO - Using device: cuda
2024-09-06 05:14:33,753 - INFO - Using device: cuda
2024-09-06 06:55:48,861 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_0.5\profile_stats.txt
2024-09-06 06:55:48,861 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_0.5\profile_stats.txt
2024-09-06 06:55:48,861 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_0.5\profile_stats.txt
2024-09-06 07:06:43,281 - INFO - Training and evaluation completed.
2024-09-06 07:06:43,281 - INFO - Training and evaluation completed.
2024-09-06 07:06:43,281 - INFO - Training and evaluation completed.
2024-09-06 07:06:43,283 - INFO - Experiment kg_completeness_0.5 completed
2024-09-06 07:06:43,283 - INFO - Experiment kg_completeness_0.5 completed
2024-09-06 07:06:43,283 - INFO - Experiment kg_completeness_0.5 completed
2024-09-06 07:06:43,284 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 07:06:43,284 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 07:06:43,284 - INFO - Running experiment: kg_completeness_0.75
2024-09-06 07:06:43,285 - INFO - Using device: cuda
2024-09-06 07:06:43,285 - INFO - Using device: cuda
2024-09-06 07:06:43,285 - INFO - Using device: cuda
2024-09-06 07:06:43,285 - INFO - Using device: cuda
2024-09-06 08:48:57,038 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_0.75\profile_stats.txt
2024-09-06 08:48:57,038 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_0.75\profile_stats.txt
2024-09-06 08:48:57,038 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_0.75\profile_stats.txt
2024-09-06 08:48:57,038 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_0.75\profile_stats.txt
2024-09-06 09:00:31,658 - INFO - Training and evaluation completed.
2024-09-06 09:00:31,658 - INFO - Training and evaluation completed.
2024-09-06 09:00:31,658 - INFO - Training and evaluation completed.
2024-09-06 09:00:31,658 - INFO - Training and evaluation completed.
2024-09-06 09:00:31,662 - INFO - Experiment kg_completeness_0.75 completed
2024-09-06 09:00:31,662 - INFO - Experiment kg_completeness_0.75 completed
2024-09-06 09:00:31,662 - INFO - Experiment kg_completeness_0.75 completed
2024-09-06 09:00:31,662 - INFO - Experiment kg_completeness_0.75 completed
2024-09-06 09:00:31,663 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 09:00:31,663 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 09:00:31,663 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 09:00:31,663 - INFO - Running experiment: kg_completeness_1.0
2024-09-06 09:00:31,664 - INFO - Using device: cuda
2024-09-06 09:00:31,664 - INFO - Using device: cuda
2024-09-06 09:00:31,664 - INFO - Using device: cuda
2024-09-06 09:00:31,664 - INFO - Using device: cuda
2024-09-06 09:00:31,664 - INFO - Using device: cuda
2024-09-06 10:40:44,469 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_1.0\profile_stats.txt
2024-09-06 10:40:44,469 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_1.0\profile_stats.txt
2024-09-06 10:40:44,469 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_1.0\profile_stats.txt
2024-09-06 10:40:44,469 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_1.0\profile_stats.txt
2024-09-06 10:40:44,469 - INFO - Profiling stats saved to results\20240906_032153\kg_completeness_1.0\profile_stats.txt
2024-09-06 10:51:43,154 - INFO - Training and evaluation completed.
2024-09-06 10:51:43,154 - INFO - Training and evaluation completed.
2024-09-06 10:51:43,154 - INFO - Training and evaluation completed.
2024-09-06 10:51:43,154 - INFO - Training and evaluation completed.
2024-09-06 10:51:43,154 - INFO - Training and evaluation completed.
2024-09-06 10:51:43,158 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 10:51:43,158 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 10:51:43,158 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 10:51:43,158 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 10:51:43,158 - INFO - Experiment kg_completeness_1.0 completed
2024-09-06 10:51:43,160 - INFO - Ablation study results saved to results\20240906_032153\ablation_study_results.json
2024-09-06 10:51:43,160 - INFO - Ablation study results saved to results\20240906_032153\ablation_study_results.json
2024-09-06 10:51:43,160 - INFO - Ablation study results saved to results\20240906_032153\ablation_study_results.json
2024-09-06 10:51:43,160 - INFO - Ablation study results saved to results\20240906_032153\ablation_study_results.json
2024-09-06 10:51:43,160 - INFO - Ablation study results saved to results\20240906_032153\ablation_study_results.json
2024-09-06 10:51:43,162 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.25_results.json
2024-09-06 10:51:43,162 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.25_results.json
2024-09-06 10:51:43,162 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.25_results.json
2024-09-06 10:51:43,162 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.25_results.json
2024-09-06 10:51:43,162 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.25_results.json
2024-09-06 10:51:43,164 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.5_results.json
2024-09-06 10:51:43,164 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.5_results.json
2024-09-06 10:51:43,164 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.5_results.json
2024-09-06 10:51:43,164 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.5_results.json
2024-09-06 10:51:43,164 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.5_results.json
2024-09-06 10:51:43,165 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.75_results.json
2024-09-06 10:51:43,165 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.75_results.json
2024-09-06 10:51:43,165 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.75_results.json
2024-09-06 10:51:43,165 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.75_results.json
2024-09-06 10:51:43,165 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_0.75_results.json
2024-09-06 10:51:43,167 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_1.0_results.json
2024-09-06 10:51:43,167 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_1.0_results.json
2024-09-06 10:51:43,167 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_1.0_results.json
2024-09-06 10:51:43,167 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_1.0_results.json
2024-09-06 10:51:43,167 - INFO - Individual experiment results saved to results\20240906_032153\kg_completeness_1.0_results.json
2024-09-06 10:51:43,168 - INFO - Base configuration saved to results\20240906_032153\base_config.json
2024-09-06 10:51:43,168 - INFO - Base configuration saved to results\20240906_032153\base_config.json
2024-09-06 10:51:43,168 - INFO - Base configuration saved to results\20240906_032153\base_config.json
2024-09-06 10:51:43,168 - INFO - Base configuration saved to results\20240906_032153\base_config.json
2024-09-06 10:51:43,168 - INFO - Base configuration saved to results\20240906_032153\base_config.json
2024-09-06 10:51:43,169 - INFO - Ablation Study completed
2024-09-06 10:51:43,169 - INFO - Ablation Study completed
2024-09-06 10:51:43,169 - INFO - Ablation Study completed
2024-09-06 10:51:43,169 - INFO - Ablation Study completed
2024-09-06 10:51:43,169 - INFO - Ablation Study completed
2024-09-06 11:42:33,817 - INFO - Created results directory: results\20240906_114233
2024-09-06 11:42:33,817 - INFO - Starting Ablation Study
2024-09-06 11:42:33,817 - INFO - Running experiment: kg_completeness_0.25
2024-09-06 11:42:33,842 - INFO - Using device: cuda
2024-09-06 11:42:33,842 - INFO - Using device: cuda
2024-09-09 21:46:41,202 - INFO - Created results directory: results\20240909_214641
2024-09-09 21:46:41,202 - INFO - Starting Ablation Study
2024-09-09 21:46:41,202 - INFO - Running experiment: kg_completeness_0.25
2024-09-09 21:46:41,268 - INFO - Using device: cuda
2024-09-09 21:46:41,268 - INFO - Using device: cuda
2024-09-09 21:48:11,544 - INFO - Created results directory: results\20240909_214811
2024-09-09 21:48:11,545 - INFO - Starting Ablation Study
2024-09-09 21:48:11,545 - INFO - Running experiment: kg_completeness_0.25
2024-09-09 21:48:11,568 - INFO - Using device: cuda
2024-09-09 21:48:11,568 - INFO - Using device: cuda
2024-09-10 10:26:10,369 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_0.25\profile_stats.txt
2024-09-10 10:26:10,369 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_0.25\profile_stats.txt
2024-09-10 10:39:56,653 - INFO - Training and evaluation completed.
2024-09-10 10:39:56,653 - INFO - Training and evaluation completed.
2024-09-10 10:39:56,668 - INFO - Experiment kg_completeness_0.25 completed
2024-09-10 10:39:56,668 - INFO - Experiment kg_completeness_0.25 completed
2024-09-10 10:39:56,668 - INFO - Running experiment: kg_completeness_0.5
2024-09-10 10:39:56,668 - INFO - Running experiment: kg_completeness_0.5
2024-09-10 10:39:56,705 - INFO - Using device: cuda
2024-09-10 10:39:56,705 - INFO - Using device: cuda
2024-09-10 10:39:56,705 - INFO - Using device: cuda
2024-09-10 23:46:03,692 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_0.5\profile_stats.txt
2024-09-10 23:46:03,692 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_0.5\profile_stats.txt
2024-09-10 23:46:03,692 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_0.5\profile_stats.txt
2024-09-11 00:04:05,977 - INFO - Training and evaluation completed.
2024-09-11 00:04:05,977 - INFO - Training and evaluation completed.
2024-09-11 00:04:05,977 - INFO - Training and evaluation completed.
2024-09-11 00:04:06,007 - INFO - Experiment kg_completeness_0.5 completed
2024-09-11 00:04:06,007 - INFO - Experiment kg_completeness_0.5 completed
2024-09-11 00:04:06,007 - INFO - Experiment kg_completeness_0.5 completed
2024-09-11 00:04:06,008 - INFO - Running experiment: kg_completeness_0.75
2024-09-11 00:04:06,008 - INFO - Running experiment: kg_completeness_0.75
2024-09-11 00:04:06,008 - INFO - Running experiment: kg_completeness_0.75
2024-09-11 00:04:06,064 - INFO - Using device: cuda
2024-09-11 00:04:06,064 - INFO - Using device: cuda
2024-09-11 00:04:06,064 - INFO - Using device: cuda
2024-09-11 00:04:06,064 - INFO - Using device: cuda
2024-09-11 12:47:05,354 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_0.75\profile_stats.txt
2024-09-11 12:47:05,354 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_0.75\profile_stats.txt
2024-09-11 12:47:05,354 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_0.75\profile_stats.txt
2024-09-11 12:47:05,354 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_0.75\profile_stats.txt
2024-09-11 13:00:42,967 - INFO - Training and evaluation completed.
2024-09-11 13:00:42,967 - INFO - Training and evaluation completed.
2024-09-11 13:00:42,967 - INFO - Training and evaluation completed.
2024-09-11 13:00:42,967 - INFO - Training and evaluation completed.
2024-09-11 13:00:42,971 - INFO - Experiment kg_completeness_0.75 completed
2024-09-11 13:00:42,971 - INFO - Experiment kg_completeness_0.75 completed
2024-09-11 13:00:42,971 - INFO - Experiment kg_completeness_0.75 completed
2024-09-11 13:00:42,971 - INFO - Experiment kg_completeness_0.75 completed
2024-09-11 13:00:42,973 - INFO - Running experiment: kg_completeness_1.0
2024-09-11 13:00:42,973 - INFO - Running experiment: kg_completeness_1.0
2024-09-11 13:00:42,973 - INFO - Running experiment: kg_completeness_1.0
2024-09-11 13:00:42,973 - INFO - Running experiment: kg_completeness_1.0
2024-09-11 13:00:43,011 - INFO - Using device: cuda
2024-09-11 13:00:43,011 - INFO - Using device: cuda
2024-09-11 13:00:43,011 - INFO - Using device: cuda
2024-09-11 13:00:43,011 - INFO - Using device: cuda
2024-09-11 13:00:43,011 - INFO - Using device: cuda
2024-09-12 02:12:50,923 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_1.0\profile_stats.txt
2024-09-12 02:12:50,923 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_1.0\profile_stats.txt
2024-09-12 02:12:50,923 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_1.0\profile_stats.txt
2024-09-12 02:12:50,923 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_1.0\profile_stats.txt
2024-09-12 02:12:50,923 - INFO - Profiling stats saved to results\20240909_214811\kg_completeness_1.0\profile_stats.txt
2024-09-12 02:27:34,889 - INFO - Training and evaluation completed.
2024-09-12 02:27:34,889 - INFO - Training and evaluation completed.
2024-09-12 02:27:34,889 - INFO - Training and evaluation completed.
2024-09-12 02:27:34,889 - INFO - Training and evaluation completed.
2024-09-12 02:27:34,889 - INFO - Training and evaluation completed.
2024-09-12 02:27:34,900 - INFO - Experiment kg_completeness_1.0 completed
2024-09-12 02:27:34,900 - INFO - Experiment kg_completeness_1.0 completed
2024-09-12 02:27:34,900 - INFO - Experiment kg_completeness_1.0 completed
2024-09-12 02:27:34,900 - INFO - Experiment kg_completeness_1.0 completed
2024-09-12 02:27:34,900 - INFO - Experiment kg_completeness_1.0 completed
2024-09-12 02:27:34,904 - INFO - Ablation study results saved to results\20240909_214811\ablation_study_results.json
2024-09-12 02:27:34,904 - INFO - Ablation study results saved to results\20240909_214811\ablation_study_results.json
2024-09-12 02:27:34,904 - INFO - Ablation study results saved to results\20240909_214811\ablation_study_results.json
2024-09-12 02:27:34,904 - INFO - Ablation study results saved to results\20240909_214811\ablation_study_results.json
2024-09-12 02:27:34,904 - INFO - Ablation study results saved to results\20240909_214811\ablation_study_results.json
2024-09-12 02:27:34,905 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.25_results.json
2024-09-12 02:27:34,905 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.25_results.json
2024-09-12 02:27:34,905 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.25_results.json
2024-09-12 02:27:34,905 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.25_results.json
2024-09-12 02:27:34,905 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.25_results.json
2024-09-12 02:27:34,907 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.5_results.json
2024-09-12 02:27:34,907 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.5_results.json
2024-09-12 02:27:34,907 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.5_results.json
2024-09-12 02:27:34,907 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.5_results.json
2024-09-12 02:27:34,907 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.5_results.json
2024-09-12 02:27:34,908 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.75_results.json
2024-09-12 02:27:34,908 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.75_results.json
2024-09-12 02:27:34,908 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.75_results.json
2024-09-12 02:27:34,908 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.75_results.json
2024-09-12 02:27:34,908 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_0.75_results.json
2024-09-12 02:27:34,909 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_1.0_results.json
2024-09-12 02:27:34,909 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_1.0_results.json
2024-09-12 02:27:34,909 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_1.0_results.json
2024-09-12 02:27:34,909 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_1.0_results.json
2024-09-12 02:27:34,909 - INFO - Individual experiment results saved to results\20240909_214811\kg_completeness_1.0_results.json
2024-09-12 02:27:34,910 - INFO - Base configuration saved to results\20240909_214811\base_config.json
2024-09-12 02:27:34,910 - INFO - Base configuration saved to results\20240909_214811\base_config.json
2024-09-12 02:27:34,910 - INFO - Base configuration saved to results\20240909_214811\base_config.json
2024-09-12 02:27:34,910 - INFO - Base configuration saved to results\20240909_214811\base_config.json
2024-09-12 02:27:34,910 - INFO - Base configuration saved to results\20240909_214811\base_config.json
2024-09-12 02:27:34,911 - INFO - Ablation Study completed
2024-09-12 02:27:34,911 - INFO - Ablation Study completed
2024-09-12 02:27:34,911 - INFO - Ablation Study completed
2024-09-12 02:27:34,911 - INFO - Ablation Study completed
2024-09-12 02:27:34,911 - INFO - Ablation Study completed
2024-09-12 16:30:14,295 - INFO - Created results directory: results\20240912_163014
2024-09-12 16:30:14,295 - INFO - Starting Ablation Study
2024-09-12 16:30:14,295 - INFO - Running experiment: kg_completeness_0.25
2024-09-12 16:30:14,325 - INFO - Using device: cuda
2024-09-12 16:30:14,325 - INFO - Using device: cuda
2024-09-12 16:42:28,543 - INFO - Created results directory: results\20240912_164228
2024-09-12 16:42:28,543 - INFO - Starting Ablation Study
2024-09-12 16:42:28,543 - INFO - Running experiment: kg_completeness_0.25
2024-09-12 16:42:28,574 - INFO - Using device: cuda
2024-09-12 16:42:28,574 - INFO - Using device: cuda
2024-09-12 16:42:29,236 - ERROR - An error occurred during experiment kg_completeness_0.25: Cannot choose from an empty sequence
2024-09-12 16:42:29,236 - ERROR - An error occurred during experiment kg_completeness_0.25: Cannot choose from an empty sequence
2024-09-12 16:42:29,277 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,277 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,286 - INFO - Running experiment: kg_completeness_0.5
2024-09-12 16:42:29,286 - INFO - Running experiment: kg_completeness_0.5
2024-09-12 16:42:29,288 - INFO - Using device: cuda
2024-09-12 16:42:29,288 - INFO - Using device: cuda
2024-09-12 16:42:29,288 - INFO - Using device: cuda
2024-09-12 16:42:29,323 - ERROR - An error occurred during experiment kg_completeness_0.5: Cannot choose from an empty sequence
2024-09-12 16:42:29,323 - ERROR - An error occurred during experiment kg_completeness_0.5: Cannot choose from an empty sequence
2024-09-12 16:42:29,323 - ERROR - An error occurred during experiment kg_completeness_0.5: Cannot choose from an empty sequence
2024-09-12 16:42:29,325 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,325 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,325 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,334 - INFO - Running experiment: kg_completeness_0.75
2024-09-12 16:42:29,334 - INFO - Running experiment: kg_completeness_0.75
2024-09-12 16:42:29,334 - INFO - Running experiment: kg_completeness_0.75
2024-09-12 16:42:29,335 - INFO - Using device: cuda
2024-09-12 16:42:29,335 - INFO - Using device: cuda
2024-09-12 16:42:29,335 - INFO - Using device: cuda
2024-09-12 16:42:29,335 - INFO - Using device: cuda
2024-09-12 16:42:29,707 - ERROR - An error occurred during experiment kg_completeness_0.75: Cannot choose from an empty sequence
2024-09-12 16:42:29,707 - ERROR - An error occurred during experiment kg_completeness_0.75: Cannot choose from an empty sequence
2024-09-12 16:42:29,707 - ERROR - An error occurred during experiment kg_completeness_0.75: Cannot choose from an empty sequence
2024-09-12 16:42:29,707 - ERROR - An error occurred during experiment kg_completeness_0.75: Cannot choose from an empty sequence
2024-09-12 16:42:29,708 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,708 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,708 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,708 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,723 - INFO - Running experiment: kg_completeness_1.0
2024-09-12 16:42:29,723 - INFO - Running experiment: kg_completeness_1.0
2024-09-12 16:42:29,723 - INFO - Running experiment: kg_completeness_1.0
2024-09-12 16:42:29,723 - INFO - Running experiment: kg_completeness_1.0
2024-09-12 16:42:29,725 - INFO - Using device: cuda
2024-09-12 16:42:29,725 - INFO - Using device: cuda
2024-09-12 16:42:29,725 - INFO - Using device: cuda
2024-09-12 16:42:29,725 - INFO - Using device: cuda
2024-09-12 16:42:29,725 - INFO - Using device: cuda
2024-09-12 16:42:29,816 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-12 16:42:29,816 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-12 16:42:29,816 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-12 16:42:29,816 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-12 16:42:29,816 - ERROR - An error occurred during experiment kg_completeness_1.0: Cannot choose from an empty sequence
2024-09-12 16:42:29,816 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,816 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,816 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,816 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,816 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 43, in initialize_components
    self.environment = Environment(heightmap, self.tile_size, number_of_outposts=3)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 36, in __init__
    self.player = self.init_player()
                  ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 140, in init_player
    location = self.get_random_less_suitable_location()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\environment.py", line 47, in get_random_less_suitable_location
    return random.choice(self.less_suitable_terrain_locations[key])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\random.py", line 373, in choice
    raise IndexError('Cannot choose from an empty sequence')
IndexError: Cannot choose from an empty sequence

2024-09-12 16:42:29,833 - INFO - Ablation study results saved to results\20240912_164228\ablation_study_results.json
2024-09-12 16:42:29,833 - INFO - Ablation study results saved to results\20240912_164228\ablation_study_results.json
2024-09-12 16:42:29,833 - INFO - Ablation study results saved to results\20240912_164228\ablation_study_results.json
2024-09-12 16:42:29,833 - INFO - Ablation study results saved to results\20240912_164228\ablation_study_results.json
2024-09-12 16:42:29,833 - INFO - Ablation study results saved to results\20240912_164228\ablation_study_results.json
2024-09-12 16:42:29,837 - INFO - Base configuration saved to results\20240912_164228\base_config.json
2024-09-12 16:42:29,837 - INFO - Base configuration saved to results\20240912_164228\base_config.json
2024-09-12 16:42:29,837 - INFO - Base configuration saved to results\20240912_164228\base_config.json
2024-09-12 16:42:29,837 - INFO - Base configuration saved to results\20240912_164228\base_config.json
2024-09-12 16:42:29,837 - INFO - Base configuration saved to results\20240912_164228\base_config.json
2024-09-12 16:42:29,837 - INFO - Ablation Study completed
2024-09-12 16:42:29,837 - INFO - Ablation Study completed
2024-09-12 16:42:29,837 - INFO - Ablation Study completed
2024-09-12 16:42:29,837 - INFO - Ablation Study completed
2024-09-12 16:42:29,837 - INFO - Ablation Study completed
2024-09-12 17:07:46,431 - INFO - Created results directory: results\20240912_170746
2024-09-12 17:07:46,431 - INFO - Starting Ablation Study
2024-09-12 17:07:46,431 - INFO - Running experiment: kg_completeness_0.25
2024-09-12 17:07:46,465 - INFO - Using device: cuda
2024-09-12 17:07:46,465 - INFO - Using device: cuda
2024-09-12 17:07:47,225 - ERROR - An error occurred during experiment kg_completeness_0.25: 0
2024-09-12 17:07:47,225 - ERROR - An error occurred during experiment kg_completeness_0.25: 0
2024-09-12 17:07:47,225 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:47,225 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:47,236 - INFO - Running experiment: kg_completeness_0.5
2024-09-12 17:07:47,236 - INFO - Running experiment: kg_completeness_0.5
2024-09-12 17:07:47,237 - INFO - Using device: cuda
2024-09-12 17:07:47,237 - INFO - Using device: cuda
2024-09-12 17:07:47,237 - INFO - Using device: cuda
2024-09-12 17:07:48,333 - ERROR - An error occurred during experiment kg_completeness_0.5: 0
2024-09-12 17:07:48,333 - ERROR - An error occurred during experiment kg_completeness_0.5: 0
2024-09-12 17:07:48,333 - ERROR - An error occurred during experiment kg_completeness_0.5: 0
2024-09-12 17:07:48,333 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:48,333 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:48,333 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:48,343 - INFO - Running experiment: kg_completeness_0.75
2024-09-12 17:07:48,343 - INFO - Running experiment: kg_completeness_0.75
2024-09-12 17:07:48,343 - INFO - Running experiment: kg_completeness_0.75
2024-09-12 17:07:48,344 - INFO - Using device: cuda
2024-09-12 17:07:48,344 - INFO - Using device: cuda
2024-09-12 17:07:48,344 - INFO - Using device: cuda
2024-09-12 17:07:48,344 - INFO - Using device: cuda
2024-09-12 17:07:50,363 - ERROR - An error occurred during experiment kg_completeness_0.75: 0
2024-09-12 17:07:50,363 - ERROR - An error occurred during experiment kg_completeness_0.75: 0
2024-09-12 17:07:50,363 - ERROR - An error occurred during experiment kg_completeness_0.75: 0
2024-09-12 17:07:50,363 - ERROR - An error occurred during experiment kg_completeness_0.75: 0
2024-09-12 17:07:50,375 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:50,375 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:50,375 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:50,375 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:50,384 - INFO - Running experiment: kg_completeness_1.0
2024-09-12 17:07:50,384 - INFO - Running experiment: kg_completeness_1.0
2024-09-12 17:07:50,384 - INFO - Running experiment: kg_completeness_1.0
2024-09-12 17:07:50,384 - INFO - Running experiment: kg_completeness_1.0
2024-09-12 17:07:50,386 - INFO - Using device: cuda
2024-09-12 17:07:50,386 - INFO - Using device: cuda
2024-09-12 17:07:50,386 - INFO - Using device: cuda
2024-09-12 17:07:50,386 - INFO - Using device: cuda
2024-09-12 17:07:50,386 - INFO - Using device: cuda
2024-09-12 17:07:51,285 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-12 17:07:51,285 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-12 17:07:51,285 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-12 17:07:51,285 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-12 17:07:51,285 - ERROR - An error occurred during experiment kg_completeness_1.0: 0
2024-09-12 17:07:51,295 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:51,295 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:51,295 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:51,295 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:51,295 - ERROR - Traceback (most recent call last):
  File "c:\Users\anton\Dev\ABM\training.py", line 328, in run
    trainer.setup(self.base_config)
  File "c:\Users\anton\Dev\ABM\training.py", line 378, in setup
    self.env: CustomEnv = self.env_manager.make_env()
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\training.py", line 32, in make_env
    env = CustomEnv(self.game_manager_args, self.simulation_manager_args, self.model_args, plot = False)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\custom_env.py", line 64, in __init__
    self.simulation_manager = SimulationManager(
                              ^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 16, in __init__
    self.create_games(self.number_of_environments, game_manager_args, plot)
  File "c:\Users\anton\Dev\ABM\simulation_manager.py", line 49, in create_games
    game_manager = GameManager(num_tiles, screen_size, vision_range, plot)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 27, in __init__
    self.initialize_components()
  File "c:\Users\anton\Dev\ABM\game_manager.py", line 48, in initialize_components
    self.target_manager = Target_Manager(self.environment)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 18, in __init__
    self.shortest_path, self.min_path_length = self.get_target_trade_route()
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 51, in get_target_trade_route
    shortest_path_indices, min_path_length = self.find_shortest_tsp_path()
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in find_shortest_tsp_path
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\anton\Dev\ABM\target.py", line 42, in <genexpr>
    path_length = sum(self.G.edges[cycle[n], cycle[n+1]]['weight'] for n in range(len(cycle) - 1))
                      ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\anton\anaconda3\envs\ABM\Lib\site-packages\networkx\classes\reportviews.py", line 1085, in __getitem__
    return self._adjdict[u][v]
           ~~~~~~~~~~~~~~~~^^^
KeyError: 0

2024-09-12 17:07:51,303 - INFO - Ablation study results saved to results\20240912_170746\ablation_study_results.json
2024-09-12 17:07:51,303 - INFO - Ablation study results saved to results\20240912_170746\ablation_study_results.json
2024-09-12 17:07:51,303 - INFO - Ablation study results saved to results\20240912_170746\ablation_study_results.json
2024-09-12 17:07:51,303 - INFO - Ablation study results saved to results\20240912_170746\ablation_study_results.json
2024-09-12 17:07:51,303 - INFO - Ablation study results saved to results\20240912_170746\ablation_study_results.json
2024-09-12 17:07:51,303 - INFO - Base configuration saved to results\20240912_170746\base_config.json
2024-09-12 17:07:51,303 - INFO - Base configuration saved to results\20240912_170746\base_config.json
2024-09-12 17:07:51,303 - INFO - Base configuration saved to results\20240912_170746\base_config.json
2024-09-12 17:07:51,303 - INFO - Base configuration saved to results\20240912_170746\base_config.json
2024-09-12 17:07:51,303 - INFO - Base configuration saved to results\20240912_170746\base_config.json
2024-09-12 17:07:51,303 - INFO - Ablation Study completed
2024-09-12 17:07:51,303 - INFO - Ablation Study completed
2024-09-12 17:07:51,303 - INFO - Ablation Study completed
2024-09-12 17:07:51,303 - INFO - Ablation Study completed
2024-09-12 17:07:51,303 - INFO - Ablation Study completed
2024-09-12 17:08:19,938 - INFO - Created results directory: results\20240912_170819
2024-09-12 17:08:19,938 - INFO - Starting Ablation Study
2024-09-12 17:08:19,938 - INFO - Running experiment: kg_completeness_0.25
2024-09-12 17:08:19,965 - INFO - Using device: cuda
2024-09-12 17:08:19,965 - INFO - Using device: cuda
2024-09-12 17:09:01,749 - INFO - Created results directory: results\20240912_170901
2024-09-12 17:09:01,749 - INFO - Starting Ablation Study
2024-09-12 17:09:01,749 - INFO - Running experiment: kg_completeness_0.25
2024-09-12 17:09:01,768 - INFO - Using device: cuda
2024-09-12 17:09:01,768 - INFO - Using device: cuda
2024-09-13 09:08:22,011 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_0.25\profile_stats.txt
2024-09-13 09:08:22,011 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_0.25\profile_stats.txt
2024-09-13 09:19:32,213 - INFO - Training and evaluation completed.
2024-09-13 09:19:32,213 - INFO - Training and evaluation completed.
2024-09-13 09:19:32,216 - INFO - Experiment kg_completeness_0.25 completed
2024-09-13 09:19:32,216 - INFO - Experiment kg_completeness_0.25 completed
2024-09-13 09:19:32,216 - INFO - Running experiment: kg_completeness_0.5
2024-09-13 09:19:32,216 - INFO - Running experiment: kg_completeness_0.5
2024-09-13 09:19:32,224 - INFO - Using device: cuda
2024-09-13 09:19:32,224 - INFO - Using device: cuda
2024-09-13 09:19:32,224 - INFO - Using device: cuda
2024-09-14 01:24:15,050 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_0.5\profile_stats.txt
2024-09-14 01:24:15,050 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_0.5\profile_stats.txt
2024-09-14 01:24:15,050 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_0.5\profile_stats.txt
2024-09-14 01:35:19,706 - INFO - Training and evaluation completed.
2024-09-14 01:35:19,706 - INFO - Training and evaluation completed.
2024-09-14 01:35:19,706 - INFO - Training and evaluation completed.
2024-09-14 01:35:19,708 - INFO - Experiment kg_completeness_0.5 completed
2024-09-14 01:35:19,708 - INFO - Experiment kg_completeness_0.5 completed
2024-09-14 01:35:19,708 - INFO - Experiment kg_completeness_0.5 completed
2024-09-14 01:35:19,708 - INFO - Running experiment: kg_completeness_0.75
2024-09-14 01:35:19,708 - INFO - Running experiment: kg_completeness_0.75
2024-09-14 01:35:19,708 - INFO - Running experiment: kg_completeness_0.75
2024-09-14 01:35:19,710 - INFO - Using device: cuda
2024-09-14 01:35:19,710 - INFO - Using device: cuda
2024-09-14 01:35:19,710 - INFO - Using device: cuda
2024-09-14 01:35:19,710 - INFO - Using device: cuda
2024-09-14 17:13:26,652 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_0.75\profile_stats.txt
2024-09-14 17:13:26,652 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_0.75\profile_stats.txt
2024-09-14 17:13:26,652 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_0.75\profile_stats.txt
2024-09-14 17:13:26,652 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_0.75\profile_stats.txt
2024-09-14 17:25:17,196 - INFO - Training and evaluation completed.
2024-09-14 17:25:17,196 - INFO - Training and evaluation completed.
2024-09-14 17:25:17,196 - INFO - Training and evaluation completed.
2024-09-14 17:25:17,196 - INFO - Training and evaluation completed.
2024-09-14 17:25:17,201 - INFO - Experiment kg_completeness_0.75 completed
2024-09-14 17:25:17,201 - INFO - Experiment kg_completeness_0.75 completed
2024-09-14 17:25:17,201 - INFO - Experiment kg_completeness_0.75 completed
2024-09-14 17:25:17,201 - INFO - Experiment kg_completeness_0.75 completed
2024-09-14 17:25:17,201 - INFO - Running experiment: kg_completeness_1.0
2024-09-14 17:25:17,201 - INFO - Running experiment: kg_completeness_1.0
2024-09-14 17:25:17,201 - INFO - Running experiment: kg_completeness_1.0
2024-09-14 17:25:17,201 - INFO - Running experiment: kg_completeness_1.0
2024-09-14 17:25:17,212 - INFO - Using device: cuda
2024-09-14 17:25:17,212 - INFO - Using device: cuda
2024-09-14 17:25:17,212 - INFO - Using device: cuda
2024-09-14 17:25:17,212 - INFO - Using device: cuda
2024-09-14 17:25:17,212 - INFO - Using device: cuda
2024-09-15 09:26:48,726 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_1.0\profile_stats.txt
2024-09-15 09:26:48,726 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_1.0\profile_stats.txt
2024-09-15 09:26:48,726 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_1.0\profile_stats.txt
2024-09-15 09:26:48,726 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_1.0\profile_stats.txt
2024-09-15 09:26:48,726 - INFO - Profiling stats saved to results\20240912_170901\kg_completeness_1.0\profile_stats.txt
2024-09-15 09:37:20,099 - INFO - Training and evaluation completed.
2024-09-15 09:37:20,099 - INFO - Training and evaluation completed.
2024-09-15 09:37:20,099 - INFO - Training and evaluation completed.
2024-09-15 09:37:20,099 - INFO - Training and evaluation completed.
2024-09-15 09:37:20,099 - INFO - Training and evaluation completed.
2024-09-15 09:37:20,103 - INFO - Experiment kg_completeness_1.0 completed
2024-09-15 09:37:20,103 - INFO - Experiment kg_completeness_1.0 completed
2024-09-15 09:37:20,103 - INFO - Experiment kg_completeness_1.0 completed
2024-09-15 09:37:20,103 - INFO - Experiment kg_completeness_1.0 completed
2024-09-15 09:37:20,103 - INFO - Experiment kg_completeness_1.0 completed
2024-09-15 09:37:20,105 - INFO - Ablation study results saved to results\20240912_170901\ablation_study_results.json
2024-09-15 09:37:20,105 - INFO - Ablation study results saved to results\20240912_170901\ablation_study_results.json
2024-09-15 09:37:20,105 - INFO - Ablation study results saved to results\20240912_170901\ablation_study_results.json
2024-09-15 09:37:20,105 - INFO - Ablation study results saved to results\20240912_170901\ablation_study_results.json
2024-09-15 09:37:20,105 - INFO - Ablation study results saved to results\20240912_170901\ablation_study_results.json
2024-09-15 09:37:20,143 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.25_results.json
2024-09-15 09:37:20,143 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.25_results.json
2024-09-15 09:37:20,143 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.25_results.json
2024-09-15 09:37:20,143 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.25_results.json
2024-09-15 09:37:20,143 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.25_results.json
2024-09-15 09:37:20,145 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.5_results.json
2024-09-15 09:37:20,145 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.5_results.json
2024-09-15 09:37:20,145 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.5_results.json
2024-09-15 09:37:20,145 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.5_results.json
2024-09-15 09:37:20,145 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.5_results.json
2024-09-15 09:37:20,146 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.75_results.json
2024-09-15 09:37:20,146 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.75_results.json
2024-09-15 09:37:20,146 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.75_results.json
2024-09-15 09:37:20,146 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.75_results.json
2024-09-15 09:37:20,146 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_0.75_results.json
2024-09-15 09:37:20,147 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_1.0_results.json
2024-09-15 09:37:20,147 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_1.0_results.json
2024-09-15 09:37:20,147 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_1.0_results.json
2024-09-15 09:37:20,147 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_1.0_results.json
2024-09-15 09:37:20,147 - INFO - Individual experiment results saved to results\20240912_170901\kg_completeness_1.0_results.json
2024-09-15 09:37:20,148 - INFO - Base configuration saved to results\20240912_170901\base_config.json
2024-09-15 09:37:20,148 - INFO - Base configuration saved to results\20240912_170901\base_config.json
2024-09-15 09:37:20,148 - INFO - Base configuration saved to results\20240912_170901\base_config.json
2024-09-15 09:37:20,148 - INFO - Base configuration saved to results\20240912_170901\base_config.json
2024-09-15 09:37:20,148 - INFO - Base configuration saved to results\20240912_170901\base_config.json
2024-09-15 09:37:20,149 - INFO - Ablation Study completed
2024-09-15 09:37:20,149 - INFO - Ablation Study completed
2024-09-15 09:37:20,149 - INFO - Ablation Study completed
2024-09-15 09:37:20,149 - INFO - Ablation Study completed
2024-09-15 09:37:20,149 - INFO - Ablation Study completed
